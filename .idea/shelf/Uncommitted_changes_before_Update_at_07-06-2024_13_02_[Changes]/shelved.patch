Index: twin4build/model/model.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import networkx as nx\r\nimport pandas as pd\r\nimport warnings\r\nimport math\r\nimport shutil\r\nimport subprocess\r\nimport sys\r\nimport os\r\nimport copy\r\nimport pydot\r\nimport inspect\r\nimport numpy as np\r\nimport pandas as pd\r\nimport numbers\r\nimport datetime\r\nimport torch\r\nimport json\r\nimport builtins\r\nimport pickle\r\nimport matplotlib.font_manager\r\nfrom PIL import ImageFont\r\nfrom itertools import count\r\nfrom prettytable import PrettyTable\r\nfrom prettytable.colortable import ColorTable, Themes\r\n\r\nfrom openpyxl import load_workbook\r\nfrom dateutil.parser import parse\r\nfrom twin4build.utils.fmu.fmu_component import FMUComponent\r\nfrom twin4build.utils.isnumeric import isnumeric\r\nfrom twin4build.utils.get_object_attributes import get_object_attributes\r\nfrom twin4build.utils.mkdir_in_root import mkdir_in_root\r\nfrom twin4build.utils.rsetattr import rsetattr\r\nfrom twin4build.utils.rgetattr import rgetattr\r\nfrom twin4build.utils.istype import istype\r\nfrom twin4build.utils.data_loaders.fiwareReader import fiwareReader\r\nfrom twin4build.utils.preprocessing.data_sampler import data_sampler\r\nfrom twin4build.utils.data_loaders.load_spreadsheet import sample_from_df\r\nfrom twin4build.saref4syst.connection import Connection \r\nfrom twin4build.saref4syst.connection_point import ConnectionPoint\r\nfrom twin4build.saref4syst.system import System\r\nimport twin4build.utils.signature_pattern.signature_pattern as signature_pattern\r\nfrom twin4build.utils.uppath import uppath\r\n# from twin4build.utils.outdoor_environment import OutdoorEnvironmentSystem\r\n# from twin4build.utils.schedule import ScheduleSystem\r\n# from twin4build.utils.flow_junction_system import FlowJunctionSystem\r\n# from twin4build.utils.piecewise_linear import PiecewiseLinearSystem\r\n# from twin4build.utils.piecewise_linear_supply_water_temperature import PiecewiseLinearSupplyWaterTemperatureSystem\r\n# from twin4build.utils.on_off_system import OnOffSystem\r\nfrom twin4build.utils.data_loaders.load_spreadsheet import load_spreadsheet\r\n# from twin4build.saref.measurement.measurement import Measurement\r\n# from twin4build.utils.time_series_input import TimeSeriesInputSystem\r\n# from twin4build.utils.piecewise_linear_schedule import PiecewiseLinearScheduleSystem\r\n\r\n# import twin4build.saref.property_.property_ as property_\r\n# from twin4build.saref.property_.temperature.temperature import Temperature\r\n# from twin4build.saref.property_.Co2.Co2 import Co2\r\n# from twin4build.saref.property_.opening_position.opening_position import OpeningPosition #This is in use\r\n# from twin4build.saref.property_.energy.energy import Energy #This is in use\r\n# from twin4build.saref.property_.power.power import Power #This is in use\r\n# from twin4build.saref.property_.pressure.pressure import Pressure #This is in use\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_device import DistributionDevice\r\n# from twin4build.saref4bldg.building_space.building_space import BuildingSpace\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.coil.coil import Coil\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_control_device.controller.controller import Controller\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.air_to_air_heat_recovery.air_to_air_heat_recovery import AirToAirHeatRecovery\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_controller.damper.damper import Damper\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_controller.valve.valve import Valve\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_moving_device.fan.fan import Fan\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_terminal.space_heater.space_heater import SpaceHeater\r\n# from twin4build.saref.device.sensor.sensor import Sensor\r\n# from twin4build.saref.device.meter.meter import Meter\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_moving_device.pump.pump import Pump\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.shading_device.shading_device import ShadingDevice\r\n# from twin4build.saref4bldg.building_space.building_space_adjacent_system import BuildingSpaceSystem, NoSpaceModelException\r\n# from twin4build.saref4bldg.building_space.building_space_co2_system import BuildingSpaceCo2System\r\n# from twin4build.saref4bldg.building_space.building_space_occ_system import BuildingSpaceOccSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.coil.coil_system_fmu import CoilSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.coil.coil_heating_system import CoilHeatingSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.coil.coil_cooling_system import CoilCoolingSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_control_device.controller.controller_system import ControllerSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_control_device.controller.controller_system_rulebased import RulebasedControllerSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.air_to_air_heat_recovery.air_to_air_heat_recovery_system import AirToAirHeatRecoverySystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_controller.damper.damper_system import DamperSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_controller.valve.valve_system import ValveSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_moving_device.fan.fan_system import FanSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.flow_terminal.space_heater.space_heater_system import SpaceHeaterSystem\r\n# from twin4build.saref.device.sensor.sensor_system import SensorSystem\r\n# from twin4build.saref.device.meter.meter_system import MeterSystem\r\n# from twin4build.saref4bldg.physical_object.building_object.building_device.shading_device.shading_device_system import ShadingDeviceSystem\r\nfrom twin4build.logger.Logging import Logging\r\n# import twin4build as tb\r\nimport twin4build.base as base\r\nimport twin4build.components as components\r\n\r\nlogger = Logging.get_logger(\"ai_logfile\")\r\n\r\ndef str2Class(str):\r\n    return getattr(sys.modules[__name__], str)\r\n\r\n\r\nclass Model:\r\n    def __str__(self):\r\n        columns = [\"id\", \"class\"]\r\n        t = PrettyTable(columns)\r\n        # t = ColorTable(columns, theme=Themes.OCEAN)\r\n        t.title = f\"Model overview    id: {self.id}\"\r\n\r\n        unique_class_list = []\r\n        for component in self.component_dict.values():\r\n            cls = component.__class__\r\n            if cls not in unique_class_list:\r\n                unique_class_list.append(cls)\r\n        unique_class_list = sorted(unique_class_list, key=lambda x: x.__name__.lower())\r\n\r\n        for cls in unique_class_list:\r\n            cs = self.get_component_by_class(self.component_dict, cls)\r\n            n = len(cs)\r\n            for i,c in enumerate(cs):\r\n                t.add_row([c.id, cls.__name__], divider=True if i==n-1 else False)\r\n            \r\n        return t.get_string()\r\n\r\n    def __init__(self,\r\n                 id=None,\r\n                saveSimulationResult=False):\r\n        self.valid_chars = [\"_\", \"-\", \" \", \"(\", \")\", \"[\", \"]\"]\r\n        assert isinstance(id, str), f\"Argument \\\"id\\\" must be of type {str(type(str))}\"\r\n        isvalid = np.array([x.isalnum() or x in self.valid_chars for x in id])\r\n        np_id = np.array(list(id))\r\n        violated_characters = list(np_id[isvalid==False])\r\n        assert all(isvalid), f\"The model with id \\\"{id}\\\" has an invalid id. The characters \\\"{', '.join(violated_characters)}\\\" are not allowed.\"\r\n        self.id = id\r\n        self.saveSimulationResult = saveSimulationResult\r\n        # self.system_graph = pydot.Dot()#nx.MultiDiGraph() ###\r\n        \r\n        # self.system_graph_rank=None #Set to string \"same\" to put all nodes with same class on same rank\r\n        # self.object_graph_rank=None #Set to string \"same\" to put all nodes with same class on same rank\r\n        # self.system_subgraph_dict = {}\r\n        # self.object_subgraph_dict = {}\r\n        # self.system_graph_node_attribute_dict = {}\r\n        # self.system_graph_edge_label_dict = {}\r\n        \r\n        self._initialize_graph(\"system\")\r\n        self._initialize_graph(\"object\")\r\n\r\n\r\n        self.system_dict = {\"ventilation\": {},\r\n                            \"heating\": {},\r\n                            \"cooling\": {},\r\n                            }\r\n        self.component_base_dict = {} #Subset of object_dict\r\n        self.component_dict = {} #Subset of object_dict\r\n        self.object_dict = {}\r\n        self.object_dict_reversed = {}\r\n        self.object_counter_dict = {}\r\n        self.property_dict = {}\r\n        self.custom_initial_dict = None\r\n        self.initial_dict = None\r\n\r\n        self.graph_path, isfile = self.get_dir(folder_list=[\"graphs\"])\r\n        logger.info(\"[Model Class] : Exited from Initialise Function\")\r\n    \r\n    def get_dir(self, folder_list=[], filename=None):\r\n        f = [\"generated_files\", \"models\", self.id]\r\n        f.extend(folder_list)\r\n        folder_list = f\r\n        filename, isfile = mkdir_in_root(folder_list=folder_list, filename=filename)\r\n        return filename, isfile\r\n\r\n    def _add_edge(self, graph, a, b, sender_property_name=None, receiver_property_name=None, edge_kwargs=None):\r\n        if edge_kwargs is None:\r\n            edge_label = self.get_edge_label(sender_property_name, receiver_property_name)\r\n            edge_kwargs = {\"label\": edge_label}\r\n            graph.add_edge(pydot.Edge(a, b, **edge_kwargs))\r\n            # graph.add_edge(pydot.Edge(a, b, label=edge_label))#, tailport=sender_property_name))\r\n        else:\r\n            graph.add_edge(pydot.Edge(a, b, **edge_kwargs))\r\n\r\n    def _del_edge(self, graph, a, b, label):\r\n        if pydot.needs_quotes(a):\r\n            a = f\"\\\"{a}\\\"\"\r\n        if pydot.needs_quotes(b):\r\n            b = f\"\\\"{b}\\\"\"\r\n\r\n        edges = graph.get_edge(a, b)\r\n        is_matched = [el.obj_dict[\"attributes\"][\"label\"]==label for el in edges]\r\n        match_idx = [i for i, x in enumerate(is_matched) if x]\r\n        assert len(match_idx)==1, \"Wrong length\"\r\n        status = graph.del_edge(a, b, match_idx[0])\r\n        return status\r\n\r\n    def _add_component(self, component):\r\n        assert isinstance(component, System), f\"The argument \\\"component\\\" must be of type {System.__name__}\"\r\n        if component.id not in self.component_dict:\r\n            self.component_dict[component.id] = component\r\n\r\n        # class_name = type(component).__name__\r\n        # if class_name not in self.system_subgraph_dict:\r\n        #     self.system_subgraph_dict[class_name] = pydot.Subgraph(rank=self.system_graph_rank)\r\n        #     self.system_subgraph_dict[class_name].add_subgraph(self.system_subgraph_dict[class_name])\r\n\r\n        # if not self.system_subgraph_dict[class_name].get_node(component.id):\r\n        #     node = pydot.Node(component.id)\r\n        #     self.system_subgraph_dict[class_name].add_node(node)\r\n\r\n        self._add_object(component)\r\n\r\n    def get_new_object_name(self, obj):\r\n        if \"id\" not in get_object_attributes(obj):\r\n            if obj.__class__.__name__ not in self.object_counter_dict:\r\n                self.object_counter_dict[obj.__class__.__name__] = 0\r\n            name = f\"{obj.__class__.__name__.lower()} {str(self.object_counter_dict[obj.__class__.__name__])}\"# [{id(obj)}]\"\r\n            self.object_counter_dict[obj.__class__.__name__] += 1\r\n        else:\r\n            name = obj.id\r\n        return name\r\n\r\n    def make_pickable(self):\r\n        \"\"\"\r\n        This method is responsible to remove all references to unpickable objects for the Model instance.\r\n        This prepares the Model instance to be used with multiprocessing in the Estimator class.\r\n        \"\"\"\r\n        self.object_dict = {} \r\n        self.object_dict_reversed = {}\r\n        fmu_components = self.get_component_by_class(self.component_dict, FMUComponent)\r\n        for fmu_component in fmu_components:\r\n            if \"fmu\" in get_object_attributes(fmu_component):\r\n                del fmu_component.fmu\r\n                del fmu_component.fmu_initial_state\r\n                fmu_component.INITIALIZED = False\r\n        # print(\"====================\")\r\n        # for com in self.component_dict.values():\r\n        #     print(\"-----\")\r\n        #     print(\"id: \", com.id)\r\n        #     print(get_object_attributes(com))\r\n\r\n    def _add_object(self, obj):\r\n        if obj in self.component_dict.values() or obj in self.component_base_dict.values():\r\n            name = obj.id\r\n            self.object_dict[name] = obj\r\n            self.object_dict_reversed[obj] = name\r\n        elif obj not in self.object_dict_reversed:\r\n            name = self.get_new_object_name(obj)\r\n            self.object_dict[name] = obj\r\n            self.object_dict_reversed[obj] = name\r\n        # else:\r\n        #     warnings.warn(f\"Cannot add object with id \\\"{self.object_dict_reversed[obj]}\\\" as it already exists in model. Skipping component.\")\r\n            \r\n\r\n    def remove_component(self, component):\r\n        for connection in component.connectedThrough:\r\n            connection.connectsSystem.remove(connection)\r\n\r\n        for connection_point in component.connectsAt:\r\n            connection_point.connectPointOf = None\r\n        del self.component_dict[component.id]\r\n\r\n    def get_edge_label(self, sender_property_name, receiver_property_name):\r\n        end_space = \"          \"\r\n        edge_label = (\"Out: \" + sender_property_name.split(\"_\")[0] + end_space + \"\\n\"\r\n                        \"In: \" + receiver_property_name.split(\"_\")[0] + end_space)\r\n        return edge_label\r\n\r\n\r\n    def add_connection(self, sender_component, receiver_component, sender_property_name, receiver_property_name):\r\n        '''\r\n            It that adds a connection between two components in a system. \r\n            It creates a Connection object between the sender and receiver components, \r\n            updates their respective lists of connected components, and adds a ConnectionPoint object \r\n            to the receiver component's list of connection points. The function also validates that the output/input \r\n            property names are valid for their respective components, and updates their dictionaries of inputs/outputs \r\n            accordingly. Finally, it adds a labeled edge between the two components in a system graph, and adds the components \r\n            as nodes in their respective subgraphs.\r\n        '''\r\n\r\n        logger.info(\"[Model Class] : Entered in Add Connection Function\")\r\n\r\n        # print(\"==============================\")\r\n        # print(\"Adding connection between: \", sender_component.id, \" and \", receiver_component.id)\r\n        # print(\"==============================\")\r\n\r\n        self._add_component(sender_component)\r\n        self._add_component(receiver_component)\r\n\r\n        sender_obj_connection = Connection(connectsSystem=sender_component, senderPropertyName=sender_property_name)\r\n        sender_component.connectedThrough.append(sender_obj_connection)\r\n        receiver_component_connection_point = ConnectionPoint(connectionPointOf=receiver_component, connectsSystemThrough=sender_obj_connection, receiverPropertyName=receiver_property_name)\r\n        sender_obj_connection.connectsSystemAt = receiver_component_connection_point\r\n        receiver_component.connectsAt.append(receiver_component_connection_point)\r\n\r\n        exception_classes = (components.TimeSeriesInputSystem, components.FlowJunctionSystem, components.PiecewiseLinearSystem, components.PiecewiseLinearSupplyWaterTemperatureSystem, components.PiecewiseLinearScheduleSystem, base.Sensor, base.Meter) # These classes are exceptions because their inputs and outputs can take any form \r\n        if isinstance(sender_component, exception_classes):\r\n            sender_component.output.update({sender_property_name: None})\r\n        else:\r\n            message = f\"The property \\\"{sender_property_name}\\\" is not a valid output for the component \\\"{sender_component.id}\\\" of type \\\"{type(sender_component)}\\\".\\nThe valid output properties are: {','.join(list(sender_component.output.keys()))}\"\r\n            assert sender_property_name in (set(sender_component.input.keys()) | set(sender_component.output.keys())), message\r\n        \r\n        if isinstance(receiver_component, exception_classes):\r\n            receiver_component.input.update({receiver_property_name: None})\r\n        else:\r\n            message = f\"The property \\\"{receiver_property_name}\\\" is not a valid input for the component \\\"{receiver_component.id}\\\" of type \\\"{type(receiver_component)}\\\".\\nThe valid input properties are: {','.join(list(receiver_component.input.keys()))}\"\r\n            assert receiver_property_name in receiver_component.input.keys(), message\r\n\r\n        \r\n\r\n        self._add_graph_relation(graph=self.system_graph, sender_component=sender_component, receiver_component=receiver_component, sender_property_name=sender_property_name, receiver_property_name=receiver_property_name)\r\n        # class_name = type(sender_component).__name__\r\n        # if class_name not in self.system_subgraph_dict:\r\n        #     self.system_subgraph_dict[class_name] = pydot.Subgraph(rank=self.system_graph_rank)\r\n        # class_name = type(receiver_component).__name__\r\n        # if class_name not in self.system_subgraph_dict:\r\n        #     self.system_subgraph_dict[class_name] = pydot.Subgraph(rank=self.system_graph_rank)\r\n\r\n        # self._add_edge(self.system_graph, sender_component.id, receiver_component.id, label=edge_label) ###\r\n        # cond1 = not self.system_subgraph_dict[type(sender_component).__name__].get_node(sender_component.id)\r\n        # cond2 = not self.system_subgraph_dict[type(sender_component).__name__].get_node(\"\\\"\"+ sender_component.id +\"\\\"\")\r\n        # if cond1 and cond2:\r\n        #     node = pydot.Node(sender_component.id)\r\n        #     self.system_subgraph_dict[type(sender_component).__name__].add_node(node)\r\n        # cond1 = not self.system_subgraph_dict[type(receiver_component).__name__].get_node(receiver_component.id)\r\n        # cond2 = not self.system_subgraph_dict[type(receiver_component).__name__].get_node(\"\\\"\"+ receiver_component.id +\"\\\"\")\r\n        # if cond1 and cond2:\r\n        #     node = pydot.Node(receiver_component.id)\r\n        #     self.system_subgraph_dict[type(receiver_component).__name__].add_node(node)\r\n        # # self.system_graph_node_attribute_dict[sender_obj.id] = {\"label\": sender_obj.__class__.__name__.replace(\"Model\",\"\")}\r\n        # # self.system_graph_node_attribute_dict[receiver_component.id] = {\"label\": receiver_component.__class__.__name__.replace(\"Model\",\"\")}\r\n        # self.system_graph_node_attribute_dict[sender_component.id] = {\"label\": sender_component.id}\r\n        # self.system_graph_node_attribute_dict[receiver_component.id] = {\"label\": receiver_component.id}\r\n        logger.info(\"[Model Class] : Exited from Add Connection Function\")\r\n\r\n    def _add_graph_relation(self, graph, sender_component, receiver_component, sender_property_name=None, receiver_property_name=None, edge_kwargs=None, sender_node_kwargs=None, receiver_node_kwargs=None):\r\n        if sender_node_kwargs is None:\r\n            sender_node_kwargs = {}\r\n\r\n        if receiver_node_kwargs is None:\r\n            receiver_node_kwargs = {}\r\n\r\n\r\n        if graph is self.system_graph:\r\n            rank = self.system_graph_rank\r\n            subgraph_dict = self.system_subgraph_dict\r\n            graph_node_attribute_dict = self.system_graph_node_attribute_dict\r\n            graph_edge_label_dict = self.system_graph_edge_label_dict\r\n        elif graph is self.object_graph:\r\n            rank = self.object_graph_rank\r\n            subgraph_dict = self.object_subgraph_dict\r\n            graph_node_attribute_dict = self.object_graph_node_attribute_dict\r\n            graph_edge_label_dict = self.object_graph_edge_label_dict\r\n        else:\r\n            if isinstance(graph, pydot.Dot):\r\n                raise ValueError(\"Unknown graph object. Currently implemented graph objects are \\\"self.system_graph\\\" and \\\"self.object_graph\\\"\")\r\n            else:\r\n                raise TypeError(f\"The supplied \\\"graph\\\" argument must be of type \\\"{pydot.Dot.__name__}\\\"\")\r\n        \r\n        \r\n        \r\n        if sender_component not in self.component_dict.values():\r\n            self._add_object(sender_component)\r\n\r\n        if receiver_component not in self.component_dict.values():\r\n            self._add_object(receiver_component)\r\n\r\n        \r\n\r\n        sender_class_name = sender_component.__class__\r\n        receiver_class_name = receiver_component.__class__\r\n        if sender_class_name not in subgraph_dict:\r\n            subgraph_dict[sender_class_name] = pydot.Subgraph(rank=rank)\r\n            graph.add_subgraph(subgraph_dict[sender_class_name])\r\n        \r\n        if receiver_class_name not in subgraph_dict:\r\n            subgraph_dict[receiver_class_name] = pydot.Subgraph(rank=rank)\r\n            graph.add_subgraph(subgraph_dict[receiver_class_name])\r\n        \r\n        sender_component_name = self.object_dict_reversed[sender_component]\r\n        receiver_component_name = self.object_dict_reversed[receiver_component]\r\n        self._add_edge(graph, sender_component_name, receiver_component_name, sender_property_name, receiver_property_name, edge_kwargs) ###\r\n        \r\n        cond1 = not subgraph_dict[sender_class_name].get_node(sender_component_name)\r\n        cond2 = not subgraph_dict[sender_class_name].get_node(\"\\\"\"+ sender_component_name +\"\\\"\")\r\n        if cond1 and cond2:\r\n            node = pydot.Node(sender_component_name)\r\n            subgraph_dict[sender_class_name].add_node(node)\r\n        \r\n        cond1 = not subgraph_dict[receiver_class_name].get_node(receiver_component_name)\r\n        cond2 = not subgraph_dict[receiver_class_name].get_node(\"\\\"\"+ receiver_component_name +\"\\\"\")\r\n        if cond1 and cond2:\r\n            node = pydot.Node(receiver_component_name)\r\n            subgraph_dict[receiver_class_name].add_node(node)\r\n\r\n\r\n        if \"label\" not in sender_node_kwargs:\r\n            sender_node_kwargs.update({\"label\": sender_component_name})\r\n            graph_node_attribute_dict[sender_component_name] = sender_node_kwargs\r\n        graph_node_attribute_dict[sender_component_name] = sender_node_kwargs\r\n\r\n        if \"label\" not in receiver_node_kwargs:\r\n            receiver_node_kwargs.update({\"label\": receiver_component_name})\r\n            graph_node_attribute_dict[receiver_component_name] = receiver_node_kwargs\r\n        graph_node_attribute_dict[receiver_component_name] = receiver_node_kwargs\r\n\r\n\r\n    def remove_connection(self, sender_component, receiver_component, sender_property_name, receiver_property_name):\r\n        \"\"\"\r\n        Deletes a connection between two components in a system\r\n        Updates the respective lists of connected components and deletes the ConnectionPoint objects from the receiver component's list of connection points\r\n        It also updates the dictionaries of inputs/outputs for the sender and receiver components accordingly\r\n        Finally, it deletes the labeled edge between the two components in the system graph\r\n        \"\"\"\r\n        logger.info(\"[Model Class] : Entered in Remove Connection Function\")\r\n\r\n        #print(\"==============================\")\r\n        #print(\"Removing connection between: \", sender_component.id, \" and \", receiver_component.id)\r\n        #print(\"==============================\")\r\n\r\n        sender_obj_connection = None\r\n        for connection in sender_component.connectedThrough:\r\n            if connection.senderPropertyName == sender_property_name:\r\n                sender_obj_connection = connection\r\n                break\r\n        if sender_obj_connection is None:\r\n            raise ValueError(f\"The sender component \\\"{sender_component.id}\\\" does not have a connection with the property \\\"{sender_property_name}\\\"\")\r\n        sender_component.connectedThrough.remove(sender_obj_connection)\r\n\r\n        receiver_component_connection_point = None\r\n        for connection_point in receiver_component.connectsAt:\r\n            if connection_point.receiverPropertyName == receiver_property_name:\r\n                receiver_component_connection_point = connection_point\r\n                break\r\n        if receiver_component_connection_point is None:\r\n            raise ValueError(f\"The receiver component \\\"{receiver_component.id}\\\" does not have a connection point with the property \\\"{receiver_property_name}\\\"\")\r\n        receiver_component.connectsAt.remove(receiver_component_connection_point)\r\n\r\n        del sender_obj_connection\r\n        del receiver_component_connection_point\r\n        \r\n        self._del_edge(self.system_graph, sender_component.id, receiver_component.id, self.get_edge_label(sender_property_name, receiver_property_name))\r\n\r\n        #Exception classes \r\n        exception_classes = (components.TimeSeriesInputSystem, components.FlowJunctionSystem, components.PiecewiseLinearSystem, components.PiecewiseLinearSupplyWaterTemperatureSystem, components.PiecewiseLinearScheduleSystem, base.Sensor, base.Meter) # These classes are exceptions because their inputs and outputs can take any form\r\n\r\n        if isinstance(sender_component, exception_classes):\r\n            del sender_component.output[sender_property_name]\r\n\r\n        if isinstance(receiver_component, exception_classes):\r\n            del receiver_component.input[receiver_property_name]\r\n        \r\n        logger.info(\"[Model Class] : Exited from Remove Connection Function\")\r\n    \r\n    def add_outdoor_environment(self, filename=None):\r\n        outdoor_environment = base.OutdoorEnvironment(\r\n            filename=filename,\r\n            saveSimulationResult = self.saveSimulationResult,\r\n            id = \"outdoor_environment\")\r\n        self.component_base_dict[\"outdoor_environment\"] = outdoor_environment\r\n        # self._add_component(outdoor_environment)\r\n\r\n    def add_outdoor_environment_system(self, filename=None):\r\n        outdoor_environment = components.OutdoorEnvironmentSystem(\r\n            filename=filename,\r\n            saveSimulationResult = self.saveSimulationResult,\r\n            id = \"outdoor_environment\")\r\n        self._add_component(outdoor_environment)\r\n\r\n    # def add_supply_air_temperature_setpoint_schedule_from_csv(self, ventilation_id=None):\r\n    #     logger.info(\"[Model Class] : Entered in add_supply_air_temperature_setpoint_schedule Function\")\r\n    #     stepSize = 600\r\n    #     startTime = datetime.datetime(year=2021, month=12, day=10, hour=0, minute=0, second=0) #piecewise 20.5-23\r\n    #     endTime = datetime.datetime(year=2022, month=2, day=15, hour=0, minute=0, second=0) #piecewise 20.5-23\r\n\r\n\r\n    #     # startTime = datetime.datetime(year=2022, month=10, day=28, hour=0, minute=0, second=0) #Constant 19\r\n    #     # endTime = datetime.datetime(year=2022, month=12, day=23, hour=0, minute=0, second=0) #Constant 19\r\n    #     # startTime = datetime.datetime(year=2022, month=2, day=16, hour=0, minute=0, second=0) ##Commissioning piecewise 20-23\r\n    #     # endTime = datetime.datetime(year=2022, month=10, day=26, hour=0, minute=0, second=0) ##Commissioning piecewise 20-23\r\n    #     date_format = \"%m/%d/%Y %I:%M:%S %p\"\r\n    #     filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 2)), \"test\", \"data\", \"time_series_data\", \"VE02_FTU1.csv\")\r\n    #     VE02_FTU1 = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, date_format=date_format, dt_limit=9999)\r\n    #     # VE02_FTU1[\"FTU1\"] = (VE02_FTU1[\"FTU1\"]-32)*5/9 #convert from fahrenheit to celcius\r\n    #     filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 2)), \"test\", \"data\", \"time_series_data\", \"VE02_FTI_KALK_SV.csv\")\r\n    #     VE02_FTI_KALK_SV = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, date_format=date_format, dt_limit=9999)\r\n    #     # VE02_FTI_KALK_SV[\"FTI_KALK_SV\"] = (VE02_FTI_KALK_SV[\"FTI_KALK_SV\"]-32)*5/9 #convert from fahrenheit to celcius\r\n    #     input = pd.DataFrame()\r\n    #     input.insert(0, \"FTU1\", VE02_FTU1[\"FTU1\"])\r\n    #     input.insert(0, \"FTI_KALK_SV\", VE02_FTI_KALK_SV[\"FTI_KALK_SV\"])\r\n    #     input.insert(0, \"time\", VE02_FTI_KALK_SV[\"Time stamp\"])\r\n    #     input = input.replace([np.inf, -np.inf], np.nan).dropna()\r\n    #     output = input[\"FTI_KALK_SV\"]\r\n    #     input.drop(columns=[\"time\", \"FTI_KALK_SV\"], inplace=True)\r\n    #     if ventilation_id is not None:\r\n    #         supply_air_temperature_setpoint_schedule = components.PiecewiseLinearSystem(id=f\"{ventilation_id} Supply air temperature setpoint\", saveSimulationResult = self.saveSimulationResult)\r\n    #     else:\r\n    #         supply_air_temperature_setpoint_schedule = components.PiecewiseLinearSystem(id=f\"Supply air temperature setpoint\", saveSimulationResult = self.saveSimulationResult)\r\n    #     supply_air_temperature_setpoint_schedule.calibrate(input=input, output=output, n_line_segments=4)\r\n    #     self._add_component(supply_air_temperature_setpoint_schedule)\r\n    #     logger.info(\"[Model Class] : Exited from add_supply_air_temperature_setpoint_schedule Function\")\r\n\r\n\r\n    # def add_supply_water_temperature_setpoint_schedule_from_csv(self, heating_id=None):\r\n    #     logger.info(\"[Model Class] : Entered in Add Supply Water Temperature Setpoint ScheduleSystem Function\")\r\n\r\n    #     stepSize = 600\r\n    #     startTime = datetime.datetime(year=2022, month=12, day=6, hour=0, minute=0, second=0)\r\n    #     endTime = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0)\r\n    #     format = \"%m/%d/%Y %I:%M:%S %p\"\r\n    #     filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 2)), \"test\", \"data\", \"time_series_data\", \"weather_BMS.csv\")\r\n    #     weather_BMS = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=60)\r\n    #     # weather_BMS[\"outdoorTemperature\"] = (weather_BMS[\"outdoorTemperature\"]-32)*5/9 #convert from fahrenheit to celcius\r\n    #     filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 2)), \"test\", \"data\", \"time_series_data\", \"VA01_FTF1_SV.csv\")\r\n    #     VA01_FTF1_SV = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=999999)\r\n    #     # VA01[\"FTF1_SV\"] = (VA01[\"FTF1_SV\"]-32)*5/9 #convert from fahrenheit to celcius\r\n\r\n    #     # filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 2)), \"test\", \"data\", \"time_series_data\", \"VA01.csv\")\r\n    #     # VA01_FTF1_SV = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=999999)\r\n    #     # VA01_FTF1_SV[\"FTF1_SV\"] = (VA01_FTF1_SV[\"FTF1\"]-32)*5/9 #convert from fahrenheit to celcius\r\n\r\n    #     input = {\"normal\": pd.DataFrame(), \"boost\": pd.DataFrame()}\r\n    #     output = {\"normal\": None, \"boost\": None}\r\n    #     input[\"normal\"].insert(0, \"outdoorTemperature\", weather_BMS[\"outdoorTemperature\"])\r\n    #     input[\"normal\"].insert(0, \"FTF1_SV\", VA01_FTF1_SV[\"FTF1_SV\"])\r\n    #     input[\"normal\"].insert(0, \"time\", weather_BMS[\"Time stamp\"])\r\n    #     input[\"normal\"][(input[\"normal\"][\"time\"].dt.hour < 10) & (input[\"normal\"][\"time\"].dt.hour > 3)] = np.nan # exclude boost function, which is typically active in the excluded hours\r\n    #     input[\"normal\"] = input[\"normal\"].replace([np.inf, -np.inf], np.nan).dropna()#.reset_index()\r\n    #     output[\"normal\"] = input[\"normal\"][\"FTF1_SV\"]\r\n    #     input[\"normal\"].drop(columns=[\"time\", \"FTF1_SV\"], inplace=True)\r\n    #     input[\"boost\"].insert(0, \"outdoorTemperature\", weather_BMS[\"outdoorTemperature\"])\r\n    #     input[\"boost\"].insert(0, \"FTF1_SV\", VA01_FTF1_SV[\"FTF1_SV\"])\r\n    #     input[\"boost\"].insert(0, \"time\", weather_BMS[\"Time stamp\"])\r\n\r\n    #     if heating_id is not None:\r\n    #         id = f\"{heating_id} Supply water temperature setpoint\"\r\n    #     else:\r\n    #         id = f\"Supply water temperature setpoint\"\r\n\r\n\r\n    #     supply_water_temperature_setpoint_schedule = components.PiecewiseLinearSystem(id=id, saveSimulationResult=self.saveSimulationResult)\r\n    #     supply_water_temperature_setpoint_schedule.calibrate(input=input[\"normal\"], output=output[\"normal\"], n_line_segments=2)\r\n\r\n    #     points = supply_water_temperature_setpoint_schedule.model.predict(input[\"boost\"][\"outdoorTemperature\"])\r\n    #     tol = 0.2 #degrees\r\n    #     input[\"boost\"][(input[\"boost\"][\"FTF1_SV\"]-points).abs()<=tol] = np.nan\r\n    #     input[\"boost\"] = input[\"boost\"].replace([np.inf, -np.inf], np.nan).dropna()#.reset_index()\r\n    #     output[\"boost\"] = input[\"boost\"][\"FTF1_SV\"]\r\n    #     input[\"boost\"].drop(columns=[\"time\", \"FTF1_SV\"], inplace=True)\r\n\r\n    #     import matplotlib.pyplot as plt\r\n    #     fig,ax = plt.subplots()\r\n    #     fig.set_size_inches(7, 5/2)\r\n    #     ax.plot(input[\"normal\"][\"outdoorTemperature\"].sort_values(), supply_water_temperature_setpoint_schedule.model.predict(input[\"normal\"][\"outdoorTemperature\"].sort_values()), color=\"blue\")\r\n    #     ax.scatter(input[\"normal\"][\"outdoorTemperature\"], output[\"normal\"], color=\"red\", s=1)\r\n\r\n    #     n_line_segments = {\"normal\": 2, \"boost\": 2}\r\n    #     supply_water_temperature_setpoint_schedule = components.PiecewiseLinearSupplyWaterTemperatureSystem(id=id, saveSimulationResult = self.saveSimulationResult)\r\n    #     supply_water_temperature_setpoint_schedule.calibrate(input=input, output=output, n_line_segments=n_line_segments)\r\n    #     # Sort out outliers\r\n    #     points = supply_water_temperature_setpoint_schedule.model[\"boost\"].predict(input[\"boost\"][\"outdoorTemperature\"])\r\n    #     tol = 0.5 #degrees\r\n    #     input[\"boost\"][(output[\"boost\"]-points).abs()>=tol] = np.nan\r\n    #     input[\"boost\"] = input[\"boost\"].replace([np.inf, -np.inf], np.nan).dropna()#.reset_index()\r\n    #     output[\"boost\"][(output[\"boost\"]-points).abs()>=tol] = np.nan\r\n    #     output[\"boost\"] = output[\"boost\"].replace([np.inf, -np.inf], np.nan).dropna()#.reset_index()\r\n    #     supply_water_temperature_setpoint_schedule.calibrate(input=input, output=output, n_line_segments=n_line_segments)\r\n    #     self._add_component(supply_water_temperature_setpoint_schedule)\r\n\r\n    #     ax.plot(input[\"boost\"][\"outdoorTemperature\"].sort_values(), supply_water_temperature_setpoint_schedule.model[\"boost\"].predict(input[\"boost\"][\"outdoorTemperature\"].sort_values()), color=\"yellow\")\r\n    #     ax.scatter(input[\"boost\"][\"outdoorTemperature\"], output[\"boost\"], color=\"red\", s=1)\r\n    #     logger.info(\"[Model Class] : Exited from Add Supply Water Temperature Setpoint ScheduleSystem Function\")\r\n\r\n    def read_config_from_fiware(self):\r\n        fr = fiwareReader()\r\n        fr.read_config_from_fiware()\r\n        self.system_dict = fr.system_dict\r\n        self.component_base_dict = fr.component_base_dict\r\n\r\n    def _instantiate_objects(self, df_dict):\r\n        \"\"\"\r\n        All components listed in the configuration file are instantiated with their id.\r\n\r\n        Arguments\r\n        df_dict: A dictionary of dataframes read from the configuration file with sheet names as keys and dataframes as values.  \r\n        \"\"\"\r\n        logger.info(\"[Model Class] : Entered in Intantiate Object Function\")\r\n        for ventilation_system_name in df_dict[\"System\"][\"Ventilation system name\"].dropna():\r\n            ventilation_system = base.DistributionDevice(id=ventilation_system_name)\r\n            self.system_dict[\"ventilation\"][ventilation_system_name] = ventilation_system\r\n        \r\n        for heating_system_name in df_dict[\"System\"][\"Heating system name\"].dropna():\r\n            heating_system = base.DistributionDevice(id=heating_system_name)\r\n            self.system_dict[\"heating\"][heating_system_name] = heating_system\r\n\r\n        for cooling_system_name in df_dict[\"System\"][\"Cooling system name\"].dropna():\r\n            cooling_system = base.DistributionDevice(id=cooling_system_name)\r\n            self.system_dict[\"cooling\"][cooling_system_name] = cooling_system\r\n\r\n        for row in df_dict[\"BuildingSpace\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            space_name = row[df_dict[\"BuildingSpace\"].columns.get_loc(\"id\")]\r\n            # try: \r\n            space = base.BuildingSpace(id=space_name)\r\n            self.component_base_dict[space_name] = space\r\n            # except NoSpaceModelException:\r\n            #     logger.error(\"No fitting space model for space \" + \"\\\"\" + space_name + \"\\\"\")\r\n            #     logger.error(\"Continuing...\")\r\n            \r\n        for row in df_dict[\"Damper\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            damper_name = row[df_dict[\"Damper\"].columns.get_loc(\"id\")]\r\n            damper = base.Damper(id=damper_name)\r\n            self.component_base_dict[damper_name] = damper\r\n            #Check that an appropriate space object exists\r\n            if row[df_dict[\"Damper\"].columns.get_loc(\"isContainedIn\")] not in self.component_base_dict:\r\n                warnings.warn(\"Cannot find a matching BuildingSpace object for damper \\\"\" + damper_name + \"\\\"\")                \r\n\r\n        for row in df_dict[\"SpaceHeater\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            space_heater_name = row[df_dict[\"SpaceHeater\"].columns.get_loc(\"id\")]\r\n            space_heater = base.SpaceHeater(id=space_heater_name)\r\n            self.component_base_dict[space_heater_name] = space_heater\r\n            #Check that an appropriate object exists\r\n            if row[df_dict[\"SpaceHeater\"].columns.get_loc(\"isContainedIn\")] not in self.component_base_dict:\r\n                warnings.warn(\"Cannot find a matching SpaceHeater object for space heater \\\"\" + space_heater_name + \"\\\"\")                \r\n\r\n        for row in df_dict[\"Valve\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            valve_name = row[df_dict[\"Valve\"].columns.get_loc(\"id\")]\r\n            valve = base.Valve(id=valve_name)\r\n            self.component_base_dict[valve_name] = valve\r\n            #Check that an appropriate object exists\r\n            if row[df_dict[\"Valve\"].columns.get_loc(\"isContainedIn\")] not in self.component_base_dict:\r\n                warnings.warn(\"Cannot find a matching Valve object for valve \\\"\" + valve_name + \"\\\"\")\r\n\r\n        for row in df_dict[\"Coil\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            coil_name = row[df_dict[\"Coil\"].columns.get_loc(\"id\")]\r\n            coil = base.Coil(id=coil_name)\r\n            self.component_base_dict[coil_name] = coil\r\n            \r\n        for row in df_dict[\"AirToAirHeatRecovery\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            air_to_air_heat_recovery_name = row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"id\")]\r\n            air_to_air_heat_recovery = base.AirToAirHeatRecovery(id=air_to_air_heat_recovery_name)\r\n            self.component_base_dict[air_to_air_heat_recovery_name] = air_to_air_heat_recovery\r\n\r\n        for row in df_dict[\"Fan\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            fan_name = row[df_dict[\"Fan\"].columns.get_loc(\"id\")]\r\n            fan = base.Fan(id=fan_name)\r\n            self.component_base_dict[fan_name] = fan\r\n\r\n        for row in df_dict[\"Controller\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            controller_name = row[df_dict[\"Controller\"].columns.get_loc(\"id\")]\r\n            controller = base.Controller(id=controller_name)\r\n            self.component_base_dict[controller_name] = controller\r\n\r\n        for row in df_dict[\"SetpointController\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            controller_name = row[df_dict[\"SetpointController\"].columns.get_loc(\"id\")]\r\n            controller = base.SetpointController(id=controller_name)\r\n            self.component_base_dict[controller_name] = controller\r\n\r\n        for row in df_dict[\"RulebasedController\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            controller_name = row[df_dict[\"RulebasedController\"].columns.get_loc(\"id\")]\r\n            controller = base.RulebasedController(id=controller_name)\r\n            self.component_base_dict[controller_name] = controller\r\n\r\n        for row in df_dict[\"Schedule\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            schedule_name = row[df_dict[\"Schedule\"].columns.get_loc(\"id\")]\r\n            schedule = base.Schedule(id=schedule_name)\r\n            self.component_base_dict[schedule_name] = schedule\r\n                \r\n        for row in df_dict[\"ShadingDevice\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            shading_device_name = row[df_dict[\"ShadingDevice\"].columns.get_loc(\"id\")]\r\n            shading_device = base.ShadingDevice(id=shading_device_name)\r\n            self.component_base_dict[shading_device_name] = shading_device            \r\n\r\n        for row in df_dict[\"Sensor\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            sensor_name = row[df_dict[\"Sensor\"].columns.get_loc(\"id\")]\r\n            sensor = base.Sensor(id=sensor_name)\r\n            self.component_base_dict[sensor_name] = sensor\r\n\r\n        for row in df_dict[\"Meter\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            meter_name = row[df_dict[\"Meter\"].columns.get_loc(\"id\")]\r\n            meter = base.Meter(id=meter_name)\r\n            self.component_base_dict[meter_name] = meter\r\n\r\n        for row in df_dict[\"Pump\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            pump_name = row[df_dict[\"Pump\"].columns.get_loc(\"id\")]\r\n            pump = base.Pump(id=pump_name)\r\n            self.component_base_dict[pump_name] = pump\r\n            \r\n        for row in df_dict[\"Property\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            property_name = row[df_dict[\"Property\"].columns.get_loc(\"id\")]\r\n            # Property = getattr(sys.modules[__name__], row[df_dict[\"Property\"].columns.get_loc(\"type\")])\r\n            Property = getattr(base, row[df_dict[\"Property\"].columns.get_loc(\"type\")])\r\n            property_ = Property()\r\n            self.property_dict[property_name] = property_\r\n\r\n        logger.info(\"[Model Class] : Exited from Intantiate Object Function\")\r\n\r\n    def _populate_objects(self, df_dict):\r\n        \"\"\"\r\n        All components listed in the configuration file are populated with data and connections are defined.\r\n\r\n        Arguments\r\n        df_dict: A dictionary of dataframes read from the configuration file with sheet names as keys and dataframes as values.  \r\n        \"\"\"\r\n        logger.info(\"[Model Class] : Entered in Populate Object Function\")\r\n        allowed_classes = (str, float, int)\r\n\r\n        for row in df_dict[\"BuildingSpace\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            space_name = row[df_dict[\"BuildingSpace\"].columns.get_loc(\"id\")]\r\n            space = self.component_base_dict[space_name]\r\n            if isinstance(row[df_dict[\"BuildingSpace\"].columns.get_loc(\"hasProperty\")], str):\r\n                properties = [self.property_dict[property_name] for property_name in row[df_dict[\"BuildingSpace\"].columns.get_loc(\"hasProperty\")].split(\";\")]\r\n                space.hasProperty.extend(properties)\r\n            else:\r\n                message = f\"Required property \\\"hasProperty\\\" not set for BuildingSpace object \\\"{space.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n\r\n            if \"connectedTo\" not in df_dict[\"BuildingSpace\"].columns:\r\n                warnings.warn(\"The property \\\"connectedTo\\\" is not found in \\\"BuildingSpace\\\" sheet. This is ignored for now but will raise an error in the future. It probably is caused by using an outdated configuration file.\")\r\n            elif isinstance(row[df_dict[\"BuildingSpace\"].columns.get_loc(\"connectedTo\")], str):\r\n                connected_to = row[df_dict[\"BuildingSpace\"].columns.get_loc(\"connectedTo\")].split(\";\")\r\n                connected_to = [self.component_base_dict[component_name] for component_name in connected_to]\r\n                space.connectedTo.extend(connected_to)\r\n            \r\n            if isinstance(row[df_dict[\"BuildingSpace\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"BuildingSpace\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                space.connectedAfter.extend(connected_after)\r\n\r\n\r\n            if \"hasProfile\" not in df_dict[\"BuildingSpace\"].columns:\r\n                warnings.warn(\"The property \\\"hasProfile\\\" is not found in \\\"BuildingSpace\\\" sheet. This is ignored for now but will raise an error in the future. It probably is caused by using an outdated configuration file.\")\r\n            elif isinstance(row[df_dict[\"BuildingSpace\"].columns.get_loc(\"hasProfile\")], str):\r\n                schedule_name = row[df_dict[\"BuildingSpace\"].columns.get_loc(\"hasProfile\")]\r\n                space.hasProfile = self.component_base_dict[schedule_name]\r\n\r\n            space.airVolume = row[df_dict[\"BuildingSpace\"].columns.get_loc(\"airVolume\")]\r\n            \r\n        for row in df_dict[\"Damper\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            damper_name = row[df_dict[\"Damper\"].columns.get_loc(\"id\")]\r\n            damper = self.component_base_dict[damper_name]\r\n            systems = row[df_dict[\"Damper\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n            systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n            damper.subSystemOf.extend(systems)\r\n\r\n            if isinstance(row[df_dict[\"Damper\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"Damper\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                damper.connectedAfter.extend(connected_after)\r\n\r\n            if isinstance(row[df_dict[\"Damper\"].columns.get_loc(\"hasProperty\")], str):\r\n                properties = [self.property_dict[property_name] for property_name in row[df_dict[\"Damper\"].columns.get_loc(\"hasProperty\")].split(\";\")]\r\n                damper.hasProperty.extend(properties)\r\n            else:\r\n                message = f\"Required property \\\"hasProperty\\\" not set for Damper object \\\"{damper.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            \r\n            damper.isContainedIn = self.component_base_dict[row[df_dict[\"Damper\"].columns.get_loc(\"isContainedIn\")]]\r\n            rsetattr(damper, \"nominalAirFlowRate.hasValue\", row[df_dict[\"Damper\"].columns.get_loc(\"nominalAirFlowRate\")])\r\n            # damper.nominalAirFlowRate = base.PropertyValue(hasValue=row[df_dict[\"Damper\"].columns.get_loc(\"nominalAirFlowRate\")])\r\n            \r\n        for row in df_dict[\"SpaceHeater\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            space_heater_name = row[df_dict[\"SpaceHeater\"].columns.get_loc(\"id\")]\r\n            space_heater = self.component_base_dict[space_heater_name]\r\n\r\n            if isinstance(row[df_dict[\"SpaceHeater\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"SpaceHeater\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n                space_heater.subSystemOf.extend(systems)\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for SpaceHeater object \\\"{space_heater.id}\\\"\"\r\n                raise(ValueError(message))\r\n\r\n            if isinstance(row[df_dict[\"SpaceHeater\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"SpaceHeater\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                space_heater.connectedAfter.extend(connected_after)\r\n            else:\r\n                message = f\"Required property \\\"connectedAfter\\\" not set for SpaceHeater object \\\"{space_heater.id}\\\"\"\r\n                raise(ValueError(message))\r\n\r\n            properties = [self.property_dict[property_name] for property_name in row[df_dict[\"SpaceHeater\"].columns.get_loc(\"hasProperty\")].split(\";\")]\r\n            space_heater.hasProperty.extend(properties)\r\n            \r\n            space_heater.isContainedIn = self.component_base_dict[row[df_dict[\"SpaceHeater\"].columns.get_loc(\"isContainedIn\")]]\r\n            rsetattr(space_heater, \"outputCapacity.hasValue\", row[df_dict[\"SpaceHeater\"].columns.get_loc(\"outputCapacity\")])\r\n            # space_heater.outputCapacity = base.PropertyValue(hasValue=row[df_dict[\"SpaceHeater\"].columns.get_loc(\"outputCapacity\")])\r\n\r\n            if isinstance(row[df_dict[\"SpaceHeater\"].columns.get_loc(\"temperatureClassification\")], str):\r\n                # space_heater.temperatureClassification = row[df_dict[\"SpaceHeater\"].columns.get_loc(\"temperatureClassification\")]\r\n                rsetattr(space_heater, \"temperatureClassification.hasValue\", row[df_dict[\"SpaceHeater\"].columns.get_loc(\"temperatureClassification\")])\r\n            else:\r\n                message = f\"Required property \\\"temperatureClassification\\\" not set for SpaceHeater object \\\"{space_heater.id}\\\"\"\r\n                raise(ValueError(message))\r\n\r\n            # space_heater.thermalMassHeatCapacity = base.PropertyValue(hasValue=row[df_dict[\"SpaceHeater\"].columns.get_loc(\"thermalMassHeatCapacity\")])\r\n            rsetattr(space_heater, \"thermalMassHeatCapacity.hasValue\", row[df_dict[\"SpaceHeater\"].columns.get_loc(\"thermalMassHeatCapacity\")])\r\n\r\n        for row in df_dict[\"Valve\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            valve_name = row[df_dict[\"Valve\"].columns.get_loc(\"id\")]\r\n            valve = self.component_base_dict[valve_name]\r\n\r\n            if isinstance(row[df_dict[\"Valve\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"Valve\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n                valve.subSystemOf.extend(systems)\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for Valve object \\\"{valve.id}\\\"\"\r\n                raise(ValueError(message))\r\n\r\n            if isinstance(row[df_dict[\"Valve\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"Valve\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                valve.connectedAfter.extend(connected_after)\r\n\r\n            if isinstance(row[df_dict[\"Valve\"].columns.get_loc(\"hasProperty\")], str):\r\n                properties = [self.property_dict[property_name] for property_name in row[df_dict[\"Valve\"].columns.get_loc(\"hasProperty\")].split(\";\")]\r\n                valve.hasProperty.extend(properties)\r\n\r\n            if isinstance(row[df_dict[\"Valve\"].columns.get_loc(\"isContainedIn\")], str):\r\n                valve.isContainedIn = self.component_base_dict[row[df_dict[\"Valve\"].columns.get_loc(\"isContainedIn\")]]\r\n            \r\n            \r\n            if isinstance(row[df_dict[\"Valve\"].columns.get_loc(\"flowCoefficient\")], float) and np.isnan(row[df_dict[\"Valve\"].columns.get_loc(\"flowCoefficient\")])==False:\r\n                # valve.flowCoefficient = base.PropertyValue(hasValue=row[df_dict[\"Valve\"].columns.get_loc(\"flowCoefficient\")])\r\n                rsetattr(valve, \"flowCoefficient.hasValue\", row[df_dict[\"Valve\"].columns.get_loc(\"flowCoefficient\")])\r\n            \r\n            if isinstance(row[df_dict[\"Valve\"].columns.get_loc(\"testPressure\")], float) and np.isnan(row[df_dict[\"Valve\"].columns.get_loc(\"testPressure\")])==False:\r\n                # valve.testPressure = base.PropertyValue(hasValue=row[df_dict[\"Valve\"].columns.get_loc(\"testPressure\")])\r\n                rsetattr(valve, \"testPressure.hasValue\", row[df_dict[\"Valve\"].columns.get_loc(\"testPressure\")])\r\n\r\n        for row in df_dict[\"Coil\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            coil_name = row[df_dict[\"Coil\"].columns.get_loc(\"id\")]\r\n            coil = self.component_base_dict[coil_name]\r\n\r\n            if isinstance(row[df_dict[\"Coil\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"Coil\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n                has_ventilation_system = any([system in self.system_dict[\"ventilation\"].values() for system in systems])\r\n                has_heating_system = any([system in self.system_dict[\"heating\"].values() for system in systems])\r\n                has_cooling_system = any([system in self.system_dict[\"cooling\"].values() for system in systems])\r\n                assert has_ventilation_system and (has_heating_system or has_cooling_system), f\"Required property \\\"subSystemOf\\\" must contain both a Ventilation system and either a Heating or Cooling system for Coil object \\\"{coil.id}\\\"\"\r\n                coil.subSystemOf.extend(systems)\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for Coil object \\\"{coil.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            if isinstance(row[df_dict[\"Coil\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"Coil\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                coil.connectedAfter.extend(connected_after)\r\n\r\n            if isinstance(row[df_dict[\"Coil\"].columns.get_loc(\"hasProperty\")], str):\r\n                properties = [self.property_dict[property_name] for property_name in row[df_dict[\"Coil\"].columns.get_loc(\"hasProperty\")].split(\";\")]\r\n                coil.hasProperty.extend(properties)\r\n            \r\n        for row in df_dict[\"AirToAirHeatRecovery\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            air_to_air_heat_recovery_name = row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"id\")]\r\n            air_to_air_heat_recovery = self.component_base_dict[air_to_air_heat_recovery_name]\r\n            systems = row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n            systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n            air_to_air_heat_recovery.subSystemOf = systems\r\n\r\n            if isinstance(row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                air_to_air_heat_recovery.connectedAfter = connected_after\r\n            else:\r\n                message = f\"Required property \\\"connectedAfter\\\" not set for AirToAirHeatRecovery object \\\"{air_to_air_heat_recovery.id}\\\"\"\r\n                raise(ValueError(message))\r\n            properties = [self.property_dict[property_name] for property_name in row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"hasProperty\")].split(\";\")]\r\n            air_to_air_heat_recovery.hasProperty.extend(properties)\r\n            rsetattr(air_to_air_heat_recovery, \"primaryAirFlowRateMax.hasValue\", row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"primaryAirFlowRateMax\")])\r\n            rsetattr(air_to_air_heat_recovery, \"secondaryAirFlowRateMax.hasValue\", row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"secondaryAirFlowRateMax\")])\r\n            # air_to_air_heat_recovery.primaryAirFlowRateMax = base.PropertyValue(hasValue=row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"primaryAirFlowRateMax\")])\r\n            # air_to_air_heat_recovery.secondaryAirFlowRateMax = base.PropertyValue(hasValue=row[df_dict[\"AirToAirHeatRecovery\"].columns.get_loc(\"secondaryAirFlowRateMax\")])\r\n\r\n        for row in df_dict[\"Fan\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            fan_name = row[df_dict[\"Fan\"].columns.get_loc(\"id\")]\r\n            fan = self.component_base_dict[fan_name]\r\n\r\n            if isinstance(row[df_dict[\"Fan\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"Fan\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n                fan.subSystemOf.extend(systems)\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for fan object \\\"{fan.id}\\\"\"\r\n                raise(ValueError(message))\r\n\r\n            if isinstance(row[df_dict[\"Fan\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"Fan\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                fan.connectedAfter.extend(connected_after)\r\n            # else:\r\n            #     message = f\"Required property \\\"connectedAfter\\\" not set for fan object \\\"{fan.id}\\\"\"\r\n            #     raise(ValueError(message))\r\n            \r\n            if isinstance(row[df_dict[\"Fan\"].columns.get_loc(\"hasProperty\")], str):\r\n                properties = [self.property_dict[property_name] for property_name in row[df_dict[\"Fan\"].columns.get_loc(\"hasProperty\")].split(\";\")]\r\n                fan.hasProperty.extend(properties)\r\n            # else:\r\n            #     message = f\"Required property \\\"hasProperty\\\" not set for fan object \\\"{fan.id}\\\"\"\r\n            #     raise(ValueError(message))\r\n            # fan.nominalAirFlowRate = base.PropertyValue(hasValue=row[df_dict[\"Fan\"].columns.get_loc(\"nominalAirFlowRate\")])\r\n            # fan.nominalPowerRate = base.PropertyValue(hasValue=row[df_dict[\"Fan\"].columns.get_loc(\"nominalPowerRate\")])\r\n            rsetattr(fan, \"nominalAirFlowRate.hasValue\", row[df_dict[\"Fan\"].columns.get_loc(\"nominalAirFlowRate\")])\r\n            rsetattr(fan, \"nominalPowerRate.hasValue\", row[df_dict[\"Fan\"].columns.get_loc(\"nominalPowerRate\")])\r\n\r\n            \r\n        for row in df_dict[\"Controller\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            controller_name = row[df_dict[\"Controller\"].columns.get_loc(\"id\")]\r\n            controller = self.component_base_dict[controller_name]\r\n\r\n            if isinstance(row[df_dict[\"Controller\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"Controller\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for controller object \\\"{controller.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            controller.subSystemOf.extend(systems)\r\n\r\n            if isinstance(row[df_dict[\"Controller\"].columns.get_loc(\"isContainedIn\")], str):\r\n                controller.isContainedIn = self.component_base_dict[row[df_dict[\"Controller\"].columns.get_loc(\"isContainedIn\")]]\r\n            \r\n            # _property = self.property_dict[row[df_dict[\"Controller\"].columns.get_loc(\"observes\")]]\r\n            # controller.observes = _property\r\n\r\n            _property = self.property_dict[row[df_dict[\"Controller\"].columns.get_loc(\"observes\")]]\r\n            controller.observes = _property\r\n\r\n\r\n            if \"controls\" not in df_dict[\"Controller\"].columns:\r\n                warnings.warn(\"The property \\\"controls\\\" is not found in \\\"Controller\\\" sheet. This is ignored for now but will raise an error in the future. It probably is caused by using an outdated configuration file.\")\r\n            else:\r\n                if isinstance(row[df_dict[\"Controller\"].columns.get_loc(\"controls\")], str):\r\n                    controls = row[df_dict[\"Controller\"].columns.get_loc(\"controls\")].split(\";\")\r\n                    controls = [self.property_dict[component_name] for component_name in controls]\r\n                    controller.controls.extend(controls)\r\n                else:\r\n                    message = f\"Required property \\\"controls\\\" not set for controller object \\\"{controller.id}\\\"\"\r\n                    raise(ValueError(message))\r\n\r\n        for row in df_dict[\"SetpointController\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            controller_name = row[df_dict[\"SetpointController\"].columns.get_loc(\"id\")]\r\n            controller = self.component_base_dict[controller_name]\r\n\r\n            if isinstance(row[df_dict[\"SetpointController\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"SetpointController\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for controller object \\\"{controller.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            controller.subSystemOf.extend(systems)\r\n\r\n            if isinstance(row[df_dict[\"SetpointController\"].columns.get_loc(\"isContainedIn\")], str):\r\n                controller.isContainedIn = self.component_base_dict[row[df_dict[\"SetpointController\"].columns.get_loc(\"isContainedIn\")]]\r\n            \r\n            _property = self.property_dict[row[df_dict[\"SetpointController\"].columns.get_loc(\"observes\")]]\r\n            controller.observes = _property\r\n\r\n\r\n            if \"controls\" not in df_dict[\"SetpointController\"].columns:\r\n                warnings.warn(\"The property \\\"controls\\\" is not found in \\\"SetpointController\\\" sheet. This is ignored for now but will raise an error in the future. It probably is caused by using an outdated configuration file.\")\r\n            else:\r\n                if isinstance(row[df_dict[\"SetpointController\"].columns.get_loc(\"controls\")], str):\r\n                    controls = row[df_dict[\"SetpointController\"].columns.get_loc(\"controls\")].split(\";\")\r\n                    controls = [self.property_dict[component_name] for component_name in controls]\r\n                    controller.controls.extend(controls)\r\n                else:\r\n                    message = f\"Required property \\\"controls\\\" not set for controller object \\\"{controller.id}\\\"\"\r\n                    raise(ValueError(message))\r\n\r\n            if \"isReverse\" not in df_dict[\"SetpointController\"].columns:\r\n                warnings.warn(\"The property \\\"controls\\\" is not found in \\\"SetpointController\\\" sheet. This is ignored for now but will raise an error in the future. It probably is caused by using an outdated configuration file.\")\r\n            else:\r\n                if isinstance(row[df_dict[\"SetpointController\"].columns.get_loc(\"isReverse\")], bool):\r\n                    is_reverse = row[df_dict[\"SetpointController\"].columns.get_loc(\"isReverse\")]\r\n                    controller.isReverse = is_reverse\r\n                else:\r\n                    message = f\"Required property \\\"controls\\\" not set to Bool value for controller object \\\"{controller.id}\\\"\"\r\n                    raise(ValueError(message))\r\n\r\n            if isinstance(row[df_dict[\"SetpointController\"].columns.get_loc(\"hasProfile\")], str):\r\n                schedule_name = row[df_dict[\"SetpointController\"].columns.get_loc(\"hasProfile\")]\r\n                controller.hasProfile = self.component_base_dict[schedule_name]\r\n            else:\r\n                message = f\"Required property \\\"hasProfile\\\" not set for controller object \\\"{controller.id}\\\"\"\r\n                raise(ValueError(message))\r\n\r\n        for row in df_dict[\"RulebasedController\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            controller_name = row[df_dict[\"RulebasedController\"].columns.get_loc(\"id\")]\r\n            controller = self.component_base_dict[controller_name]\r\n\r\n            if isinstance(row[df_dict[\"RulebasedController\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"RulebasedController\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for controller object \\\"{controller.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            controller.subSystemOf.extend(systems)\r\n\r\n            if isinstance(row[df_dict[\"RulebasedController\"].columns.get_loc(\"isContainedIn\")], str):\r\n                controller.isContainedIn = self.component_base_dict[row[df_dict[\"RulebasedController\"].columns.get_loc(\"isContainedIn\")]]\r\n            \r\n            _property = self.property_dict[row[df_dict[\"RulebasedController\"].columns.get_loc(\"observes\")]]\r\n            controller.observes = _property\r\n\r\n\r\n            if \"controls\" not in df_dict[\"RulebasedController\"].columns:\r\n                warnings.warn(\"The property \\\"controls\\\" is not found in \\\"RulebasedController\\\" sheet. This is ignored for now but will raise an error in the future. It probably is caused by using an outdated configuration file.\")\r\n            else:\r\n                if isinstance(row[df_dict[\"RulebasedController\"].columns.get_loc(\"controls\")], str):\r\n                    controls = row[df_dict[\"RulebasedController\"].columns.get_loc(\"controls\")].split(\";\")\r\n                    controls = [self.property_dict[component_name] for component_name in controls]\r\n                    controller.controls.extend(controls)\r\n                else:\r\n                    message = f\"Required property \\\"controls\\\" not set for controller object \\\"{controller.id}\\\"\"\r\n                    raise(ValueError(message))\r\n\r\n            \r\n\r\n \r\n        for row in df_dict[\"ShadingDevice\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            shading_device_name = row[df_dict[\"ShadingDevice\"].columns.get_loc(\"id\")]\r\n            shading_device = self.component_base_dict[shading_device_name]\r\n\r\n            if isinstance(row[df_dict[\"ShadingDevice\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"ShadingDevice\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n                shading_device.subSystemOf.extend(systems)\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for shading_device object \\\"{shading_device.id}\\\"\"\r\n                raise(ValueError(message))\r\n\r\n            properties = [self.property_dict[property_name] for property_name in row[df_dict[\"ShadingDevice\"].columns.get_loc(\"hasProperty\")].split(\";\")]\r\n            shading_device.isContainedIn = self.component_base_dict[row[df_dict[\"ShadingDevice\"].columns.get_loc(\"isContainedIn\")]]\r\n            shading_device.hasProperty.extend(properties)\r\n      \r\n        for row in df_dict[\"Sensor\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            sensor_name = row[df_dict[\"Sensor\"].columns.get_loc(\"id\")]\r\n            sensor = self.component_base_dict[sensor_name]\r\n\r\n            if isinstance(row[df_dict[\"Sensor\"].columns.get_loc(\"observes\")], str):\r\n                properties = self.property_dict[row[df_dict[\"Sensor\"].columns.get_loc(\"observes\")]]\r\n                sensor.observes = properties\r\n            else:\r\n                message = f\"Required property \\\"observes\\\" not set for Sensor object \\\"{sensor.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            if isinstance(row[df_dict[\"Sensor\"].columns.get_loc(\"isContainedIn\")], str):\r\n                sensor.isContainedIn = self.component_base_dict[row[df_dict[\"Sensor\"].columns.get_loc(\"isContainedIn\")]]\r\n            \r\n            if isinstance(row[df_dict[\"Sensor\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"Sensor\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                sensor.connectedAfter.extend(connected_after)\r\n\r\n            if isinstance(row[df_dict[\"Sensor\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"Sensor\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n                sensor.subSystemOf.extend(systems)\r\n \r\n        for row in df_dict[\"Meter\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            meter_name = row[df_dict[\"Meter\"].columns.get_loc(\"id\")]\r\n            meter = self.component_base_dict[meter_name]\r\n            if isinstance(row[df_dict[\"Meter\"].columns.get_loc(\"observes\")], str):\r\n                properties = self.property_dict[row[df_dict[\"Meter\"].columns.get_loc(\"observes\")]]\r\n                meter.observes = properties\r\n            else:\r\n                message = f\"Required property \\\"observes\\\" not set for Sensor object \\\"{sensor.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            if isinstance(row[df_dict[\"Meter\"].columns.get_loc(\"isContainedIn\")], str):\r\n                meter.isContainedIn = self.component_base_dict[row[df_dict[\"Meter\"].columns.get_loc(\"isContainedIn\")]]\r\n\r\n            if isinstance(row[df_dict[\"Meter\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"Meter\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                meter.connectedAfter.extend(connected_after)\r\n\r\n            if isinstance(row[df_dict[\"Meter\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"Meter\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n                meter.subSystemOf.extend(systems)\r\n\r\n        for row in df_dict[\"Pump\"].dropna(subset=[\"id\"]).itertuples(index=False):\r\n            pump_name = row[df_dict[\"Pump\"].columns.get_loc(\"id\")]\r\n            pump = self.component_base_dict[pump_name]\r\n\r\n            if isinstance(row[df_dict[\"Pump\"].columns.get_loc(\"subSystemOf\")], str):\r\n                systems = row[df_dict[\"Pump\"].columns.get_loc(\"subSystemOf\")].split(\";\")\r\n                systems = [system for system_dict in self.system_dict.values() for system in system_dict.values() if system.id in systems]\r\n                pump.subSystemOf.extend(systems)\r\n            else:\r\n                message = f\"Required property \\\"subSystemOf\\\" not set for Pump object \\\"{pump.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            if isinstance(row[df_dict[\"Pump\"].columns.get_loc(\"connectedAfter\")], str):\r\n                connected_after = row[df_dict[\"Pump\"].columns.get_loc(\"connectedAfter\")].split(\";\")\r\n                connected_after = [self.component_base_dict[component_name] for component_name in connected_after]\r\n                pump.connectedAfter.extend(connected_after)\r\n            else:\r\n                message = f\"Required property \\\"connectedAfter\\\" not set for Pump object \\\"{pump.id}\\\"\"\r\n                raise(ValueError(message))\r\n            \r\n            if isinstance(row[df_dict[\"Pump\"].columns.get_loc(\"hasProperty\")], str):\r\n                pump.hasProperty.extend(row[df_dict[\"Pump\"].columns.get_loc(\"hasProperty\")])\r\n\r\n\r\n        logger.info(\"[Model Class] : Exited from Populate Object Function\")\r\n\r\n                        \r\n\r\n    def read_datamodel_config(self, semantic_model_filename):\r\n        '''\r\n            This is a method that reads a configuration file in the Excel format, \r\n            and instantiates and populates objects based on the information in the file. \r\n            The method reads various sheets in the Excel file and stores the data in separate \r\n            pandas dataframes, one for each sheet. Then, it calls two other methods, _instantiate_objects \r\n            and _populate_objects, to create and populate objects based on the data in the dataframes.        \r\n        '''\r\n\r\n        logger.info(\"[Model Class] : Entered in read_config Function\")\r\n        wb = load_workbook(semantic_model_filename, read_only=True)\r\n        df_Systems = pd.read_excel(semantic_model_filename, sheet_name=\"System\") if 'System' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Space = pd.read_excel(semantic_model_filename, sheet_name=\"BuildingSpace\") if 'BuildingSpace' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Damper = pd.read_excel(semantic_model_filename, sheet_name=\"Damper\") if 'Damper' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_SpaceHeater = pd.read_excel(semantic_model_filename, sheet_name=\"SpaceHeater\") if 'SpaceHeater' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Valve = pd.read_excel(semantic_model_filename, sheet_name=\"Valve\") if 'Valve' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Coil = pd.read_excel(semantic_model_filename, sheet_name=\"Coil\") if 'Coil' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_AirToAirHeatRecovery = pd.read_excel(semantic_model_filename, sheet_name=\"AirToAirHeatRecovery\") if 'AirToAirHeatRecovery' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Fan = pd.read_excel(semantic_model_filename, sheet_name=\"Fan\") if 'Fan' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Controller = pd.read_excel(semantic_model_filename, sheet_name=\"Controller\") if 'Controller' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_SetpointController = pd.read_excel(semantic_model_filename, sheet_name=\"SetpointController\") if 'SetpointController' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Schedule = pd.read_excel(semantic_model_filename, sheet_name=\"Schedule\") if 'Schedule' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_RulebasedController = pd.read_excel(semantic_model_filename, sheet_name=\"RulebasedController\") if 'RulebasedController' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_ShadingDevice = pd.read_excel(semantic_model_filename, sheet_name=\"ShadingDevice\") if 'ShadingDevice' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Sensor = pd.read_excel(semantic_model_filename, sheet_name=\"Sensor\") if 'Sensor' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Meter = pd.read_excel(semantic_model_filename, sheet_name=\"Meter\") if 'Meter' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Pump = pd.read_excel(semantic_model_filename, sheet_name=\"Pump\") if 'Pump' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n        df_Property = pd.read_excel(semantic_model_filename, sheet_name=\"Property\") if 'Property' in wb.sheetnames else pd.DataFrame([np.nan], columns=[\"id\"])\r\n\r\n        df_dict = {\"System\": df_Systems,\r\n                   \"BuildingSpace\": df_Space,\r\n                   \"Damper\": df_Damper,\r\n                   \"SpaceHeater\": df_SpaceHeater,\r\n                   \"Valve\": df_Valve,\r\n                   \"Coil\": df_Coil,\r\n                   \"AirToAirHeatRecovery\": df_AirToAirHeatRecovery,\r\n                   \"Fan\": df_Fan,\r\n                   \"Controller\": df_Controller,\r\n                   \"SetpointController\": df_SetpointController,\r\n                   \"Schedule\": df_Schedule,\r\n                   \"RulebasedController\": df_RulebasedController,\r\n                   \"ShadingDevice\": df_ShadingDevice,\r\n                   \"Sensor\": df_Sensor,\r\n                   \"Meter\": df_Meter,\r\n                   \"Pump\": df_Pump,\r\n                   \"Property\": df_Property}\r\n\r\n        self._instantiate_objects(df_dict)\r\n        self._populate_objects(df_dict)\r\n        logger.info(\"[Model Class] : Exited from read_config Function\")\r\n        \r\n    def read_input_config(self, input_dict):\r\n        \"\"\"\r\n        This method reads from an input dictionary and populates the corresponding objects.\r\n        \"\"\"\r\n        logger.info(\"[Model Class] : Entered in read_input_config Function\")\r\n\r\n        time_format = '%Y-%m-%d %H:%M:%S%z'\r\n        startTime = datetime.datetime.strptime(input_dict[\"metadata\"][\"start_time\"], time_format)\r\n        endTime = datetime.datetime.strptime(input_dict[\"metadata\"][\"end_time\"], time_format)\r\n        stepSize = input_dict[\"metadata\"]['stepSize']\r\n        \r\n        \r\n        if \"rooms_sensor_data\" in input_dict:\r\n            for component_id, component_data in input_dict[\"rooms_sensor_data\"].items():\r\n                data_available = bool(component_data[\"sensor_data_available\"]) \r\n                if data_available:\r\n                    timestamp = component_data[\"time\"]\r\n                    co2_values = component_data[\"co2\"]\r\n                    damper_values = component_data[\"damper_position\"]\r\n                    \r\n                    df_co2 = pd.DataFrame({\"timestamp\": timestamp, \"co2\": co2_values})\r\n                    df_damper = pd.DataFrame({\"timestamp\": timestamp, \"damper_position\": damper_values})\r\n                    \r\n                    df_co2 = sample_from_df(df_co2,\r\n                                            stepSize=stepSize,\r\n                                            start_time=startTime,\r\n                                            end_time=endTime,\r\n                                            resample=True,\r\n                                            clip=True,\r\n                                            tz=\"Europe/Copenhagen\",\r\n                                            preserve_order=True)\r\n                    df_damper = sample_from_df(df_damper,\r\n                                            stepSize=stepSize,\r\n                                            start_time=startTime,\r\n                                            end_time=endTime,\r\n                                            resample=True,\r\n                                            clip=True,\r\n                                            tz=\"Europe/Copenhagen\",\r\n                                            preserve_order=True)\r\n                    df_damper[\"damper_position\"] = df_damper[\"damper_position\"]/100\r\n                    \r\n                    components_ = self.component_dict.keys()\r\n                    #Make it an array of strings\r\n                    components_ = list(components_)\r\n                    # find all the components that contain the last part of the component_id, after the first dash\r\n                    \r\n                    #Extract the substring after the first dash\r\n                    substring_id = component_id.split(\"-\")[1] + \"-\" + component_id.split(\"-\")[2]\r\n                    substring_id = substring_id.lower().replace(\"-\", \"_\")\r\n                    \r\n                    # Find all the components that contain the substring\r\n                    filtered_components = [component_ for component_ in components_ if substring_id in component_]\r\n\r\n                    #If the component contains \"co2\" in the id, add the co2 data\r\n                    for component_ in filtered_components:\r\n                        if \"CO2_sensor\" in component_:\r\n                            co2_sensor = self.component_dict[component_]\r\n                            co2_sensor.df_input = df_co2\r\n                        elif \"Damper_position_sensor\" in component_:\r\n                            damper_position_sensor = self.component_dict[component_]\r\n                            damper_position_sensor.df_input = df_damper\r\n                else:\r\n                    logger.info(\"[Model Class] : No sensor data available in the input dictionary, using schedules instead.\")\r\n\r\n                    rooms_volumes = {\r\n                        \"601b_00\": 500,\r\n                        \"601b_0\": 417,\r\n                        \"601b_1\": 417,\r\n                        \"601b_2\": 417,\r\n                        \"603_0\" : 240,\r\n                        \"603_1\" : 240,\r\n                        \"604_0\" : 486,\r\n                        \"604_1\" : 375,\r\n                        \"603b_2\" : 159,\r\n                        \"603a_2\" : 33,\r\n                        \"604a_2\" : 33,\r\n                        \"604b_2\" : 33,\r\n                        \"605a_2\" : 33,\r\n                        \"605b_2\" : 33,\r\n                        \"604e_2\" : 33,\r\n                        \"604d_2\" : 33,\r\n                        \"604c_2\" : 33,\r\n                        \"605e_2\" : 33,\r\n                        \"605d_2\" : 33,\r\n                        \"605c_2\" : 30,\r\n\r\n                    }\r\n\r\n                    components_ = self.component_dict.keys()\r\n                    components_ = list(components_)\r\n                    substring_id = component_id.split(\"-\")[1] + \"-\" + component_id.split(\"-\")[2]\r\n                    substring_id = substring_id.lower().replace(\"-\", \"_\")\r\n                    room_filtered_components = [component_ for component_ in components_ if substring_id in component_]\r\n\r\n                    if substring_id == \"601b_0\":\r\n                        components_601b_00 = {\r\n                            \"CO2_controller_sensor_22_601b_00\",                             \r\n                            \"Damper_position_sensor_22_601b_00\", \r\n                            \"Supply_damper_22_601b_00\", \r\n                            \"Return_damper_22_601b_00\", \r\n                            \"CO2_sensor_22_601b_00\"\r\n                        }\r\n                        filtered_components = []\r\n                        for component_ in room_filtered_components:\r\n                            if component_ not in components_601b_00:\r\n                                filtered_components.append(component_)\r\n                        room_filtered_components = filtered_components\r\n\r\n                    for component_ in room_filtered_components:\r\n                        if \"CO2_sensor\" in component_:\r\n                            sender_component = self.component_dict[component_]\r\n                            receiver_component_id = next((component_ for component_ in room_filtered_components if \"CO2_controller\" in component_), None)\r\n                            receiver_component = self.component_dict[receiver_component_id]\r\n                            self.remove_connection(sender_component, receiver_component, \"indoorCo2Concentration\", \"actualValue\")\r\n                            self.remove_component(sender_component)\r\n                            \r\n                            schedule_input = component_data[\"occupancy_schedule\"] \r\n                            #Create the schedule object\r\n                            room_occupancy_schedule = components.ScheduleSystem(\r\n                                **schedule_input,\r\n                                add_noise = False,\r\n                                saveSimulationResult = True,\r\n                                id = f\"{substring_id}_occupancy_schedule\")\r\n                            #Create the space co2 object\r\n                            room_volume = int(rooms_volumes[substring_id]) \r\n                            room_space_co2 = components.BuildingSpaceCo2System(\r\n                                airVolume = room_volume,\r\n                                saveSimulationResult = True,\r\n                                id = f\"{substring_id}_CO2_space\")\r\n                            \r\n                            self._add_component(room_occupancy_schedule)\r\n                            self._add_component(room_space_co2)\r\n\r\n                            supply_damper_id = next((component_ for component_ in room_filtered_components if \"Supply_damper\" in component_), None)\r\n                            return_damper_id = next((component_ for component_ in room_filtered_components if \"Return_damper\" in component_), None)\r\n                            supply_damper = self.component_dict[supply_damper_id]\r\n                            return_damper = self.component_dict[return_damper_id]\r\n\r\n                            self.add_connection(room_occupancy_schedule, room_space_co2,\r\n                                \"scheduleValue\", \"numberOfPeople\")\r\n                            self.add_connection(supply_damper, room_space_co2,\r\n                                \"airFlowRate\", \"supplyAirFlowRate\")\r\n                            self.add_connection(return_damper, room_space_co2,\r\n                                \"airFlowRate\", \"returnAirFlowRate\")\r\n                            self.add_connection(room_space_co2, receiver_component,\r\n                                \"indoorCo2Concentration\", \"actualValue\")\r\n                            \r\n                            receiver_component.observes.isPropertyOf = room_space_co2\r\n                            #Point the property to the new space component.\r\n                            #Make sure property has the attribute \"isPropertyOf\" pointing to the space\r\n\r\n\r\n\r\n                        else:\r\n                            pass\r\n\r\n                            \r\n                            \r\n            \r\n\r\n\r\n            ## ADDED FOR DAMPER CONTROL of 601b_00, missing data\r\n\r\n            oe_601b_00_component = self.component_dict[\"CO2_controller_sensor_22_601b_00\"]\r\n            #Create a dataframe with timestamps and damper values, the timestamps are between startTime and endTime, with stepSize\r\n            freq = f\"{stepSize}S\"\r\n            df_damper_control = pd.DataFrame({\"timestamp\": pd.date_range(start=startTime, end=endTime, freq=freq)})\r\n            #Create a column with the damper values, all set to 1 \r\n            df_damper_control[\"damper_position\"] = 1\r\n            \r\n            df_damper_control = sample_from_df(df_damper_control,\r\n                        stepSize=stepSize,\r\n                        start_time=startTime,\r\n                        end_time=endTime,\r\n                        resample=True,\r\n                        clip=True,\r\n                        tz=\"Europe/Copenhagen\",\r\n                        preserve_order=True)\r\n            \r\n            #Set the df_input of the component to the new dataframe\r\n            oe_601b_00_component.df_input = df_damper_control\r\n\r\n        else:\r\n            sensor_inputs = input_dict[\"inputs_sensor\"] #Change naming to be consistent\r\n            schedule_inputs = input_dict[\"input_schedules\"] #Change naming to be consistent\r\n            weather_inputs = sensor_inputs[\"ml_inputs_dmi\"]\r\n            \r\n            df_raw = pd.DataFrame()\r\n            df_raw.insert(0, \"datetime\", weather_inputs[\"observed\"])\r\n            df_raw.insert(1, \"outdoorTemperature\", weather_inputs[\"temp_dry\"])\r\n            df_raw.insert(2, \"globalIrradiation\", weather_inputs[\"radia_glob\"])\r\n            df_sample = sample_from_df(df_raw,\r\n                                        stepSize=stepSize,\r\n                                        start_time=startTime,\r\n                                        end_time=endTime,\r\n                                        resample=True,\r\n                                        clip=True,\r\n                                        tz=\"Europe/Copenhagen\",\r\n                                        preserve_order=True)\r\n\r\n            outdoor_environment = components.OutdoorEnvironmentSystem(df_input=df_sample,\r\n                                                            saveSimulationResult = self.saveSimulationResult,\r\n                                                            id = \"outdoor_environment\")\r\n\r\n            # Initialize the room temperature \r\n\r\n            '''\r\n                MODIFIED BY NEC-INDIA\r\n\r\n                temperature_list = sensor_inputs[\"ml_inputs\"][\"temperature\"]\r\n\r\n                # take the first occurence of the value in the list \r\n                # if the [0] is 'None' then iterate for the next value till end \r\n                # if temperature_list has all 'None' then default temperature taken as 21\r\n            '''\r\n            if sensor_inputs[\"ml_inputs\"][\"temperature\"][0]==\"None\":\r\n                initial_temperature = 21\r\n            else:\r\n                initial_temperature = float(sensor_inputs[\"ml_inputs\"][\"temperature\"][0])\r\n            custom_initial_dict = {\"OE20-601b-2\": {\"indoorTemperature\": initial_temperature}}\r\n            self.set_custom_initial_dict(custom_initial_dict)\r\n\r\n            indoor_temperature_setpoint_schedule = components.ScheduleSystem(\r\n                **schedule_inputs[\"temperature_setpoint_schedule\"],\r\n                add_noise = False,\r\n                saveSimulationResult = True,\r\n                id = \"OE20-601b-2_temperature_setpoint_schedule\")\r\n\r\n            occupancy_schedule = components.ScheduleSystem(\r\n                **schedule_inputs[\"occupancy_schedule\"],\r\n                add_noise = True,\r\n                saveSimulationResult = True,\r\n                id = \"OE20-601b-2_occupancy_schedule\")\r\n\r\n            supply_water_temperature_setpoint_schedule = components.PiecewiseLinearScheduleSystem(\r\n                **schedule_inputs[\"supply_water_temperature_schedule_pwlf\"],\r\n                saveSimulationResult = True,\r\n                id = \"Heating system_supply_water_temperature_schedule\")\r\n            \r\n            supply_air_temperature_schedule = components.ScheduleSystem(\r\n                **schedule_inputs[\"supply_air_temperature_schedule\"],\r\n                saveSimulationResult = True,\r\n                id = \"Ventilation system_supply_air_temperature_schedule\")\r\n\r\n            self._add_component(outdoor_environment)\r\n            self._add_component(occupancy_schedule)\r\n            self._add_component(indoor_temperature_setpoint_schedule)\r\n            self._add_component(supply_water_temperature_setpoint_schedule)\r\n            self._add_component(supply_air_temperature_schedule)\r\n\r\n        logger.info(\"[Model Class] : Exited from read_input_config Function\")\r\n\r\n    def parse_semantic_model(self):\r\n        space_instances = self.get_component_by_class(self.component_base_dict, base.BuildingSpace)\r\n        damper_instances = self.get_component_by_class(self.component_base_dict, base.Damper)\r\n        space_heater_instances = self.get_component_by_class(self.component_base_dict, base.SpaceHeater)\r\n        valve_instances = self.get_component_by_class(self.component_base_dict, base.Valve)\r\n        coil_instances = self.get_component_by_class(self.component_base_dict, base.Coil)\r\n        air_to_air_heat_recovery_instances = self.get_component_by_class(self.component_base_dict, base.AirToAirHeatRecovery)\r\n        fan_instances = self.get_component_by_class(self.component_base_dict, base.Fan)\r\n        controller_instances = self.get_component_by_class(self.component_base_dict, base.Controller)\r\n        setpoint_controller_instances = self.get_component_by_class(self.component_base_dict, base.SetpointController)\r\n        rulebased_controller_instances = self.get_component_by_class(self.component_base_dict, base.RulebasedController)\r\n        shading_device_instances = self.get_component_by_class(self.component_base_dict, base.ShadingDevice)\r\n        sensor_instances = self.get_component_by_class(self.component_base_dict, base.Sensor)\r\n        meter_instances = self.get_component_by_class(self.component_base_dict, base.Meter)\r\n        pump_instances = self.get_component_by_class(self.component_base_dict, base.Pump)\r\n\r\n        for space in space_instances:\r\n            for property_ in space.hasProperty:\r\n                property_.isPropertyOf = space\r\n            for component in space.connectedAfter:\r\n                component.connectedBefore.append(space)\r\n            \r\n        for damper in damper_instances:\r\n            damper.isContainedIn.contains.append(damper)\r\n            for system in damper.subSystemOf:\r\n                system.hasSubSystem.append(damper)\r\n            for property_ in damper.hasProperty:\r\n                property_.isPropertyOf = damper\r\n            for component in damper.connectedAfter:\r\n                component.connectedBefore.append(damper)\r\n\r\n        for space_heater in space_heater_instances:\r\n            for component in space_heater.connectedAfter:\r\n                component.connectedBefore.append(space_heater)\r\n            space_heater.isContainedIn.contains.append(space_heater)\r\n            for system in space_heater.subSystemOf:\r\n                system.hasSubSystem.append(space_heater)\r\n            for property_ in space_heater.hasProperty:\r\n                property_.isPropertyOf = space_heater\r\n\r\n        for valve in valve_instances:\r\n            if valve.isContainedIn is not None:\r\n                valve.isContainedIn.contains.append(valve)\r\n            for system in valve.subSystemOf:\r\n                system.hasSubSystem.append(valve)\r\n            for property_ in valve.hasProperty:\r\n                property_.isPropertyOf = valve\r\n            for component in valve.connectedAfter:\r\n                component.connectedBefore.append(valve)\r\n\r\n        for coil in coil_instances:\r\n            for system in coil.subSystemOf:\r\n                system.hasSubSystem.append(coil)\r\n            for property_ in coil.hasProperty:\r\n                property_.isPropertyOf = coil\r\n            for component in coil.connectedAfter:\r\n                component.connectedBefore.append(coil)\r\n\r\n        for air_to_air_heat_recovery in air_to_air_heat_recovery_instances:\r\n            for system in air_to_air_heat_recovery.subSystemOf:\r\n                system.hasSubSystem.append(air_to_air_heat_recovery)\r\n            for property_ in air_to_air_heat_recovery.hasProperty:\r\n                property_.isPropertyOf = air_to_air_heat_recovery\r\n            for component in air_to_air_heat_recovery.connectedAfter:\r\n                component.connectedBefore.append(air_to_air_heat_recovery)\r\n\r\n        for fan in fan_instances:\r\n            for system in fan.subSystemOf:\r\n                system.hasSubSystem.append(fan)\r\n            for property_ in fan.hasProperty:\r\n                property_.isPropertyOf = fan\r\n            for component in fan.connectedAfter:\r\n                component.connectedBefore.append(fan)\r\n\r\n        for controller in controller_instances:\r\n            if controller.isContainedIn is not None:\r\n                controller.isContainedIn.contains.append(controller) if controller not in controller.isContainedIn.contains else None\r\n            controller.observes.isObservedBy.append(controller)\r\n            for property_ in controller.controls:\r\n                property_.isControlledBy.append(controller) if controller not in property_.isControlledBy else None\r\n            for system in controller.subSystemOf:\r\n                system.hasSubSystem.append(controller)\r\n\r\n        for setpoint_controller in setpoint_controller_instances:\r\n            if setpoint_controller.isContainedIn is not None:\r\n                setpoint_controller.isContainedIn.contains.append(setpoint_controller) if setpoint_controller not in setpoint_controller.isContainedIn.contains else None\r\n            setpoint_controller.observes.isObservedBy.append(setpoint_controller)\r\n            for property_ in setpoint_controller.controls:\r\n                property_.isControlledBy.append(setpoint_controller) if setpoint_controller not in property_.isControlledBy else None\r\n            for system in setpoint_controller.subSystemOf:\r\n                system.hasSubSystem.append(setpoint_controller)\r\n\r\n\r\n        for rulebased_controller in rulebased_controller_instances:\r\n            if rulebased_controller.isContainedIn is not None:\r\n                rulebased_controller.isContainedIn.contains.append(rulebased_controller)\r\n            rulebased_controller.observes.isObservedBy = rulebased_controller\r\n            for property_ in rulebased_controller.controls:\r\n                property_.isControlledBy = rulebased_controller\r\n            for system in rulebased_controller.subSystemOf:\r\n                system.hasSubSystem.append(rulebased_controller)\r\n\r\n        for shading_device in shading_device_instances:\r\n            shading_device.isContainedIn.contains.append(shading_device)\r\n            for system in shading_device.subSystemOf:\r\n                system.hasSubSystem.append(shading_device)\r\n            for property_ in shading_device.hasProperty:\r\n                property_.isPropertyOf = shading_device\r\n\r\n        for sensor in sensor_instances:\r\n            if sensor.isContainedIn is not None:\r\n                sensor.isContainedIn.contains.append(sensor)\r\n            sensor.observes.isObservedBy = sensor\r\n            for system in sensor.subSystemOf:\r\n                system.hasSubSystem.append(sensor)\r\n            for component in sensor.connectedAfter:\r\n                component.connectedBefore.append(sensor)\r\n\r\n        for meter in meter_instances:\r\n            if meter.isContainedIn is not None:\r\n                meter.isContainedIn.contains.append(meter)\r\n            meter.observes.isObservedBy = meter\r\n            for system in meter.subSystemOf:\r\n                system.hasSubSystem.append(meter)\r\n            for component in meter.connectedAfter:\r\n                component.connectedBefore.append(meter)\r\n\r\n        for pump in pump_instances:\r\n            for system in pump.subSystemOf:\r\n                system.hasSubSystem.append(pump)\r\n            for component in pump.connectedAfter:\r\n                component.connectedBefore.append(pump)\r\n            for property_ in pump.hasProperty:\r\n                property_.isPropertyOf = pump\r\n\r\n        #Add systems\r\n        for heating_system in self.system_dict[\"heating\"].values():\r\n            self._add_object(heating_system)\r\n\r\n        for cooling_system in self.system_dict[\"cooling\"].values():\r\n            self._add_object(cooling_system)\r\n\r\n        for ventilation_system in self.system_dict[\"ventilation\"].values():\r\n            self._add_object(ventilation_system)\r\n        \r\n        logger.info(\"[Model Class] : Exited from Apply Model Extensions Function\")\r\n        \r\n    def apply_model_extensions(self):\r\n        logger.info(\"[Model Class] : Entered in Apply Model Extensions Function\")\r\n        space_instances = self.get_component_by_class(self.component_base_dict, base.BuildingSpace)\r\n        damper_instances = self.get_component_by_class(self.component_base_dict, base.Damper)\r\n        space_heater_instances = self.get_component_by_class(self.component_base_dict, base.SpaceHeater)\r\n        valve_instances = self.get_component_by_class(self.component_base_dict, base.Valve)\r\n        coil_instances = self.get_component_by_class(self.component_base_dict, base.Coil)\r\n        air_to_air_heat_recovery_instances = self.get_component_by_class(self.component_base_dict, base.AirToAirHeatRecovery)\r\n        fan_instances = self.get_component_by_class(self.component_base_dict, base.Fan)\r\n        controller_instances = self.get_component_by_class(self.component_base_dict, base.Controller)\r\n        shading_device_instances = self.get_component_by_class(self.component_base_dict, base.ShadingDevice)\r\n        sensor_instances = self.get_component_by_class(self.component_base_dict, base.Sensor)\r\n        meter_instances = self.get_component_by_class(self.component_base_dict, base.Meter)\r\n\r\n        for space in space_instances:\r\n            base_kwargs = self.get_object_properties(space)\r\n            extension_kwargs = {\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            space = components.BuildingSpaceSystem(**base_kwargs)\r\n            self._add_component(space)\r\n            for property_ in space.hasProperty:\r\n                property_.isPropertyOf = space\r\n            for component in space.connectedAfter:\r\n                component.connectedBefore.append(space)\r\n            \r\n        for damper in damper_instances:\r\n            base_kwargs = self.get_object_properties(damper)\r\n            extension_kwargs = {\r\n                \"a\": 1,\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            damper = components.DamperSystem(**base_kwargs)\r\n            self._add_component(damper)\r\n            damper.isContainedIn = self.component_dict[damper.isContainedIn.id]\r\n            damper.isContainedIn.contains.append(damper)\r\n            for system in damper.subSystemOf:\r\n                system.hasSubSystem.append(damper)\r\n            for property_ in damper.hasProperty:\r\n                property_.isPropertyOf = damper\r\n            for component in damper.connectedAfter:\r\n                component.connectedBefore.append(damper)\r\n\r\n        for space_heater in space_heater_instances:\r\n            base_kwargs = self.get_object_properties(space_heater)\r\n            extension_kwargs = {\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            space_heater = components.SpaceHeaterSystem(**base_kwargs)\r\n            space_heater.heatTransferCoefficient = 8.31495759e+01\r\n            space_heater.thermalMassHeatCapacity.hasvalue = 2.72765272e+06\r\n            for component in space_heater.connectedAfter:\r\n                component.connectedBefore.append(space_heater)\r\n\r\n            self._add_component(space_heater)\r\n            space_heater.isContainedIn = self.component_dict[space_heater.isContainedIn.id]\r\n            space_heater.isContainedIn.contains.append(space_heater)\r\n            for system in space_heater.subSystemOf:\r\n                system.hasSubSystem.append(space_heater)\r\n            for property_ in space_heater.hasProperty:\r\n                property_.isPropertyOf = space_heater\r\n\r\n        for valve in valve_instances:\r\n            base_kwargs = self.get_object_properties(valve)\r\n            extension_kwargs = {\r\n                \"waterFlowRateMax\": 0.0202,\r\n                \"valveAuthority\": 1.,\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            valve = components.ValveSystem(**base_kwargs)\r\n            self._add_component(valve)\r\n            valve.isContainedIn = self.component_dict[valve.isContainedIn.id]\r\n            valve.isContainedIn.contains.append(valve)\r\n            for system in valve.subSystemOf:\r\n                system.hasSubSystem.append(valve)\r\n            for property_ in valve.hasProperty:\r\n                property_.isPropertyOf = valve\r\n            for component in valve.connectedAfter:\r\n                component.connectedBefore.append(valve)\r\n\r\n        for coil in coil_instances:\r\n            base_kwargs = self.get_object_properties(coil)\r\n            extension_kwargs = {\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            if len([v for v in coil.subSystemOf if v in self.system_dict[\"heating\"].values()])==1:\r\n                coil = components.CoilHeatingSystem(**base_kwargs)\r\n            elif len([v for v in coil.subSystemOf if v in self.system_dict[\"cooling\"].values()])==1:\r\n                coil = components.CoilCoolingSystem(**base_kwargs)\r\n            else:\r\n                raise(ValueError(f\"The system of the Coil with id \\\"{coil.id}\\\" is not set.\"))\r\n            self._add_component(coil)\r\n            for system in coil.subSystemOf:\r\n                system.hasSubSystem.append(coil)\r\n            for property_ in coil.hasProperty:\r\n                property_.isPropertyOf = coil\r\n            for component in coil.connectedAfter:\r\n                component.connectedBefore.append(coil)\r\n\r\n        for air_to_air_heat_recovery in air_to_air_heat_recovery_instances:\r\n            base_kwargs = self.get_object_properties(air_to_air_heat_recovery)\r\n            extension_kwargs = {\r\n                \"specificHeatCapacityAir\": base.PropertyValue(hasValue=1000),\r\n                \"eps_75_h\": 0.84918046,\r\n                \"eps_75_c\": 0.82754917,\r\n                \"eps_100_h\": 0.85202735,\r\n                \"eps_100_c\": 0.8215695,\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            air_to_air_heat_recovery = components.AirToAirHeatRecoverySystem(**base_kwargs)\r\n            self._add_component(air_to_air_heat_recovery)\r\n            for system in air_to_air_heat_recovery.subSystemOf:\r\n                system.hasSubSystem.append(air_to_air_heat_recovery)\r\n            for property_ in air_to_air_heat_recovery.hasProperty:\r\n                property_.isPropertyOf = air_to_air_heat_recovery\r\n            for component in air_to_air_heat_recovery.connectedAfter:\r\n                component.connectedBefore.append(air_to_air_heat_recovery)\r\n\r\n        for fan in fan_instances:\r\n            base_kwargs = self.get_object_properties(fan)\r\n            extension_kwargs = {\r\n                \"c1\": 0.027828,\r\n                \"c2\": 0.026583,\r\n                \"c3\": -0.087069,\r\n                \"c4\": 1.030920,\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            fan = components.FanSystem(**base_kwargs)\r\n            self._add_component(fan)\r\n            for system in fan.subSystemOf:\r\n                system.hasSubSystem.append(fan)\r\n            for property_ in fan.hasProperty:\r\n                property_.isPropertyOf = fan\r\n            for component in fan.connectedAfter:\r\n                component.connectedBefore.append(fan)\r\n\r\n        for controller in controller_instances:\r\n            base_kwargs = self.get_object_properties(controller)\r\n            if isinstance(controller.observes, base.Temperature):\r\n                K_i = 2.50773924e-01\r\n                K_p = 4.38174242e-01\r\n                K_d = 0\r\n                extension_kwargs = {\r\n                    \"K_p\": K_p,\r\n                    \"K_i\": K_i,\r\n                    \"K_d\": K_d,\r\n                    \"saveSimulationResult\": self.saveSimulationResult,\r\n                }\r\n                base_kwargs.update(extension_kwargs)\r\n                controller = components.ControllerSystem(**base_kwargs)\r\n            elif isinstance(controller.observes, base.Co2):\r\n                extension_kwargs = {\r\n                    \"saveSimulationResult\": self.saveSimulationResult,\r\n                }\r\n                base_kwargs.update(extension_kwargs)\r\n                controller = components.RulebasedControllerSystem(**base_kwargs)\r\n            self._add_component(controller)\r\n            controller.isContainedIn = self.component_dict[controller.isContainedIn.id]\r\n            controller.isContainedIn.contains.append(controller)\r\n            controller.observes.isControlledBy = self.component_dict[controller.id]\r\n            for system in controller.subSystemOf:\r\n                system.hasSubSystem.append(controller)\r\n\r\n        for shading_device in shading_device_instances:\r\n            base_kwargs = self.get_object_properties(shading_device)\r\n            extension_kwargs = {\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            shading_device = components.ShadingDeviceSystem(**base_kwargs)\r\n            self._add_component(shading_device)\r\n            shading_device.isContainedIn = self.component_dict[shading_device.isContainedIn.id]\r\n            shading_device.isContainedIn.contains.append(shading_device)\r\n            for system in shading_device.subSystemOf:\r\n                system.hasSubSystem.append(shading_device)\r\n            for property_ in shading_device.hasProperty:\r\n                property_.isPropertyOf = shading_device\r\n\r\n        for sensor in sensor_instances:\r\n            base_kwargs = self.get_object_properties(sensor)\r\n            extension_kwargs = {\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            sensor = components.SensorSystem(**base_kwargs)\r\n            self._add_component(sensor)\r\n            if sensor.isContainedIn is not None:\r\n                sensor.isContainedIn = self.component_dict[sensor.isContainedIn.id]\r\n                sensor.isContainedIn.contains.append(sensor)\r\n            sensor.observes.isObservedBy = self.component_dict[sensor.id]\r\n            for system in sensor.subSystemOf:\r\n                system.hasSubSystem.append(sensor)\r\n            for component in sensor.connectedAfter:\r\n                component.connectedBefore.append(sensor)\r\n\r\n        for meter in meter_instances:\r\n            base_kwargs = self.get_object_properties(meter)\r\n            extension_kwargs = {\r\n                \"saveSimulationResult\": self.saveSimulationResult,\r\n            }\r\n            base_kwargs.update(extension_kwargs)\r\n            meter = components.MeterSystem(**base_kwargs)\r\n            self._add_component(meter)\r\n            if meter.isContainedIn is not None:\r\n                meter.isContainedIn = self.component_dict[meter.isContainedIn.id]\r\n                meter.isContainedIn.contains.append(meter)\r\n            meter.observes.isObservedBy = self.component_dict[meter.id]\r\n            for system in meter.subSystemOf:\r\n                system.hasSubSystem.append(meter)\r\n            for component in meter.connectedAfter:\r\n                component.connectedBefore.append(meter)\r\n\r\n        # # Add supply and return node for each ventilation system\r\n        for ventilation_system in self.system_dict[\"ventilation\"].values():\r\n            node_S = components.FlowJunctionSystem(\r\n                    subSystemOf = [ventilation_system],\r\n                    operationMode = \"supply\",\r\n                    saveSimulationResult = self.saveSimulationResult,\r\n                    # id = f\"N_supply_{ventilation_system.id}\")\r\n                    id = \"Supply node\") ####\r\n            self._add_component(node_S)\r\n            ventilation_system.hasSubSystem.append(node_S)\r\n            node_E = components.FlowJunctionSystem(\r\n                    subSystemOf = [ventilation_system],\r\n                    operationMode = \"return\",\r\n                    saveSimulationResult = self.saveSimulationResult,\r\n                    # id = f\"N_return_{ventilation_system.id}\") ##############################  ####################################################################################\r\n                    id = \"Exhaust node\") ####\r\n            self._add_component(node_E)\r\n            ventilation_system.hasSubSystem.append(node_E)\r\n\r\n        #Map all connectedTo properties\r\n        for component in self.component_dict.values():\r\n            connectedTo_new = []\r\n            if component.connectedTo is not None:\r\n                for base_component in component.connectedTo:\r\n                    connectedTo_new.append(self.component_dict[base_component.id])\r\n            component.connectedTo = connectedTo_new\r\n\r\n        for component in self.component_dict.values():\r\n            connectedBefore_new = []\r\n            if len(component.connectedBefore)>0:\r\n                for base_component in component.connectedBefore:\r\n                    connectedBefore_new.append(self.component_dict[base_component.id])\r\n            component.connectedBefore = connectedBefore_new\r\n\r\n        for component in self.component_dict.values():\r\n            connectedAfter_new = []\r\n            if len(component.connectedAfter)>0:\r\n                for base_component in component.connectedAfter:\r\n                    connectedAfter_new.append(self.component_dict[base_component.id])\r\n            component.connectedAfter = connectedAfter_new\r\n\r\n        #Add systems\r\n        for heating_system in self.system_dict[\"heating\"].values():\r\n            self._add_object(heating_system)\r\n\r\n        for cooling_system in self.system_dict[\"cooling\"].values():\r\n            self._add_object(cooling_system)\r\n\r\n        for ventilation_system in self.system_dict[\"ventilation\"].values():\r\n            self._add_object(ventilation_system)\r\n        \r\n        logger.info(\"[Model Class] : Exited from Apply Model Extensions Function\")\r\n\r\n    def get_object_properties(self, object_):\r\n        return {key: value for (key, value) in vars(object_).items()}\r\n        \r\n    def get_component_by_class(self, dict_, class_, filter=None):\r\n        if filter is None:\r\n            filter = lambda v: True\r\n        return [v for v in dict_.values() if (isinstance(v, class_) and filter(v))]\r\n\r\n    def get_dampers_by_space(self, space):\r\n        return [component for component in space.contains if isinstance(component, base.Damper)]\r\n\r\n    def get_space_heaters_by_space(self, space):\r\n        return [component for component in space.contains if isinstance(component, base.SpaceHeater)]\r\n\r\n    def get_valves_by_space(self, space):\r\n        return [component for component in space.contains if isinstance(component, base.Valve)]\r\n\r\n    def get_controllers_by_space(self, space):\r\n        return [component for component in space.contains if isinstance(component, base.Controller)]\r\n\r\n    def get_shading_devices_by_space(self, space):\r\n        return [component for component in space.contains if isinstance(component, base.ShadingDevice)]\r\n\r\n    def _get_leaf_node_old(self, component, last_component, ref_component, found_ref=False):\r\n        # if isinstance(component, AirToAirHeatRecovery)==False or len(list(set(component.connectedTo) - set([component])))>1:\r\n        if isinstance(component, base.AirToAirHeatRecovery) or len(component.connectedTo)<2:\r\n            node = component\r\n            found_ref = True if component is ref_component else False\r\n        else:\r\n            for connected_component in component.connectedTo:\r\n                if connected_component is not last_component:\r\n                    if isinstance(connected_component, base.AirToAirHeatRecovery)==False and len(connected_component.connectedTo)>1:\r\n                        node, found_ref = self._get_leaf_node_old(connected_component, component, ref_component, found_ref=found_ref)\r\n                        found_ref = True if connected_component is ref_component else False\r\n                    else:\r\n                        node = connected_component\r\n        return node, found_ref\r\n\r\n    def _get_flow_placement_old(self, ref_component, component):\r\n        \"\"\"\r\n         _______________________________________________________\r\n        |                                                       |\r\n    ref | ------------------------------------> flow direction  | component\r\n        |_______________________________________________________|\r\n\r\n        The above example would yield placement = \"after\"\r\n        \"\"\"\r\n        for connected_component in component.connectedTo:\r\n            placement=None\r\n            node, found_ref = self._get_leaf_node_old(connected_component, component, ref_component)\r\n            if isinstance(node, base.Damper):\r\n                if found_ref:\r\n                    if node.operationMode==\"supply\":\r\n                        placement = \"before\"\r\n                        side = \"supply\"\r\n                        # print(1)\r\n                    else:\r\n                        placement = \"after\"\r\n                        side = \"return\"\r\n                        # print(2)\r\n                else:\r\n                    if node.operationMode==\"supply\":\r\n                        placement = \"after\"\r\n                        side = \"supply\"\r\n                        # print(3)\r\n                    else:\r\n                        placement = \"before\"\r\n                        side = \"return\"\r\n                        # print(4)\r\n                break\r\n\r\n            elif isinstance(node, components.OutdoorEnvironmentSystem):\r\n                if found_ref:\r\n                    placement = \"after\"\r\n                    side = \"supply\"\r\n                    # print(5)\r\n                else:\r\n                    placement = \"before\"\r\n                    side = \"supply\"\r\n                    # print(6)\r\n                break\r\n\r\n            elif isinstance(node, base.AirToAirHeatRecovery):\r\n                saved_found_ref = found_ref\r\n\r\n        if placement is None:\r\n            if saved_found_ref:\r\n                placement = \"after\"\r\n                side = \"return\"\r\n                # print(7)\r\n            else:\r\n                placement = \"before\"\r\n                side = \"return\"\r\n                # print(8)\r\n                \r\n        return placement, side\r\n\r\n    def _get_leaf_nodes_before(self, ref_component, component, leaf_nodes=None, found_ref=False):\r\n        if leaf_nodes is None:\r\n            leaf_nodes = []\r\n        if len(component.connectedAfter)>0:\r\n            for connected_component in component.connectedAfter:\r\n                found_ref = True if connected_component is ref_component else False\r\n                leaf_nodes, found_ref = self._get_leaf_nodes_before(ref_component, connected_component, leaf_nodes, found_ref=found_ref)\r\n        else:\r\n            leaf_nodes.append(component)\r\n        return leaf_nodes, found_ref\r\n    \r\n    def _get_leaf_nodes_after(self, component, leaf_nodes=None, visited=None):\r\n        if leaf_nodes is None:\r\n            leaf_nodes = []\r\n        if visited is None:\r\n            visited = [component.id]\r\n        if len(component.connectedBefore)>0:\r\n            for connected_component in component.connectedBefore:\r\n                if connected_component.id not in visited:\r\n                    visited.append(connected_component.id)\r\n                    leaf_nodes, visited = self._get_leaf_nodes_after(connected_component, leaf_nodes, visited)\r\n                else:\r\n                    visited.append(connected_component.id)\r\n                    raise RecursionError(f\"The component of class \\\"{connected_component.__class__.__name__}\\\" with id \\\"{connected_component.id}\\\" is part of a cycle. The following components form a cycle with the \\\"connectedBefore\\\" property: {' -> '.join(visited)}\")\r\n        else:\r\n            leaf_nodes.append(component)\r\n        return leaf_nodes, visited\r\n\r\n    def component_is_before(self, ref_component, component, is_before=False):\r\n        if len(component.connectedAfter)>0:\r\n            for connected_component in component.connectedAfter:\r\n                is_before = True if connected_component is ref_component else False\r\n                is_before = self.component_is_before(ref_component, connected_component, is_before=is_before)\r\n        return is_before\r\n\r\n    def component_is_after(self, ref_component, component, is_after=False):\r\n        if len(component.connectedBefore)>0:\r\n            for connected_component in component.connectedBefore:\r\n                is_after = True if connected_component is ref_component else False\r\n                is_after = self.component_is_after(ref_component, connected_component, is_after=is_after)\r\n        return is_after\r\n    \r\n    def _classes_are_before(self, ref_classes, component, is_before=False, visited=None):\r\n        if visited is None:\r\n            visited = [component.id]\r\n        if len(component.connectedAfter)>0:\r\n            for connected_component in component.connectedAfter:\r\n                if connected_component.id not in visited:\r\n                    is_before = True if istype(connected_component, ref_classes) else False\r\n                    if is_before==False:\r\n                        is_before = self._classes_are_before(ref_classes, connected_component, is_before, visited)\r\n                else:\r\n                    visited.append(connected_component.id)\r\n                    raise RecursionError(f\"The component of class \\\"{connected_component.__class__.__name__}\\\" with id \\\"{connected_component.id}\\\" is part of a cycle. The following components form a cycle with the \\\"connectedBefore\\\" property: {' -> '.join(visited)}\")\r\n\r\n        return is_before\r\n\r\n    def _classes_are_after(self, ref_classes, component, is_after=False, visited=None):\r\n        if visited is None:\r\n            visited = [component.id]\r\n        if len(component.connectedBefore)>0:\r\n            for connected_component in component.connectedBefore:\r\n                if connected_component.id not in visited:\r\n                    visited.append(connected_component.id)\r\n                    is_after = True if istype(connected_component, ref_classes) else False\r\n                    if is_after==False:\r\n                        is_after = self._classes_are_after(ref_classes, connected_component, is_after, visited)\r\n                else:\r\n                    visited.append(connected_component.id)\r\n                    raise RecursionError(f\"The component of class \\\"{connected_component.__class__.__name__}\\\" with id \\\"{connected_component.id}\\\" is part of a cycle. The following components form a cycle with the \\\"connectedBefore\\\" property: {' -> '.join(visited)}\")\r\n\r\n        return is_after\r\n\r\n    def _get_instance_of_type_before(self, ref_classes, component, found_instance=None, visited=None):\r\n        if found_instance is None:\r\n            found_instance = []\r\n        if visited is None:\r\n            visited = [component.id]\r\n        if len(component.connectedAfter)>0:\r\n            for connected_component in component.connectedAfter:\r\n                if connected_component.id not in visited:\r\n                    visited.append(connected_component.id)\r\n                    is_type = True if istype(connected_component, ref_classes) else False\r\n                    if is_type==False:\r\n                        found_instance = self._get_instance_of_type_before(ref_classes, connected_component, found_instance, visited)\r\n                    else:\r\n                        found_instance.append(connected_component)\r\n                else:\r\n                    visited.append(connected_component.id)\r\n                    raise RecursionError(f\"The component of class \\\"{connected_component.__class__.__name__}\\\" with id \\\"{connected_component.id}\\\" is part of a cycle. The following components form a cycle with the \\\"connectedBefore\\\" property: {' -> '.join(visited)}\")\r\n\r\n        return found_instance\r\n\r\n    def _get_instance_of_type_after(self, ref_classes, component, found_instance=None, visited=None):\r\n        if found_instance is None:\r\n            found_instance = []\r\n        if visited is None:\r\n            visited = [component.id]\r\n        if len(component.connectedBefore)>0:\r\n            for connected_component in component.connectedBefore:\r\n                if connected_component.id not in visited:\r\n                    visited.append(connected_component.id)\r\n                    is_type = True if istype(connected_component, ref_classes) else False\r\n                    if is_type==False:\r\n                        found_instance = self._get_instance_of_type_after(ref_classes, connected_component, found_instance, visited)\r\n                    else:\r\n                        found_instance.append(connected_component)\r\n                else:\r\n                    visited.append(connected_component.id)\r\n                    raise RecursionError(f\"The component of class \\\"{connected_component.__class__.__name__}\\\" with id \\\"{connected_component.id}\\\" is part of a cycle. The following components form a cycle with the \\\"connectedBefore\\\" property: {' -> '.join(visited)}\")\r\n\r\n        return found_instance\r\n\r\n    def _get_flow_placement(self, component):\r\n        \"\"\"\r\n         _______________________________________________________\r\n        |                                                       |\r\n    ref | ------------------------------------> flow direction  | component\r\n        |_______________________________________________________|\r\n\r\n        The above example would yield placement = \"after\"\r\n        \"\"\"\r\n        # leaf_nodes_after, visited = self._get_leaf_nodes_after(component)\r\n        # if leaf_nodes_after is None: #No leaf nodes exists as there is a cycle.\r\n        #     space = [v for v in visited if isinstance(v, BuildingSpace)]\r\n        #     if len(space)>0:\r\n        #         leaf_nodes_after = space\r\n                \r\n\r\n        # if any([isinstance(component, BuildingSpace) for component in leaf_nodes_after]): #We assume that a BuildingSpace object is always present in ventilation systems\r\n        if self._classes_are_after((components.BuildingSpaceSystem, ), component):\r\n            side = \"supply\"\r\n        else:\r\n            side = \"return\"\r\n        return side\r\n\r\n    def _get_component_system_type(self, component):\r\n        \"\"\"\r\n        Assumes that the component only has one supersystem\r\n        \"\"\"\r\n        if component.subSystemOf[0].id in self.system_dict[\"ventilation\"]:\r\n            system_type = \"ventilation\"\r\n        elif component.subSystemOf[0].id in self.system_dict[\"heating\"]:\r\n            system_type = \"heating\"\r\n        elif component.subSystemOf[0].id in self.system_dict[\"cooling\"]:\r\n            system_type = \"cooling\"\r\n        return system_type\r\n\r\n    def get_occupancy_schedule(self, space_id):\r\n        if space_id is not None:\r\n            if f\"{space_id}_occupancy_schedule\" in self.component_dict:\r\n                id = f\"{space_id}_occupancy_schedule\"\r\n            else:\r\n                id = f\"{space_id}| Occupancy schedule\"\r\n        else:\r\n            id = f\"occupancy_schedule\"\r\n        occupancy_schedule = self.component_dict[id]\r\n        return occupancy_schedule\r\n\r\n    def get_indoor_temperature_setpoint_schedule(self, space_id=None):\r\n        if space_id is not None:\r\n            if f\"{space_id}_temperature_setpoint_schedule\" in self.component_dict:\r\n                id = f\"{space_id}_temperature_setpoint_schedule\"\r\n            else:\r\n                id = f\"{space_id}| Temperature setpoint schedule\"\r\n        else:\r\n            id = f\"temperature_setpoint_schedule\"\r\n        indoor_temperature_setpoint_schedule = self.component_dict[id]\r\n        return indoor_temperature_setpoint_schedule\r\n\r\n    def get_co2_setpoint_schedule(self, space_id):\r\n        if space_id is not None:\r\n            if f\"{space_id}_co2_setpoint_schedule\" in self.component_dict:\r\n                id = f\"{space_id}_co2_setpoint_schedule\"\r\n            else:\r\n                id = f\"CO2 setpoint schedule {space_id}\"\r\n        else:\r\n            id = f\"co2_setpoint_schedule\"\r\n        co2_setpoint_schedule = self.component_dict[id]\r\n        return co2_setpoint_schedule\r\n        \r\n    def get_shade_setpoint_schedule(self, space_id):\r\n        if space_id is not None:\r\n            id = f\"{space_id}_shade_setpoint_schedule\"\r\n        else:\r\n            id = f\"shade_setpoint_schedule\"\r\n        shade_setpoint_schedule = self.component_dict[id]\r\n        return shade_setpoint_schedule\r\n\r\n    def get_supply_air_temperature_setpoint_schedule(self, ventilation_id):\r\n        if ventilation_id is not None:\r\n            if f\"{ventilation_id}_supply_air_temperature_schedule\" in self.component_dict:\r\n                id = f\"{ventilation_id}_supply_air_temperature_schedule\"\r\n            else:\r\n                id = f\"{ventilation_id}| Supply air temperature schedule\"\r\n        else:\r\n            id = f\"supply_air_temperature_schedule\"\r\n        supply_air_temperature_setpoint_schedule = self.component_dict[id]\r\n        return supply_air_temperature_setpoint_schedule\r\n\r\n    def get_supply_water_temperature_setpoint_schedule(self, heating_id):\r\n        if heating_id is not None:\r\n            if f\"{heating_id}_supply_water_temperature_schedule\" in self.component_dict:\r\n                id = f\"{heating_id}_supply_water_temperature_schedule\"\r\n            else:\r\n                id = f\"{heating_id}| Supply water temperature schedule\"\r\n        else:\r\n            id = f\"supply_water_temperature_schedule\"\r\n        supply_water_temperature_setpoint_schedule = self.component_dict[id]\r\n        return supply_water_temperature_setpoint_schedule\r\n\r\n    # def get_supply_water_temperature_setpoint_schedule(self, heating_id):\r\n    #     id = f\"{heating_id} Supply water temperature setpoint\"\r\n    #     return self.component_dict[id]\r\n\r\n    def connect_new(self):\r\n        def copy_nodemap(nodemap):\r\n            return {k: v.copy() for k, v in nodemap.items()}\r\n        \r\n        def _prune_recursive(match_node, sp_node, node_map, node_map_list, feasible, comparison_table, ruleset):\r\n            match_node_id = match_node.id if \"id\" in get_object_attributes(match_node) else match_node.__class__.__name__ + \" [\" + str(id(match_node)) +\"]\"\r\n            print(\"-------- ENTERED PRUNE RECURSIVE --------\")\r\n            print(f\"Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n            # node_map_list = []\r\n            if sp_node not in feasible: feasible[sp_node] = set()\r\n            feasible[sp_node].add(match_node)\r\n            # sp_name_attributes = list(sp_node.attributes)\r\n            # sp_nodes_child = [rgetattr(sp_node, sp_attr_name) for sp_attr_name in sp_name_attributes]\r\n            # sp_nodes_child_pairs = [(sp_attr_name, sp_node_child) for (sp_attr_name, sp_node_child) in zip(sp_name_attributes, sp_nodes_child) if sp_node_child is not None and (isinstance(sp_node_child, list) and len(sp_node_child)==0)==False] # Remove None values and lists with length=0\r\n            \r\n\r\n            match_name_attributes = get_object_attributes(match_node)\r\n\r\n\r\n            sp_node_pairs = sp_node.attributes\r\n            sp_node_pairs_ = sp_node._attributes\r\n            sp_node_pairs_list = sp_node._list_attributes\r\n            \r\n            # if len(sp_nodes_child_pairs)==0:\r\n            if len(sp_node_pairs)==0:\r\n                node_map[sp_node] = {match_node}\r\n                node_map_list = [node_map]\r\n\r\n            print(\"sp_node_pairs: \", sp_node_pairs)\r\n\r\n            #Iterate over non-list attributes\r\n            for sp_attr_name, sp_node_child in sp_node_pairs_.items(): #iterate the required attributes/predicates of the signature node\r\n                if sp_attr_name in match_name_attributes: #is there a match with the semantic node?\r\n                    match_node_child = rgetattr(match_node, sp_attr_name)\r\n                    if match_node_child is not None:\r\n                        print(\"IS SP NODE CHILD A LIST?\")\r\n                        rule = ruleset[(sp_node, sp_node_child, sp_attr_name)]\r\n                        pairs, rule_applies, ruleset = rule.apply(match_node_child, ruleset)\r\n\r\n                        # if isinstance(match_node_child, sp_node_child.cls):\r\n                        if len(pairs)==1:\r\n                            filtered_match_node_child, filtered_sp_node_child = next(iter(pairs))\r\n                            # if filtered_sp_node_child not in comparison_table: comparison_table[filtered_sp_node_child] = set()\r\n                            if filtered_match_node_child not in comparison_table[sp_node_child]:\r\n                                comparison_table[sp_node_child].add(filtered_match_node_child)\r\n                                node_map_list, node_map, feasible, comparison_table, prune = _prune_recursive(filtered_match_node_child, filtered_sp_node_child, copy_nodemap(node_map), node_map_list, feasible, comparison_table, ruleset)\r\n                                if prune and isinstance(rule, signature_pattern.Optional)==False:\r\n                                    feasible[sp_node].remove(match_node)\r\n                                    print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                    return node_map_list, node_map, feasible, comparison_table, True\r\n                                else:\r\n                                    for node_map_ in node_map_list:\r\n                                        node_map_[sp_node] = {match_node} #Multiple nodes might be added if multiple branches match\r\n                            elif filtered_match_node_child in feasible[sp_node_child]:\r\n                                print(\"IS FILTERED MATCH NODE CHILD IN FEASIBLE?\")\r\n                                print(node_map_list)\r\n                                node_map_list = [node_map] if len(node_map_list)==0 else node_map_list ####################################################################################\r\n                                for node_map_ in node_map_list:\r\n                                    node_map_[sp_node] = {match_node} #Multiple nodes might be added if multiple branches match\r\n                                    node_map_[sp_node_child] = {filtered_match_node_child}\r\n                            else:\r\n                                feasible[sp_node].remove(match_node)\r\n                                print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                return node_map_list, node_map, feasible, comparison_table, True\r\n                        else:\r\n                            feasible[sp_node].remove(match_node)\r\n                            print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                            return node_map_list, node_map, feasible, comparison_table, True\r\n                    else:\r\n                        if isinstance(sp_node_child, list):# and isinstance(match_node_child, list):\r\n                            for sp_node_child_ in sp_node_child:\r\n                                rule = ruleset[(sp_node, sp_node_child_, sp_attr_name)]\r\n                                if isinstance(rule, signature_pattern.Optional)==False:\r\n                                    feasible[sp_node].remove(match_node)\r\n                                    print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                    return node_map_list, node_map, feasible, comparison_table, True\r\n                        else:\r\n                            rule = ruleset[(sp_node, sp_node_child, sp_attr_name)]\r\n                            if isinstance(rule, signature_pattern.Optional)==False:\r\n                                feasible[sp_node].remove(match_node)\r\n                                print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                return node_map_list, node_map, feasible, comparison_table, True\r\n                else:\r\n                    if isinstance(sp_node_child, list):# and isinstance(match_node_child, list):\r\n                        for sp_node_child_ in sp_node_child:\r\n                            rule = ruleset[(sp_node, sp_node_child_, sp_attr_name)]\r\n                            if isinstance(rule, signature_pattern.Optional)==False:\r\n                                feasible[sp_node].remove(match_node)\r\n                                print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                return node_map_list, node_map, feasible, comparison_table, True\r\n                    else:\r\n                        rule = ruleset[(sp_node, sp_node_child, sp_attr_name)]\r\n                        if isinstance(rule, signature_pattern.Optional)==False:\r\n                            feasible[sp_node].remove(match_node)\r\n                            print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                            return node_map_list, node_map, feasible, comparison_table, True\r\n\r\n\r\n            #Iterate over list attributes\r\n            for sp_attr_name, sp_node_child in sp_node_pairs_list.items(): #iterate the required attributes/predicates of the signature node\r\n                if sp_attr_name in match_name_attributes: #is there a match with the semantic node?\r\n                    match_node_child = rgetattr(match_node, sp_attr_name)\r\n                    if match_node_child is not None:\r\n                        for sp_node_child_ in sp_node_child:\r\n                            rule = ruleset[(sp_node, sp_node_child_, sp_attr_name)]\r\n                            pairs, rule_applies, ruleset = rule.apply(match_node_child, ruleset)\r\n                            found = False\r\n                            new_node_map_list = []\r\n                            for filtered_match_node_child, filtered_sp_node_child in pairs:\r\n                                # if isinstance(match_node_child_, sp_node_child_.cls):\r\n                                # if filtered_sp_node_child not in comparison_table: comparison_table[filtered_sp_node_child] = set()\r\n                                print(\"IS FILTERED MATCH NODE CHILD IN COMPARISON TABLE?\")\r\n                                print(filtered_match_node_child in comparison_table[sp_node_child_])\r\n                                if filtered_match_node_child not in comparison_table[sp_node_child_]:#filtered_sp_node_child  #working sp_node_child_\r\n                                    comparison_table[sp_node_child_].add(filtered_match_node_child)\r\n                                    # if found==True:\r\n                                    #     node_map = copy_nodemap(node_map)\r\n                                    \r\n                                    node_map_list_, node_map, feasible, comparison_table, prune = _prune_recursive(filtered_match_node_child, filtered_sp_node_child, copy_nodemap(node_map), node_map_list.copy(), feasible, comparison_table, ruleset)\r\n                                        \r\n                                    if found and prune==False:# and isinstance(rule, signature_pattern.MultipleMatches)==False:\r\n                                        # node_map_list.extend(node_map_list_)\r\n                                        # node_map_list.extend(node_map_)\r\n                                        # feasible[sp_node].remove(match_node)\r\n                                        name = match_node.id if \"id\" in get_object_attributes(match_node) else match_node.__class__.__name__\r\n                                        warnings.warn(f\"Multiple matches found for context signature node \\\"{sp_node.id}\\\" and semantic model node \\\"{name}\\\".\")\r\n                                        # return node_map, feasible, comparison_table, True\r\n                                    \r\n                                    if prune==False: #be careful here - multiple branches might match - how to account for?\r\n                                        print(\"node map list\")\r\n                                        print(new_node_map_list)\r\n                                        new_node_map_list.extend(node_map_list_)\r\n                                        found = True\r\n\r\n                                elif filtered_match_node_child in feasible[sp_node_child_]:\r\n                                    node_map[sp_node_child_] = {filtered_match_node_child}\r\n                                    new_node_map_list.extend([node_map])\r\n                                    found = True\r\n\r\n                            if found==False and isinstance(rule, signature_pattern.Optional)==False:\r\n                                feasible[sp_node].remove(match_node)\r\n                                print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                return node_map_list, node_map, feasible, comparison_table, True\r\n                            else:\r\n                                node_map_list = new_node_map_list\r\n                                print(\"printing node_map_list:\")\r\n                                for i in node_map_list:\r\n                                    print(\"---\")\r\n                                    for k,v in i.items():\r\n                                        x = [vv.id if \"id\" in get_object_attributes(vv) else vv.__class__.__name__ for vv in v]\r\n                                        ids = [id(vv) for vv in v]\r\n                                        aa = f\"    :{k.id}, {x}, {ids}\"\r\n                                        print(aa)\r\n                                for node_map_ in node_map_list:\r\n                                    print(sp_node.id)\r\n                                    print(sp_node.cls)\r\n                                    node_map_[sp_node] = set() if sp_node not in node_map_ else node_map_[sp_node]\r\n                                    node_map_[sp_node].add(match_node) #Multiple nodes might be added if multiple branches match\r\n                    else:\r\n                        if isinstance(sp_node_child, list):# and isinstance(match_node_child, list):\r\n                            for sp_node_child_ in sp_node_child:\r\n                                rule = ruleset[(sp_node, sp_node_child_, sp_attr_name)]\r\n                                if isinstance(rule, signature_pattern.Optional)==False:\r\n                                    feasible[sp_node].remove(match_node)\r\n                                    print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                    return node_map_list, node_map, feasible, comparison_table, True\r\n                        else:\r\n                            rule = ruleset[(sp_node, sp_node_child, sp_attr_name)]\r\n                            if isinstance(rule, signature_pattern.Optional)==False:\r\n                                feasible[sp_node].remove(match_node)\r\n                                print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                return node_map_list, node_map, feasible, comparison_table, True\r\n                else:\r\n                    if isinstance(sp_node_child, list):# and isinstance(match_node_child, list):\r\n                        for sp_node_child_ in sp_node_child:\r\n                            rule = ruleset[(sp_node, sp_node_child_, sp_attr_name)]\r\n                            if isinstance(rule, signature_pattern.Optional)==False:\r\n                                feasible[sp_node].remove(match_node)\r\n                                print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                                return node_map_list, node_map, feasible, comparison_table, True\r\n                    else:\r\n                        rule = ruleset[(sp_node, sp_node_child, sp_attr_name)]\r\n                        if isinstance(rule, signature_pattern.Optional)==False:\r\n                            feasible[sp_node].remove(match_node)\r\n                            print(f\"================== PRUNING --- Match node: {match_node_id}, SP node: {sp_node.id}\")\r\n                            return node_map_list, node_map, feasible, comparison_table, True\r\n            print(\"Returning node_map_list:\")\r\n            for i in node_map_list:\r\n                print(\"---\")\r\n                for k,v in i.items():\r\n                    x = [vv.id if \"id\" in get_object_attributes(vv) else vv.__class__.__name__ for vv in v]\r\n                    ids = [id(vv) for vv in v]\r\n                    aa = f\"    :{k.id}, {x}, {ids}\"\r\n                    print(aa)\r\n            return node_map_list, node_map, feasible, comparison_table, False\r\n\r\n        def match(group, node_map_, sp, cg, new_ig):\r\n            can_match = all([group[sp_node_]==node_map_[sp_node_] if len(group[sp_node_])!=0 and len(node_map_[sp_node_])!=0 else True for sp_node_ in sp.nodes])\r\n            is_match = False\r\n            if can_match:\r\n                print(\"CAN MATCH******************\")\r\n                \r\n                for k,v in group.items():\r\n                    x = [vv.id if \"id\" in get_object_attributes(vv) else vv.__class__.__name__ for vv in v]\r\n                    ids = [id(vv) for vv in v]\r\n                    aa = f\"    :{k.id}, {x}, {ids}\"\r\n                    print(aa)\r\n                print(\"---------------------\")\r\n                node_map_no_None = {sp_node_: match_node_set for sp_node_,match_node_set in node_map_.items() if len(match_node_set)!=0}\r\n                for k,v in node_map_no_None.items():\r\n                    x = [vv.id if \"id\" in get_object_attributes(vv) else vv.__class__.__name__ for vv in v]\r\n                    ids = [id(vv) for vv in v]\r\n                    aa = f\"    :{k.id}, {x}, {ids}\"\r\n                    print(aa)\r\n                is_match = False\r\n                break_loop = False\r\n                # Check if any of the node_map predicates match with the group\r\n                for sp_node_, match_node_set_nm in node_map_no_None.items():\r\n                    attributes = sp_node_.attributes\r\n                    for attr, subject in attributes.items():\r\n                        for match_node_nm in match_node_set_nm:\r\n                            node_map_child = getattr(match_node_nm, attr)\r\n                            if node_map_child is not None and (isinstance(node_map_child, list) and len(node_map_child)==0)==False:\r\n                                if isinstance(node_map_child, list)==False:\r\n                                    node_map_child_ = [node_map_child]\r\n                                else:\r\n                                    node_map_child_ = node_map_child\r\n                                print(\"attr: \", attr)\r\n                                if isinstance(subject, list)==False:\r\n                                    subject_ = [subject]\r\n                                else:\r\n                                    subject_ = subject\r\n\r\n                                \r\n\r\n                                for subject__ in subject_:\r\n                                    print(\"subject id:\", subject__.id)\r\n                                    group_child_ = group[subject__]\r\n                                    if len(group_child_)!=0 and len(node_map_child_)!=0:\r\n                                        break_loop = True\r\n                                        for group_child__ in group_child_:\r\n                                            print(\"group_child__: \", group_child__)\r\n                                            for node_map_child__ in node_map_child_:\r\n                                                print(\"node_map_child__: \", node_map_child__)\r\n                                                if group_child__ is node_map_child__:\r\n                                                    is_match = True\r\n                                                if is_match:\r\n                                                    break\r\n                                            if is_match:\r\n                                                break\r\n                                    if break_loop:\r\n                                        break\r\n                                if break_loop:\r\n                                    break\r\n                            if break_loop:\r\n                                break\r\n                        if break_loop:\r\n                            break\r\n                    if break_loop:\r\n                        break\r\n                        \r\n                if is_match:\r\n                    print(\"IS MATCH******* node to group ***********\")\r\n                    for sp_node__, match_node__ in node_map_no_None.items(): #Add all elements\r\n                        group[sp_node__] = match_node__\r\n                    if all([len(group[sp_node_])!=0 for sp_node_ in sp.nodes]):\r\n                        cg.append(group)\r\n                        new_ig.remove(group)\r\n                        # new_ig.pop(i_group)\r\n                    # break\r\n                else:\r\n                    print(\"Entered group to node\")\r\n                    group_no_None = {sp_node_: match_node_set for sp_node_,match_node_set in group.items() if len(match_node_set)!=0}\r\n                    break_loop = False\r\n                    # Check if any of the group predicates match with the node_map\r\n                    for sp_node_, match_node_set_group in group_no_None.items():\r\n                        attributes = sp_node_.attributes\r\n                        for attr, subject in attributes.items():\r\n                            for match_node_group in match_node_set_group:\r\n                                print(\"match_node_group: \", match_node_group)\r\n                                group_child = getattr(match_node_group, attr)\r\n                                print(\"group_child: \", group_child)\r\n                                if group_child is not None and (isnumeric(group_child) and math.isnan(group_child))==False and (isinstance(group_child, list) and len(group_child)==0)==False:\r\n                                    if isinstance(group_child, list)==False:\r\n                                        group_child_ = [group_child]\r\n                                    else:\r\n                                        group_child_ = group_child\r\n                                    print(\"attr: \", attr)\r\n                                    if isinstance(subject, list)==False:\r\n                                        subject_ = [subject]\r\n                                    else:\r\n                                        subject_ = subject\r\n                                    print(\"subject\", subject_)\r\n\r\n                                    for subject__ in subject_:\r\n                                        node_map_child_ = node_map_[subject__]\r\n                                        if len(group_child_)!=0 and len(node_map_child_)!=0:\r\n                                            break_loop = True\r\n                                            for group_child__ in group_child_:\r\n                                                print(\"group_child__: \", group_child__)\r\n                                                for node_map_child__ in node_map_child_:\r\n                                                    print(\"node_map_child__: \", node_map_child__)\r\n                                                    if group_child__ is node_map_child__:\r\n                                                        is_match = True\r\n                                                    if is_match:\r\n                                                        break\r\n                                                if is_match:\r\n                                                    break\r\n                                        if break_loop:\r\n                                            break\r\n\r\n                                    if break_loop:\r\n                                        break\r\n                                if break_loop:\r\n                                    break\r\n                            if break_loop:\r\n                                break\r\n                        if break_loop:\r\n                            break\r\n                    if is_match:\r\n                        print(\"IS MATCH*******group to node***********\")\r\n                        for sp_node__, match_node__ in node_map_no_None.items(): #Add all elements\r\n                            group[sp_node__] = match_node__\r\n                        if all([len(group[sp_node_])!=0 for sp_node_ in sp.nodes]):\r\n                            cg.append(group)\r\n                            new_ig.remove(group)\r\n            return is_match, group, cg, new_ig\r\n\r\n        classes = [cls[1] for cls in inspect.getmembers(components, inspect.isclass) if (issubclass(cls[1], (System, )) and hasattr(cls[1], \"sp\"))]\r\n        # complete_groups = []\r\n        # incomplete_groups = []\r\n        complete_groups = {}\r\n        incomplete_groups = {}\r\n        counter = 0\r\n        for component_cls in classes:\r\n            complete_groups[component_cls] = {}\r\n            incomplete_groups[component_cls] = {}\r\n            sps = component_cls.sp\r\n            for sp in sps:\r\n                print(\"HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\")\r\n                print(\"HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\")\r\n                print(\"HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\")\r\n                print(\"HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\")\r\n                print(\"HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\")\r\n                print(sp.ownedBy)\r\n                complete_groups[component_cls][sp] = []\r\n                incomplete_groups[component_cls][sp] = []\r\n                cg = complete_groups[component_cls][sp]\r\n                ig = incomplete_groups[component_cls][sp]\r\n                feasible = {sp_node: set() for sp_node in sp.nodes}\r\n                comparison_table = {sp_node: set() for sp_node in sp.nodes}\r\n                for sp_node in sp.nodes:\r\n                    l = list(sp_node.cls)\r\n                    l.remove(signature_pattern.NodeBase)\r\n                    l = tuple(l)\r\n                    match_nodes = [c for c in self.object_dict.values() if (isinstance(c, l))]\r\n                    print(\"MATCH NODES:\")\r\n                    for k,v in self.object_dict.items():\r\n                        if v in match_nodes:\r\n                            print(k)\r\n                        \r\n                    for match_node in match_nodes:\r\n                        node_map = {sp_node_: set() for sp_node_ in sp.nodes}\r\n                        # print(\"original\")\r\n                        # for sp_node_ in sp.nodes:\r\n                        #     print(id(node_map[sp_node_]))\r\n                        \r\n                        # print(\"copy\")\r\n                        # nm_copy = node_map.copy()\r\n                        # for sp_node_ in sp.nodes:\r\n                        #     print(id(nm_copy[sp_node_]))\r\n                        # aaa\r\n                        node_map_list = []\r\n                        if match_node not in comparison_table[sp_node]:\r\n                            sp.reset_ruleset()\r\n                            node_map_list, node_map, feasible, comparison_table, prune = _prune_recursive(match_node, sp_node, node_map, node_map_list, feasible, comparison_table, sp.ruleset)\r\n                            print(\"==============AFTER===============\")\r\n                            print(\"==============AFTER===============\")\r\n                            print(\"==============AFTER===============\")\r\n                            print(\"==============AFTER===============\")\r\n                            print(\"==============AFTER===============\")\r\n                            # if component_cls is components.DamperSystem and prune==False:\r\n                            #     counter += 1\r\n\r\n                            # if component_cls is components.DamperSystem and counter==2:\r\n                            #     print(\"aallalalalal\")\r\n                            #     aaaaa\r\n\r\n                            \r\n                        elif match_node in feasible[sp_node]:\r\n                            node_map[sp_node] = {match_node}\r\n                            node_map_list = [node_map]\r\n                            print(\"match node in feasible\")\r\n                            print(match_node)\r\n                            print(node_map_list)\r\n                            # for node_map_ in node_map_list:\r\n                            #     node_map_[sp_node].add(match_node)\r\n                            prune = False\r\n                        \r\n                        if prune==False:\r\n                            print(\"After pruning: \", node_map_list)\r\n                            modeled_nodes = []\r\n                            for node_map_ in node_map_list:\r\n                                print(type(node_map_))\r\n                                \r\n                                node_map_set = set()\r\n                                for sp_modeled_node in sp.modeled_nodes:\r\n                                    node_map_set.update(node_map_[sp_modeled_node])\r\n                                modeled_nodes.append(node_map_set)\r\n                            print(\"Modeled nodes: \", modeled_nodes)\r\n                            #Make sure that the modeled nodes are not part of any other group\r\n                            node_map_list_new = []\r\n                            for i,(node_map_, node_map_set) in enumerate(zip(node_map_list, modeled_nodes)):\r\n                                active_set = node_map_set\r\n                                passive_set = set().union(*[v for k,v in enumerate(modeled_nodes) if k!=i])\r\n                                if len(active_set.intersection(passive_set))==0:\r\n                                    node_map_list_new.append(node_map_)\r\n                            node_map_list = node_map_list_new\r\n\r\n                            print(\"node_map_list after pruning: \", node_map_list)\r\n                            \r\n                               \r\n                            for node_map_ in node_map_list:\r\n                                if all([len(match_node_set)!=0 for sp_node_,match_node_set in node_map_.items()]):#all([sp_node_ in node_map_ for sp_node_ in sp.nodes]):\r\n                                    print(\"adding to complete group\")\r\n                                    cg.append(node_map_)\r\n                                else:\r\n                                    if len(ig)==0: #If there are no groups in the incomplete group list, add the node map\r\n                                        ig.append(node_map_)\r\n                                    else:\r\n                                        new_ig = ig.copy()\r\n                                        is_match_ = False\r\n                                        for group in ig: #Iterate over incomplete groups\r\n                                            is_match, group, cg, new_ig = match(group, node_map_, sp, cg, new_ig)\r\n                                            if is_match:\r\n                                                is_match_ = True\r\n                                            print(\"group\")\r\n                                            print(group)\r\n                                            \r\n                                                        # break\r\n                                        if is_match_==False:\r\n                                            new_ig.append(node_map_)\r\n                                        ig = new_ig\r\n                # After all match nodes have been processed, we add the nodemap to the complete group if all required nodes are matched\r\n                new_ig = ig.copy()\r\n                for group in ig: #Iterate over incomplete groups\r\n                    if all([len(group[sp_node_])!=0 for sp_node_ in sp.required_nodes]):\r\n                        cg.append(group)\r\n                        print(new_ig)\r\n                        new_ig.remove(group)\r\n                ig = new_ig\r\n            \r\n\r\n        # Sort after priority within each group\r\n        for component_cls, sps in complete_groups.items():\r\n            complete_groups[component_cls] = {sp: groups for sp, groups in sorted(complete_groups[component_cls].items(), key=lambda item: item[0].priority, reverse=True)}\r\n\r\n        # Sort after priority between classes\r\n        complete_groups = {k: v for k, v in sorted(complete_groups.items(), key=lambda item: max(sp.priority for sp in item[1]), reverse=True)}\r\n        for i, (component_cls, sps) in enumerate(complete_groups.items()):\r\n            i = 0\r\n            for sp, groups in sps.items():\r\n                print(\"===================================\")\r\n                print(sp.ownedBy)\r\n                i+= 1\r\n                for group in groups:\r\n                    print(\"GROUP******************\")\r\n                    for cs_node, match_node_set in group.items():\r\n                        for match_node in match_node_set:\r\n                            print(\"-------\")\r\n                            print(len(match_node_set))\r\n                            print(\"cs_node: \", cs_node.id, [cc.__name__ for cc in cs_node.cls])\r\n                            print(\"sem: \", match_node.id) if \"id\" in get_object_attributes(match_node) else print(\"sem: \", match_node.__class__.__name__, id(match_node))\r\n\r\n\r\n\r\n        #############################################\r\n        # Create instances\r\n        self.instance_map = {}\r\n        self.instance_map_reversed = {}\r\n        instance_to_group_map = {}\r\n        modeled_components = set()\r\n        for i, (component_cls, sps) in enumerate(complete_groups.items()):\r\n            for sp, groups in sps.items():\r\n                for group in groups:\r\n                    modeled_match_nodes = {c for sp_node in sp.modeled_nodes for c in group[sp_node]}\r\n                    print(\"hh\")\r\n                    print(modeled_match_nodes)\r\n                    if len(modeled_components.intersection(modeled_match_nodes))==0:\r\n                        modeled_components |= modeled_match_nodes #Union/add set\r\n                        # Naive aproach:\r\n                        # Add the first model that matches\r\n                        if len(modeled_match_nodes)==1:\r\n                            component = next(iter(modeled_match_nodes))\r\n                            id_ = component.id\r\n                            base_kwargs = self.get_object_properties(component)\r\n                            extension_kwargs = {\"id\": id_}\r\n                        else:\r\n                            id_ = \"\"\r\n                            modeled_match_nodes_sorted = sorted(modeled_match_nodes, key=lambda x: x.id)\r\n                            for component in modeled_match_nodes_sorted:\r\n                                # id_ += f\"({component.id})\"\r\n                                id_ += f\"[{component.id}]\"\r\n                            base_kwargs = {}\r\n                            extension_kwargs = {\"id\": id_}\r\n                            for component in modeled_match_nodes_sorted:\r\n                                kwargs = self.get_object_properties(component)\r\n                                base_kwargs.update(kwargs)\r\n                        ####\r\n                        base_kwargs.update(extension_kwargs)\r\n                        component = component_cls(**base_kwargs)\r\n                        ####\r\n                        # component = component_cls(id=id_)\r\n                        instance_to_group_map[component] = (modeled_match_nodes, (component_cls, sp, group))\r\n                        self.instance_map[component] = modeled_match_nodes\r\n                        for modeled_match_node in modeled_match_nodes:\r\n                            self.instance_map_reversed[modeled_match_node] = component\r\n\r\n        # Make connections and set parameters\r\n        for component, (modeled_match_nodes, (component_cls, sp, group)) in instance_to_group_map.items():\r\n            \r\n\r\n            # Make connections\r\n            for key, (sp_node, source_keys) in sp.inputs.items():\r\n                match_node_set = group[sp_node]\r\n                if match_node_set.issubset(modeled_components):\r\n                    #Find group\r\n                    for component_inner, (modeled_match_nodes_inner, group_inner) in instance_to_group_map.items():\r\n                        if match_node_set.issubset(modeled_match_nodes_inner) and component_inner is not component:\r\n                            print(\"---\")\r\n                            print(component_inner)\r\n                            print(component)\r\n                            print([source_key for c, source_key in source_keys.items()])\r\n                            source_key = [source_key for c, source_key in source_keys.items() if isinstance(component_inner, c)][0]\r\n                            self.add_connection(component_inner, component, source_key, key)\r\n                else:\r\n                    for match_node in match_node_set:\r\n                        warnings.warn(f\"\\nThe component with class \\\"{match_node.__class__.__name__}\\\" and id \\\"{match_node.id}\\\" is not modeled. The input \\\"{key}\\\" of the component with class \\\"{component_cls.__name__}\\\" and id \\\"{component.id}\\\" is not connected.\\n\")\r\n        \r\n            # Set parameters\r\n            for key, node in sp.parameters.items():\r\n                if len(group[node])==1:\r\n                    (value, ) = group[node] #unpack set\r\n                    print(node.id)\r\n                    print(\"key: \", key)\r\n                    print(value)\r\n                    rsetattr(component, key, value)\r\n                    print(rgetattr(component, key))\r\n        \r\n        \r\n        ##############################################\r\n\r\n\r\n\r\n\r\n    def connect(self):\r\n        \"\"\"\r\n        Connects component instances using the saref4syst extension.\r\n        \"\"\"\r\n        logger.info(\"[Model Class] : Entered in Connect Function\")\r\n\r\n        space_instances = self.get_component_by_class(self.component_dict, components.BuildingSpaceSystem)\r\n        damper_instances = self.get_component_by_class(self.component_dict, components.DamperSystem)\r\n        space_heater_instances = self.get_component_by_class(self.component_dict, components.SpaceHeaterSystem)\r\n        valve_instances = self.get_component_by_class(self.component_dict, components.ValveSystem)\r\n        coil_heating_instances = self.get_component_by_class(self.component_dict, components.CoilHeatingSystem)\r\n        coil_cooling_instances = self.get_component_by_class(self.component_dict, components.CoilCoolingSystem)\r\n        air_to_air_heat_recovery_instances = self.get_component_by_class(self.component_dict, components.AirToAirHeatRecoverySystem)\r\n        fan_instances = self.get_component_by_class(self.component_dict, components.FanSystem)\r\n        controller_instances = self.get_component_by_class(self.component_dict, base.Controller)\r\n        shading_device_instances = self.get_component_by_class(self.component_dict, components.ShadingDeviceSystem)\r\n        sensor_instances = self.get_component_by_class(self.component_dict, components.SensorSystem, filter=lambda v: isinstance(v.observes, base.Pressure)==False)\r\n        meter_instances = self.get_component_by_class(self.component_dict, components.MeterSystem)\r\n        node_instances = self.get_component_by_class(self.component_dict, components.FlowJunctionSystem)\r\n        # flow_temperature_change_types = (AirToAirHeatRecoverySystem, FanSystem, CoilHeatingSystem, CoilCoolingSystem)\r\n\r\n\r\n\r\n        flow_temperature_change_types = (components.AirToAirHeatRecoverySystem, components.CoilHeatingSystem, components.CoilCoolingSystem)\r\n        flow_change_types = (components.FlowJunctionSystem, )\r\n\r\n        outdoor_environment = self.component_dict[\"outdoor_environment\"]\r\n        \r\n        for id, heating_system in self.system_dict[\"heating\"].items():\r\n            supply_water_temperature_setpoint_schedule = self.get_supply_water_temperature_setpoint_schedule(id)\r\n            self.add_connection(outdoor_environment, supply_water_temperature_setpoint_schedule, \"outdoorTemperature\", \"outdoorTemperature\")\r\n\r\n        for space in space_instances:\r\n            dampers = self.get_dampers_by_space(space)\r\n            valves = self.get_valves_by_space(space)\r\n            shading_devices = self.get_shading_devices_by_space(space)\r\n\r\n            for damper in dampers:\r\n                if space in damper.connectedBefore:\r\n                    self.add_connection(damper, space, \"airFlowRate\", \"supplyAirFlowRate\")\r\n                    self.add_connection(damper, space, \"damperPosition\", \"supplyDamperPosition\")\r\n                    ventilation_system = damper.subSystemOf[0] #Logic might be needed here in the future if multiple systems are returned\r\n                    supply_air_temperature_setpoint_schedule = self.get_supply_air_temperature_setpoint_schedule(ventilation_system.id)\r\n                    self.add_connection(supply_air_temperature_setpoint_schedule, space, \"scheduleValue\", \"supplyAirTemperature\")\r\n                    \r\n                elif space in damper.connectedAfter:\r\n                    self.add_connection(damper, space, \"airFlowRate\", \"returnAirFlowRate\")\r\n                    self.add_connection(damper, space, \"damperPosition\", \"returnDamperPosition\")\r\n            \r\n            for valve in valves:\r\n                self.add_connection(valve, space, \"valvePosition\", \"valvePosition\")\r\n                heating_system = valve.subSystemOf[0] #Logic might be needed here in the fututre if multiple systems are returned\r\n                supply_water_temperature_setpoint_schedule = self.get_supply_water_temperature_setpoint_schedule(heating_system.id)\r\n                self.add_connection(supply_water_temperature_setpoint_schedule, space, \"scheduleValue\", \"supplyWaterTemperature\")\r\n\r\n            for shading_device in shading_devices:\r\n                self.add_connection(shading_device, space, \"shadePosition\", \"shadePosition\")\r\n\r\n                        \r\n            self.add_connection(outdoor_environment, space, \"globalIrradiation\", \"globalIrradiation\")\r\n            self.add_connection(outdoor_environment, space, \"outdoorTemperature\", \"outdoorTemperature\")\r\n            occupancy_schedule = self.get_occupancy_schedule(space.id)\r\n            self.add_connection(occupancy_schedule, space, \"scheduleValue\", \"numberOfPeople\")\r\n            \r\n        for damper in damper_instances:\r\n            controllers = self.get_controllers_by_space(damper.isContainedIn)\r\n            controller = [controller for controller in controllers if isinstance(controller.observes, base.Co2)]\r\n            if len(controller)!=0:\r\n                controller = controller[0]\r\n                self.add_connection(controller, damper, \"inputSignal\", \"damperPosition\")\r\n            else:\r\n                filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 2)), \"test\", \"data\", \"time_series_data\", \"OE20-601b-2_Damper position.csv\")\r\n                warnings.warn(f\"No CO2 controller found in BuildingSpace: \\\"{damper.isContainedIn.id}\\\".\\nAssigning historic values by file: \\\"{filename}\\\"\")\r\n                if \" Damper position data\" not in self.component_dict:\r\n                    damper_position_schedule = components.TimeSeriesInputSystem(id=\" Damper position data\", filename=filename)\r\n                    self._add_component(damper_position_schedule)\r\n                else:\r\n                    damper_position_schedule = self.component_dict[\" Damper position data\"]\r\n                self.add_connection(damper_position_schedule, damper, \"damperPosition\", \"damperPosition\")\r\n\r\n        for space_heater in space_heater_instances:\r\n            valve = space_heater.connectedAfter[0] #The space heater is currently a terminal component meaning that only 1 component can be connected\r\n            self.add_connection(space, space_heater, \"indoorTemperature\", \"indoorTemperature\") \r\n            self.add_connection(valve, space_heater, \"waterFlowRate\", \"waterFlowRate\")\r\n            heating_system = [v for v in space_heater.subSystemOf if v in self.system_dict[\"heating\"].values()][0]\r\n            supply_water_temperature_setpoint_schedule = self.get_supply_water_temperature_setpoint_schedule(heating_system.id)\r\n            self.add_connection(supply_water_temperature_setpoint_schedule, space_heater, \"scheduleValue\", \"supplyWaterTemperature\")\r\n            \r\n        for valve in valve_instances:\r\n            controllers = self.get_controllers_by_space(valve.isContainedIn)\r\n            controller = [controller for controller in controllers if isinstance(controller.observes, base.Temperature)]\r\n            # property_ = valve.hasProperty\r\n            # controller = property_.isControlledBy\r\n            if len(controller)!=0:\r\n                controller = controller[0]\r\n                self.add_connection(controller, valve, \"inputSignal\", \"valvePosition\")\r\n            else:\r\n                filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 2)), \"test\", \"data\", \"time_series_data\", \"OE20-601b-2_Space heater valve position.csv\")\r\n                warnings.warn(f\"No Temperature controller found in BuildingSpace: \\\"{valve.isContainedIn.id}\\\".\\nAssigning historic values by file: \\\"{filename}\\\"\")\r\n                if \"Valve position schedule\" not in self.component_dict:\r\n                    valve_position_schedule = components.TimeSeriesInputSystem(id=\"Valve position schedule\", filename=filename)\r\n                    self._add_component(valve_position_schedule)\r\n                else:\r\n                    valve_position_schedule = self.component_dict[\"Valve position schedule\"]\r\n                self.add_connection(valve_position_schedule, valve, \"valvePosition\", \"valvePosition\")\r\n\r\n        for coil_heating in coil_heating_instances:\r\n            instance_of_type_before = self._get_instance_of_type_before(flow_temperature_change_types, coil_heating)\r\n            if len(instance_of_type_before)==0:\r\n                self.add_connection(outdoor_environment, coil_heating, \"outdoorTemperature\", \"inletAirTemperature\")\r\n            else:\r\n                instance_of_type_before = instance_of_type_before[0]\r\n                if isinstance(instance_of_type_before, components.AirToAirHeatRecoverySystem):\r\n                    self.add_connection(instance_of_type_before, coil_heating, \"primaryTemperatureOut\", \"inletAirTemperature\")\r\n                elif isinstance(instance_of_type_before, components.FanSystem):\r\n                    self.add_connection(instance_of_type_before, coil_heating, \"outletAirTemperature\", \"inletAirTemperature\")\r\n                elif isinstance(instance_of_type_before, components.CoilHeatingSystem):\r\n                    self.add_connection(instance_of_type_before, coil_heating, \"outletAirTemperature\", \"inletAirTemperature\")\r\n                elif isinstance(instance_of_type_before, components.CoilCoolingSystem):\r\n                    self.add_connection(instance_of_type_before, coil_heating, \"outletAirTemperature\", \"inletAirTemperature\")\r\n            ventilation_system = [v for v in coil_heating.subSystemOf if v in self.system_dict[\"ventilation\"].values()][0]\r\n            supply_air_temperature_setpoint_schedule = self.get_supply_air_temperature_setpoint_schedule(ventilation_system.id)\r\n            self.add_connection(supply_air_temperature_setpoint_schedule, coil_heating, \"scheduleValue\", \"outletAirTemperatureSetpoint\")\r\n            # node = self._get_instance_of_type_after((FlowJunctionSystem, ), coil_heating)[0]\r\n            supply_node = [node for node in node_instances if node.operationMode==\"supply\"][0]\r\n            self.add_connection(supply_node, coil_heating, \"flowRate\", \"airFlowRate\")\r\n\r\n        for coil_cooling in coil_cooling_instances:\r\n            instance_of_type_before = self._get_instance_of_type_before(flow_temperature_change_types, coil_cooling)\r\n            if len(instance_of_type_before)==0:\r\n                self.add_connection(outdoor_environment, coil_cooling, \"outdoorTemperature\", \"inletAirTemperature\")\r\n            else:\r\n                instance_of_type_before = instance_of_type_before[0]\r\n                if isinstance(instance_of_type_before, components.AirToAirHeatRecoverySystem):\r\n                    self.add_connection(instance_of_type_before, coil_cooling, \"primaryTemperatureOut\", \"inletAirTemperature\")\r\n                elif isinstance(instance_of_type_before, components.FanSystem):\r\n                    self.add_connection(instance_of_type_before, coil_cooling, \"outletAirTemperature\", \"inletAirTemperature\")\r\n                elif isinstance(instance_of_type_before, components.CoilHeatingSystem):\r\n                    self.add_connection(instance_of_type_before, coil_cooling, \"outletAirTemperature\", \"inletAirTemperature\")\r\n                elif isinstance(instance_of_type_before, components.CoilCoolingSystem):\r\n                    self.add_connection(instance_of_type_before, coil_cooling, \"outletAirTemperature\", \"inletAirTemperature\")\r\n            ventilation_system = [v for v in coil_cooling.subSystemOf if v in self.system_dict[\"ventilation\"].values()][0]\r\n            supply_air_temperature_setpoint_schedule = self.get_supply_air_temperature_setpoint_schedule(ventilation_system.id)\r\n            self.add_connection(supply_air_temperature_setpoint_schedule, coil_cooling, \"scheduleValue\", \"outletAirTemperatureSetpoint\")\r\n            supply_node = [node for node in node_instances if node.operationMode==\"supply\"][0]\r\n            self.add_connection(supply_node, coil_cooling, \"flowRate\", \"airFlowRate\")\r\n\r\n        for air_to_air_heat_recovery in air_to_air_heat_recovery_instances:\r\n            ventilation_system = air_to_air_heat_recovery.subSystemOf[0]\r\n            node_S = [v for v in ventilation_system.hasSubSystem if isinstance(v, components.FlowJunctionSystem) and v.operationMode == \"supply\"][0]\r\n            node_E = [v for v in ventilation_system.hasSubSystem if isinstance(v, components.FlowJunctionSystem) and v.operationMode == \"return\"][0]\r\n            self.add_connection(outdoor_environment, air_to_air_heat_recovery, \"outdoorTemperature\", \"primaryTemperatureIn\")\r\n            self.add_connection(node_E, air_to_air_heat_recovery, \"flowTemperatureOut\", \"secondaryTemperatureIn\")\r\n            self.add_connection(node_S, air_to_air_heat_recovery, \"flowRate\", \"primaryAirFlowRate\")\r\n            self.add_connection(node_E, air_to_air_heat_recovery, \"flowRate\", \"secondaryAirFlowRate\")\r\n\r\n            supply_air_temperature_setpoint_schedule = self.get_supply_air_temperature_setpoint_schedule(ventilation_system.id)\r\n            self.add_connection(supply_air_temperature_setpoint_schedule, air_to_air_heat_recovery, \"scheduleValue\", \"primaryTemperatureOutSetpoint\")\r\n\r\n        for fan in fan_instances:\r\n            side = self._get_flow_placement(component=fan)\r\n            if side==\"supply\":\r\n                nodes = [node for node in node_instances if node.operationMode==\"supply\"]\r\n            else:\r\n                nodes = [node for node in node_instances if node.operationMode==\"return\"]\r\n            \r\n            if len(nodes)==0:\r\n                raise(Exception(\"No Nodes after or before fanFan\"))\r\n            else:\r\n                node = nodes[0]\r\n                self.add_connection(node, fan, \"flowRate\", \"airFlowRate\")\r\n\r\n        for controller in controller_instances:\r\n            property_ = controller.observes\r\n            property_of = property_.isPropertyOf\r\n            measuring_device = property_.isObservedBy\r\n            if isinstance(controller, components.RulebasedControllerSystem)==False:\r\n                if isinstance(property_of, base.BuildingSpace):\r\n                    if isinstance(property_, base.Temperature):\r\n                        self.add_connection(measuring_device, controller, \"indoorTemperature\", \"actualValue\")\r\n                        setpoint_schedule = self.get_indoor_temperature_setpoint_schedule(property_of.id)\r\n                    elif isinstance(property_, base.Co2):\r\n                        self.add_connection(measuring_device, controller, \"indoorCo2Concentration\", \"actualValue\")\r\n                        setpoint_schedule = self.get_co2_setpoint_schedule(property_of.id)\r\n                elif isinstance(property_of, components.CoilHeatingSystem):\r\n                    system = [v for v in property_of.subSystemOf if v in self.system_dict[\"heating\"].values()][0]\r\n                    setpoint_schedule = self.get_supply_air_temperature_setpoint_schedule(system.id)\r\n                elif isinstance(property_of, components.CoilCoolingSystem):\r\n                    system = [v for v in property_of.subSystemOf if v in self.system_dict[\"cooling\"].values()][0]\r\n                    setpoint_schedule = self.get_supply_air_temperature_setpoint_schedule(system.id)\r\n                else:\r\n                    logger.error(\"[Model Class] : \" f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n                    raise Exception(f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n                self.add_connection(setpoint_schedule, controller, \"scheduleValue\", \"setpointValue\")\r\n            else:\r\n                if isinstance(property_of, base.BuildingSpace):\r\n                    if isinstance(property_, base.Temperature):\r\n                        self.add_connection(measuring_device, controller, \"indoorTemperature\", \"actualValue\")\r\n                    elif isinstance(property_, base.Co2):\r\n                        self.add_connection(measuring_device, controller, \"indoorCo2Concentration\", \"actualValue\")\r\n                elif isinstance(property_of, components.CoilHeatingSystem):\r\n                    system = [v for v in property_of.subSystemOf if v in self.system_dict[\"heating\"].values()][0]\r\n                elif isinstance(property_of, components.CoilCoolingSystem):\r\n                    system = [v for v in property_of.subSystemOf if v in self.system_dict[\"cooling\"].values()][0]\r\n                else:\r\n                    logger.error(\"[Model Class] : \" f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n                    raise Exception(f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n                \r\n\r\n        for shading_device in shading_device_instances:\r\n            shade_setpoint_schedule = self.get_shade_setpoint_schedule(shading_device.id)\r\n            self.add_connection(shade_setpoint_schedule, shading_device, \"scheduleValue\", \"shadePosition\")\r\n\r\n        for sensor in sensor_instances:\r\n            property_ = sensor.observes\r\n            property_of = property_.isPropertyOf\r\n            if property_of is None:\r\n                instance_of_type_before = self._get_instance_of_type_before(flow_temperature_change_types, sensor)\r\n                if len(instance_of_type_before)==0:\r\n                    self.add_connection(outdoor_environment, sensor, \"outdoorTemperature\", \"inletAirTemperature\")\r\n                elif len(instance_of_type_before)==1:\r\n                    instance_of_type_before = instance_of_type_before[0]\r\n                    if isinstance(instance_of_type_before, base.Coil):\r\n                        if isinstance(property_, base.Temperature):\r\n                            self.add_connection(instance_of_type_before, sensor, \"outletAirTemperature\", \"flowAirTemperature\")\r\n                        else:\r\n                            logger.error(\"[Model Class] :\" f\"Unknown property {str(type(property_))} of {str(type(instance_of_type_before))}\")\r\n                            raise Exception(f\"Unknown property {str(type(property_))} of {str(type(instance_of_type_before))}\")\r\n\r\n                    elif isinstance(instance_of_type_before, base.AirToAirHeatRecovery):\r\n                        side = self._get_flow_placement(sensor)\r\n                        if isinstance(property_, base.Temperature):\r\n                            if side==\"supply\":\r\n                                self.add_connection(instance_of_type_before, sensor, \"primaryTemperatureOut\", \"primaryTemperatureOut\")\r\n                            else:\r\n                                self.add_connection(instance_of_type_before, sensor, \"secondaryTemperatureOut\", \"secondaryTemperatureOut\")\r\n                        else:\r\n                            logger.error(\"[Model Class] :\" f\"Unknown property {str(type(property_))} of {str(type(instance_of_type_before))}\")\r\n                            raise Exception(f\"Unknown property {str(type(property_))} of {str(type(instance_of_type_before))}\")\r\n                        \r\n                    # elif isinstance(instance_of_type_before, Fan):\r\n                    #     if isinstance(property_, Temperature):\r\n                    #         self.add_connection(instance_of_type_before, sensor, \"outletAirTemperature\", \"flowAirTemperature\")\r\n                    #     else:\r\n                    #         logger.error(\"[Model Class] :\" f\"Unknown property {str(type(property_))} of {str(type(instance_of_type_before))}\")\r\n                    #         raise Exception(f\"Unknown property {str(type(property_))} of {str(type(instance_of_type_before))}\")\r\n            else:\r\n                if isinstance(property_of, base.BuildingSpace):\r\n                    if isinstance(property_, base.Temperature):\r\n                        self.add_connection(property_of, sensor, \"indoorTemperature\", \"indoorTemperature\")\r\n                    elif isinstance(property_, base.Co2): \r\n                        self.add_connection(property_of, sensor, \"indoorCo2Concentration\", \"indoorCo2Concentration\")\r\n                    else:\r\n                        logger.error(\"[Model Class] :\" f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n                        raise Exception(f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n\r\n                if isinstance(property_of, base.Damper):\r\n                    if isinstance(property_, base.OpeningPosition):\r\n                        self.add_connection(property_of, sensor, \"damperPosition\", \"damperPosition\")\r\n                    else:\r\n                        logger.error(\"[Model Class] :\" f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n                        raise Exception(f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n\r\n                if isinstance(property_of, base.Valve):\r\n                    if isinstance(property_, base.OpeningPosition):\r\n                        self.add_connection(property_of, sensor, \"valvePosition\", \"valvePosition\")\r\n                    else:\r\n                        logger.error(\"[Model Class] :\" f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n                        raise Exception(f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n\r\n                if isinstance(property_of, base.ShadingDevice):\r\n                    if isinstance(property_, base.OpeningPosition):\r\n                        self.add_connection(property_of, sensor, \"shadePosition\", \"shadePosition\")\r\n                    else:\r\n                        logger.error(\"[Model Class] :\" f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n                        raise Exception(f\"Unknown property {str(type(property_))} of {str(type(property_of))}\")\r\n\r\n        for meter in meter_instances:\r\n            property_ = meter.observes\r\n            property_of = property_.isPropertyOf\r\n            if isinstance(property_of, base.SpaceHeater):\r\n                if isinstance(property_, base.Energy):\r\n                    self.add_connection(property_of, meter, \"Energy\", \"Energy\")\r\n                elif isinstance(property_, base.Power):\r\n                    self.add_connection(property_of, meter, \"Power\", \"Power\")\r\n\r\n            elif isinstance(property_of, base.Coil):\r\n                if isinstance(property_, base.Energy):\r\n                    self.add_connection(property_of, meter, \"Energy\", \"Energy\")\r\n                elif isinstance(property_, base.Power):\r\n                    self.add_connection(property_of, meter, \"Power\", \"Power\")\r\n\r\n            elif isinstance(property_of, base.Fan):\r\n                if isinstance(property_, base.Energy):\r\n                    self.add_connection(property_of, meter, \"Energy\", \"Energy\")\r\n                elif isinstance(property_, base.Power):\r\n                    self.add_connection(property_of, meter, \"Power\", \"Power\")\r\n\r\n\r\n        for node in node_instances:\r\n            ventilation_system = node.subSystemOf[0]\r\n            supply_dampers = [v for v in ventilation_system.hasSubSystem if isinstance(v, base.Damper) and len(v.connectedAfter)>0 and isinstance(v.connectedAfter[0], components.BuildingSpaceSystem)]\r\n            exhaust_dampers = [v for v in ventilation_system.hasSubSystem if isinstance(v, base.Damper) and len(v.connectedBefore)>0 and isinstance(v.connectedBefore[0], components.BuildingSpaceSystem)]\r\n            if node.operationMode==\"return\":\r\n                for damper in exhaust_dampers:\r\n                    space = damper.isContainedIn\r\n                    self.add_connection(damper, node, \"airFlowRate\", \"flowRate_\" + space.id)\r\n                    self.add_connection(space, node, \"indoorTemperature\", \"flowTemperatureIn_\" + space.id)\r\n            else:\r\n                for damper in supply_dampers:\r\n                    self.add_connection(damper, node, \"airFlowRate\", \"flowRate_\" + space.id)\r\n                # self.add_connection(supply_air_temperature_setpoint_schedule, node, \"supplyAirTemperature\", \"flowTemperatureIn\")\r\n        logger.info(\"[Model Class] : Exited from Connect Function\")\r\n\r\n\r\n    def init_building_space_systems(self):\r\n        for space in self.get_component_by_class(self.component_dict, components.BuildingSpaceSystem):\r\n            space.get_model()\r\n\r\n    def init_building_space_systems(self):\r\n        for space in self.get_component_by_class(self.component_dict, components.BuildingSpaceSystem):\r\n            space.get_model()\r\n\r\n\r\n    def set_custom_initial_dict(self, custom_initial_dict):\r\n        #validate input\r\n        np_custom_initial_dict_ids = np.array(list(custom_initial_dict.keys()))\r\n        legal_ids = np.array([dict_id in self.component_dict for dict_id in custom_initial_dict])\r\n        assert np.all(legal_ids), f\"Unknown component id(s) provided in \\\"custom_initial_dict\\\": {np_custom_initial_dict_ids[legal_ids==False]}\"\r\n        self.custom_initial_dict = custom_initial_dict\r\n\r\n    def set_initial_values(self):\r\n        \"\"\"\r\n        Arguments\r\n        use_default: If True, set default initial values, e.g. damper position=0. If False, use initial_dict.\r\n        initial_dict: Dictionary with component id as key and dictionary as values containing output property\r\n        \"\"\"\r\n        default_initial_dict = {\r\n            components.OutdoorEnvironmentSystem.__name__: {},\r\n            components.ScheduleSystem.__name__: {},\r\n            components.BuildingSpaceSystem.__name__: {\"indoorTemperature\": 21,\r\n                                                      \"indoorCo2Concentration\": 500},\r\n            components.BuildingSpaceCo2System.__name__: {\"indoorCo2Concentration\": 500},\r\n            components.BuildingSpaceOccSystem.__name__: {\"numberOfPeople\": 0},\r\n            components.BuildingSpaceFMUSystem.__name__: {\"indoorTemperature\": 21,\r\n                                                        \"indoorCo2Concentration\": 500},\r\n            components.ControllerSystem.__name__: {\"inputSignal\": 0},\r\n            components.RulebasedControllerSystem.__name__: {\"inputSignal\": 0},\r\n            components.ClassificationAnnControllerSystem.__name__: {\"inputSignal\": 0},\r\n            components.PIControllerFMUSystem.__name__: {\"inputSignal\": 0},\r\n            components.AirToAirHeatRecoverySystem.__name__: {},\r\n            components.CoilPumpValveFMUSystem.__name__: {},\r\n            components.CoilFMUSystem.__name__: {},\r\n            components.CoilHeatingSystem.__name__: {\"outletAirTemperature\": 21},\r\n            components.CoilCoolingSystem.__name__: {},\r\n            components.DamperSystem.__name__: {\"airFlowRate\": 0,\r\n                            \"damperPosition\": 0},\r\n            components.ValveSystem.__name__: {\"waterFlowRate\": 0,\r\n                                                \"valvePosition\": 0},\r\n            components.ValveFMUSystem.__name__: {\"waterFlowRate\": 0,\r\n                                                \"valvePosition\": 0},\r\n            components.ValvePumpFMUSystem.__name__: {\"waterFlowRate\": 0,\r\n                                                \"valvePosition\": 0},\r\n            components.FanSystem.__name__: {}, #Energy\r\n            components.FanFMUSystem.__name__: {}, #Energy\r\n            components.SpaceHeaterSystem.__name__: {\"outletWaterTemperature\": 21,\r\n                                        \"Energy\": 0},\r\n            components.FlowJunctionSystem.__name__: {},\r\n            components.ShadingDeviceSystem.__name__: {},\r\n            components.SensorSystem.__name__: {},\r\n            components.MeterSystem.__name__: {},\r\n            components.PiecewiseLinearSystem.__name__: {},\r\n            components.PiecewiseLinearSupplyWaterTemperatureSystem.__name__: {},\r\n            components.PiecewiseLinearScheduleSystem.__name__: {},\r\n            components.TimeSeriesInputSystem.__name__: {},\r\n            components.OnOffSystem.__name__: {},\r\n        }\r\n        initial_dict = {}\r\n        for component in self.component_dict.values():\r\n            initial_dict[component.id] = default_initial_dict[type(component).__name__]\r\n        if self.custom_initial_dict is not None:\r\n            for key, value in self.custom_initial_dict.items():\r\n                initial_dict[key].update(value)\r\n\r\n        for component in self.component_dict.values():\r\n            component.output.update(initial_dict[component.id])\r\n\r\n    def set_parameters_from_array(self, parameters, component_list, attr_list):\r\n        for i, (obj, attr) in enumerate(zip(component_list, attr_list)):\r\n            rsetattr(obj, attr, parameters[i])\r\n\r\n    def set_parameters_from_dict(self, parameters, component_list, attr_list):\r\n        for (obj, attr) in zip(component_list, attr_list):\r\n            rsetattr(obj, attr, parameters[attr])\r\n\r\n    def cache(self,\r\n                startTime=None,\r\n                endTime=None,\r\n                stepSize=None):\r\n        \"\"\"\r\n        This method is called once before using multiprocessing on the Simulator.\r\n        It calls the customizable \"initialize\" method for specific components to cache and create the folder structure for time series data.\r\n        \"\"\"\r\n        c = self.get_component_by_class(self.component_dict, (components.SensorSystem, components.MeterSystem, components.OutdoorEnvironmentSystem, components.TimeSeriesInputSystem))\r\n        for component in c:\r\n            component.initialize(startTime=startTime,\r\n                                endTime=endTime,\r\n                                stepSize=stepSize)\r\n\r\n    def initialize(self,\r\n                    startTime=None,\r\n                    endTime=None,\r\n                    stepSize=None):\r\n        \"\"\"\r\n        This method is always called before simulation. \r\n        It sets initial values for the different components and further calls the customizable \"initialize\" method for each component. \r\n        \"\"\"\r\n        logger.info(\"Initializing model for simulation...\")\r\n        self.set_initial_values()\r\n        self.check_for_for_missing_initial_values()\r\n        for component in self.flat_execution_order:\r\n        # for component in self.component_dict.values():\r\n            component.clear_results()\r\n            component.initialize(startTime=startTime,\r\n                                endTime=endTime,\r\n                                stepSize=stepSize)\r\n            \r\n    def validate_model(self):\r\n        self.validate_ids()\r\n        self.validate_connections()\r\n                \r\n    def validate_ids(self):\r\n        components = list(self.component_dict.values())\r\n        for component in components:\r\n            # Validate ids\r\n            isvalid = np.array([x.isalnum() or x in self.valid_chars for x in component.id])\r\n            np_id = np.array(list(component.id))\r\n            violated_characters = list(np_id[isvalid==False])\r\n            assert all(isvalid), f\"The component with class \\\"{component.__class__.__name__}\\\" and id \\\"{component.id}\\\" has an invalid id. The characters \\\"{', '.join(violated_characters)}\\\" are not allowed.\"\r\n\r\n    def validate_connections(self):\r\n        components = list(self.component_dict.values())\r\n        for component in components:\r\n            if len(component.connectedThrough)==0 and len(component.connectsAt)==0:\r\n                warnings.warn(f\"The component with class \\\"{component.__class__.__name__}\\\" and id \\\"{component.id}\\\" has no connections. It has been removed from the model.\")\r\n                self.remove_component(component)\r\n\r\n            input_labels = [cp.receiverPropertyName for cp in component.connectsAt]\r\n            for req_input_label in component.input.keys():\r\n                assert req_input_label in input_labels, f\"The component with class \\\"{component.__class__.__name__}\\\" and id \\\"{component.id}\\\" is missing the input: \\\"{req_input_label}\\\"\"\r\n\r\n        \r\n\r\n    \r\n    def load_model(self, semantic_model_filename=None, input_config=None, infer_connections=True, fcn=None, do_load_parameters=True):\r\n        \"\"\"\r\n        This method loads component models and creates connections between the models. \r\n        In addition, it creates and draws graphs of the simulation model and the semantic model. \r\n        \"\"\"\r\n        print(\"Loading model...\")\r\n        # if infer_connections:\r\n        # self.add_outdoor_environment_system()\r\n        if semantic_model_filename is not None:\r\n            self.read_datamodel_config(semantic_model_filename)\r\n            self._create_object_graph(self.component_base_dict)\r\n            self.draw_object_graph(filename=\"object_graph_input\")\r\n            self.apply_model_extensions()\r\n\r\n        if fcn is not None:\r\n            # Model.fcn = fcn # Causes fcn to be shared between instances, which is not the desired behavior\r\n            self.fcn = fcn.__get__(self, Model)\r\n\r\n\r\n        self.fcn()\r\n        if input_config is not None:\r\n            self.read_input_config(input_config)\r\n        \r\n        # self._create_object_graph(self.component_dict)\r\n        # self.draw_object_graph(filename=\"object_graph_completed\")\r\n        if infer_connections:\r\n            self.connect()\r\n\r\n        self.validate_model()\r\n        self._create_system_graph()\r\n        self.draw_system_graph()\r\n        self._get_execution_order_old()\r\n        self._create_flat_execution_graph()\r\n        self.draw_system_graph_no_cycles()\r\n        self.draw_execution_graph()\r\n        if do_load_parameters:\r\n            self._load_parameters()\r\n\r\n\r\n\r\n    def _load_parameters(self):\r\n        for component in self.component_dict.values():\r\n            assert hasattr(component, \"config\"), f\"The class \\\"{component.__class__.__name__}\\\" has no \\\"config\\\" attribute.\"\r\n            config = component.config.copy()\r\n            assert \"parameters\" in config, f\"The \\\"config\\\" attribute of class \\\"{component.__class__.__name__}\\\" has no \\\"parameters\\\" key.\"\r\n            filename, isfile = self.get_dir(folder_list=[\"model_parameters\", component.__class__.__name__], filename=f\"{component.id}.json\")\r\n            config[\"parameters\"] = {attr: rgetattr(component, attr) for attr in config[\"parameters\"]}\r\n            if isfile==False:\r\n                with open(filename, 'w') as f:\r\n                    json.dump(config, f, indent=4)\r\n            else:\r\n                with open(filename) as f:\r\n                    config = json.load(f)\r\n                parameters = {k: float(v) if isnumeric(v) else v for k, v in config[\"parameters\"].items()}\r\n                for attr, value in parameters.items():\r\n                    rsetattr(component, attr, value)\r\n\r\n                if \"readings\" in config:\r\n                    filename_ = config[\"readings\"][\"filename\"]\r\n                    datecolumn = config[\"readings\"][\"datecolumn\"]\r\n                    valuecolumn = config[\"readings\"][\"valuecolumn\"]\r\n                    if filename_ is not None:\r\n                        component.filename = filename_\r\n\r\n                        if datecolumn is not None:\r\n                            component.datecolumn = datecolumn\r\n                        elif isinstance(component, components.OutdoorEnvironmentSystem)==False:\r\n                            raise(ValueError(f\"\\\"datecolumn\\\" is not defined in the \\\"readings\\\" key of the config file: {filename}\"))\r\n\r\n                        if valuecolumn is not None:\r\n                            component.valuecolumn = valuecolumn\r\n                        elif isinstance(component, components.OutdoorEnvironmentSystem)==False:\r\n                            raise(ValueError(f\"\\\"valuecolumn\\\" is not defined in the \\\"readings\\\" key of the config file: {filename}\"))\r\n                    \r\n\r\n\r\n    def load_model_new(self, semantic_model_filename=None, input_config=None, infer_connections=True, fcn=None, create_signature_graphs=False):\r\n        \"\"\"\r\n        This method loads component models and creates connections between the models. \r\n        In addition, it creates and draws graphs of the simulation model and the semantic model. \r\n        \"\"\"\r\n        print(\"Loading model...\")\r\n        # if infer_connections:\r\n        self.add_outdoor_environment()\r\n        if semantic_model_filename is not None:\r\n            self.read_datamodel_config(semantic_model_filename)\r\n            self._create_object_graph(self.component_base_dict)\r\n            self.draw_object_graph(filename=\"object_graph_input\")\r\n            self.parse_semantic_model()\r\n\r\n\r\n        if input_config is not None:\r\n            self.read_input_config(input_config)\r\n\r\n        self._create_object_graph(self.component_base_dict)\r\n        self.draw_object_graph(filename=\"object_graph_parsed\")\r\n        # self._create_object_graph(self.component_dict)\r\n        # self.draw_object_graph(filename=\"object_graph_completed\")\r\n        if infer_connections:\r\n            self.connect_new()\r\n\r\n        print(self)\r\n\r\n        \r\n        if fcn is not None:\r\n            # Model.fcn = fcn # Causes fcn to be shared between instances, which is not the desired behavior\r\n            self.fcn = fcn.__get__(self, Model) # This is a workaround to avoid the fcn to be shared between instances (https://stackoverflow.com/questions/28127874/monkey-patching-python-an-instance-method)\r\n        self.fcn()\r\n\r\n        if create_signature_graphs:\r\n            self._create_signature_graphs()\r\n        \r\n        self._create_system_graph()\r\n        self.draw_system_graph()\r\n        # self._get_execution_order()\r\n        # self._create_flat_execution_graph()\r\n        # self.draw_system_graph_no_cycles()\r\n        # self.draw_execution_graph()\r\n\r\n        self.validate_model()\r\n        self._get_execution_order()\r\n        self._create_flat_execution_graph()\r\n        self.draw_system_graph_no_cycles()\r\n        self.draw_execution_graph()\r\n        self._load_parameters()\r\n\r\n    def fcn(self):\r\n        pass\r\n\r\n    def split_name(self, name, linesep=\"\\n\"):\r\n\r\n        split_delimiters = [\" \", \")(\", \"_\", \"]\", \"|\"]\r\n        new_name = name\r\n        char_len = len(name)\r\n        char_limit = 20\r\n        if any([s in name for s in split_delimiters]):\r\n            if char_len>char_limit:\r\n                name_splits = [name]\r\n                for split_delimiter_ in split_delimiters:\r\n                    new_name_splits = []\r\n                    for name_split in name_splits:\r\n                        splitted = name_split.split(split_delimiter_)\r\n                        n = [e+split_delimiter_ if e and i<len(splitted)-1 else e for i,e in enumerate(splitted)]\r\n                        new_name_splits.extend(n)                    \r\n                    name_splits = new_name_splits\r\n\r\n                char_cumsum = np.cumsum(np.array([len(s) for s in name_splits]))\r\n                add_space_char = np.arange(char_cumsum.shape[0])\r\n                char_cumsum = char_cumsum + add_space_char\r\n                idx_arr = np.where(char_cumsum>char_limit)[0]\r\n                if idx_arr.size!=0 and (idx_arr[0]==0 and idx_arr.size==1)==False:\r\n                    if idx_arr[0]==0:\r\n                        idx = idx_arr[1]\r\n                    else:\r\n                        idx = idx_arr[0]\r\n                    name_before_line_break = \"\".join(name_splits[0:idx])\r\n                    name_after_line_break = \"\".join(name_splits[idx:])\r\n                    if len(name_after_line_break)>char_limit:\r\n                        name_after_line_break = self.split_name(name_after_line_break, linesep=linesep)\r\n                    \r\n                    if name_before_line_break!=\"\" and name_after_line_break!=\"\":\r\n                        new_name = name_before_line_break + linesep + name_after_line_break\r\n                    else:\r\n                        new_name = name\r\n        return new_name\r\n    \r\n    def _initialize_graph(self, graph_type):\r\n        if graph_type==\"system\":\r\n            self.system_graph = pydot.Dot()\r\n            self.system_subgraph_dict = {}\r\n            self.system_graph_node_attribute_dict = {}\r\n            self.system_graph_edge_label_dict = {}\r\n            self.system_graph_rank=None\r\n        elif graph_type==\"object\":\r\n            self.object_graph = pydot.Dot()\r\n            self.object_subgraph_dict = {}\r\n            self.object_graph_node_attribute_dict = {}\r\n            self.object_graph_edge_label_dict = {}\r\n            self.object_graph_rank=None\r\n        else:\r\n            raise(ValueError(f\"Unknown graph type: \\\"{graph_type}\\\"\"))\r\n\r\n    def _create_signature_graphs(self):\r\n        classes = [cls[1] for cls in inspect.getmembers(components, inspect.isclass) if (issubclass(cls[1], (System, )) and hasattr(cls[1], \"sp\"))]\r\n        for component_cls in classes:\r\n            sps = component_cls.sp\r\n            for sp in sps:\r\n                d = {s.id: s for s in sp.nodes}\r\n                filename = self.get_dir(folder_list=[\"graphs\", \"signatures\"], filename=f\"signature_{component_cls.__name__}_{sp.id}\")[0]\r\n                self._create_object_graph(d, sp.ruleset, add_brackets=False)\r\n                self.draw_graph(filename, self.object_graph)\r\n\r\n    def _create_object_graph(self, object_dict, ruleset=None, add_brackets=True):\r\n        logger.info(\"[Model Class] : Entered in Create Object Graph Function\")\r\n        self._initialize_graph(\"object\")\r\n        # self._reset_object_dict()\r\n        # exception_classes = (dict, float, str, int, Connection, ConnectionPoint, np.ndarray, torch.device, pd.DataFrame, property_.Property, Measurement) # These classes are excluded from the graph \r\n        exceptions = []\r\n        builtin_types = [getattr(builtins, d) for d in dir(builtins) if isinstance(getattr(builtins, d), type)]\r\n        for exception in exceptions: builtin_types.remove(exception)\r\n        exception_classes = (Connection, ConnectionPoint, np.ndarray, torch.device, pd.DataFrame) # These classes are excluded from the graph \r\n        exception_classes_exact = (base.DistributionDevice, *builtin_types, count)\r\n        # required_attributes = {base.PropertyValue: \"hasValue\",\r\n        #                        }\r\n        visited = []\r\n\r\n\r\n        ruleset_applies = True if ruleset is not None else False\r\n        shape_dict = {signature_pattern.IgnoreIntermediateNodes: \"circle\",\r\n                      signature_pattern.Optional: \"diamond\",}\r\n        dummy_dim = 0.3\r\n        \r\n        for component in object_dict.values():\r\n            if component not in visited:\r\n                visited = self._depth_first_search_recursive(component, visited, exception_classes, exception_classes_exact)\r\n        \r\n        ignore_nodes = [v.isValueOfProperty for v in visited if isinstance(v, base.PropertyValue) and v.hasValue is None]\r\n        ignore_nodes.extend([v for v in visited if isinstance(v, base.PropertyValue) and v.hasValue is None])\r\n        include_nodes = [v.hasValue for v in visited if isinstance(v, base.PropertyValue) and v.hasValue is not None]\r\n        end_space = \"  \"\r\n        for component in visited:\r\n            attributes = get_object_attributes(component)\r\n                \r\n            for attr in attributes:\r\n                edge_label = attr+end_space\r\n                obj = rgetattr(component, attr)\r\n\r\n                if hasattr(component.__class__, attr) and isinstance(rgetattr(component.__class__, attr), property):\r\n                    class_property = True\r\n                else:\r\n                    class_property = False\r\n                # print(type())\r\n                \r\n                # cond1 = isinstance(component, tuple(required_attributes.keys()))\r\n                # cond2 = rgetattr(component, required_attributes[component.__class__]) is not None if cond1 else True\r\n\r\n                if obj is not None and inspect.ismethod(obj)==False and component not in ignore_nodes and class_property==False:\r\n                    if isinstance(obj, list):\r\n                        for receiver_component in obj:\r\n                            # cond1 = isinstance(receiver_component, tuple(required_attributes.keys()))\r\n                            # cond2 = rgetattr(receiver_component, required_attributes[receiver_component.__class__]) is not None if cond1 else True\r\n                            cond1 = receiver_component in include_nodes\r\n                            cond2 = isinstance(receiver_component, exception_classes)==False and istype(receiver_component, exception_classes_exact)==False and receiver_component not in ignore_nodes\r\n                            if cond1 or cond2:\r\n                                if ruleset_applies and attr in component.attributes and receiver_component in component.attributes[attr] and type(ruleset[(component, receiver_component, attr)]) in shape_dict:\r\n                                    dummy = signature_pattern.Node(tuple())\r\n                                    shape = shape_dict[type(ruleset[(component, receiver_component, attr)])]\r\n                                    self._add_graph_relation(self.object_graph, component, dummy, edge_kwargs={\"label\": edge_label, \"arrowhead\":\"none\", \"fontname\":\"CMU Typewriter Text\"}, receiver_node_kwargs={\"label\": \"\", \"shape\":shape, \"width\":dummy_dim, \"height\":dummy_dim})#, \"fontname\":\"Helvetica\", \"fontsize\":\"21\", \"fontcolor\":\"black\"})\r\n                                    self._add_graph_relation(self.object_graph, dummy, receiver_component, edge_kwargs={\"label\": \"\"}, sender_node_kwargs={\"label\": \"\", \"shape\":shape, \"width\":dummy_dim, \"height\":dummy_dim})#, \"fontname\":\"Helvetica\", \"fontsize\":\"21\", \"fontcolor\":\"black\"})\r\n                                else:\r\n                                    self._add_graph_relation(self.object_graph, component, receiver_component, edge_kwargs={\"label\": edge_label, \"fontname\":\"CMU Typewriter Text\"})\r\n                    else:\r\n                        receiver_component = obj\r\n                        # cond1 = isinstance(receiver_component, tuple(required_attributes.keys()))\r\n                        # cond2 = rgetattr(receiver_component, required_attributes[receiver_component.__class__]) is not None if cond1 else True\r\n                        cond1 = receiver_component in include_nodes\r\n                        cond2 = isinstance(receiver_component, exception_classes)==False and istype(receiver_component, exception_classes_exact)==False and receiver_component not in ignore_nodes\r\n\r\n                        if cond1 or cond2:\r\n                            if ruleset_applies and attr in component.attributes and receiver_component == component.attributes[attr] and type(ruleset[(component, receiver_component, attr)]) in shape_dict:\r\n                                dummy = signature_pattern.Node(tuple())\r\n                                shape = shape_dict[type(ruleset[(component, receiver_component, attr)])]\r\n                                self._add_graph_relation(self.object_graph, component, dummy, edge_kwargs={\"label\": edge_label, \"arrowhead\":\"none\", \"fontname\":\"CMU Typewriter Text\"}, receiver_node_kwargs={\"label\": \"\", \"shape\":shape, \"width\":dummy_dim, \"height\":dummy_dim})#, \"fontname\":\"Helvetica\", \"fontsize\":\"21\", \"fontcolor\":\"black\"})\r\n                                self._add_graph_relation(self.object_graph, dummy, receiver_component, edge_kwargs={\"label\": \"\"}, sender_node_kwargs={\"label\": \"\", \"shape\":shape, \"width\":dummy_dim, \"height\":dummy_dim})#, \"fontname\":\"Helvetica\", \"fontsize\":\"21\", \"fontcolor\":\"black\"})\r\n                            else:\r\n                                self._add_graph_relation(self.object_graph, component, receiver_component, edge_kwargs={\"label\": edge_label, \"fontname\":\"CMU Typewriter Text\"})\r\n        graph = self.object_graph\r\n        attributes = self.object_graph_node_attribute_dict\r\n        subgraphs = self.object_subgraph_dict\r\n        self._create_graph(graph, attributes, subgraphs, add_brackets=add_brackets)\r\n\r\n    def _create_flat_execution_graph(self):\r\n        self.execution_graph = pydot.Dot()\r\n        prev_node=None\r\n        for i,component_group in enumerate(self.execution_order):\r\n            subgraph = pydot.Subgraph()#graph_name=f\"cluster_{i}\", style=\"dotted\", penwidth=8)\r\n            for component in component_group:\r\n                node = pydot.Node('\"' + component.id + '\"')\r\n                if component.id in self.system_graph_node_attribute_dict:\r\n                    node.obj_dict[\"attributes\"].update(self.system_graph_node_attribute_dict[component.id])\r\n                subgraph.add_node(node)\r\n                if prev_node:\r\n                    self._add_edge(self.execution_graph, prev_node.obj_dict[\"name\"], node.obj_dict[\"name\"], edge_kwargs={\"label\": \"\"})\r\n                prev_node = node\r\n            self.execution_graph.add_subgraph(subgraph)\r\n\r\n    def _create_system_graph(self):\r\n        graph = self.system_graph\r\n        attributes = self.system_graph_node_attribute_dict\r\n        subgraphs = self.system_subgraph_dict\r\n        self._create_graph(graph, attributes, subgraphs)\r\n\r\n    def is_html(self, name):\r\n        if len(name)>=2 and name[0]==\"<\" and name[-1]==\">\":\r\n            return True\r\n        else:\r\n            return False\r\n\r\n    def _create_graph(self, graph, attributes, subgraphs, add_brackets=False):\r\n        logger.info(\"[Model Class] : Entered in Create System Graph Function\")\r\n        light_black = \"#3B3838\"\r\n        dark_blue = \"#44546A\"\r\n        orange = \"#DC8665\"#\"#C55A11\"\r\n        red = \"#873939\"\r\n        grey = \"#666666\"\r\n        light_grey = \"#71797E\"\r\n        light_blue = \"#8497B0\"\r\n        green = \"#83AF9B\"#\"#BF9000\"\r\n        buttercream = \"#B89B72\"\r\n        green = \"#83AF9B\"        \r\n\r\n        fill_colors = {base.BuildingSpace: light_black,\r\n                            base.Controller: orange,\r\n                            base.AirToAirHeatRecovery: dark_blue,\r\n                            base.Coil: red,\r\n                            base.Damper: dark_blue,\r\n                            base.Valve: red,\r\n                            base.Fan: dark_blue,\r\n                            base.SpaceHeater: red,\r\n                            base.Sensor: green,\r\n                            base.Meter: green,\r\n                            base.Schedule: grey,\r\n                            base.Pump: red}\r\n        fill_default = light_grey\r\n        border_colors = {base.BuildingSpace: \"black\",\r\n                            base.Controller: \"black\",\r\n                            base.AirToAirHeatRecovery: \"black\",\r\n                            base.Coil: \"black\",\r\n                            base.Damper: \"black\",\r\n                            base.Valve: \"black\",\r\n                            base.Fan: \"black\",\r\n                            base.SpaceHeater: \"black\",\r\n                            base.Sensor: \"black\",\r\n                            base.Meter: \"black\"}\r\n        border_default = \"black\"\r\n        K = 1\r\n        min_fontsize = 22*K\r\n        max_fontsize = 28*K\r\n\r\n        # min_box_width = 1*K\r\n        # max_box_width = 3.7*K\r\n\r\n        # min_box_height = 0.4*K\r\n        # max_box_height = 1*K\r\n\r\n        fontpath, fontname = self.get_font()\r\n        # font_ = ImageFont.truetype(font, max_fontsize)\r\n        # ascent, descent = font.getmetrics()\r\n        # print(ascent, descent)\r\n        # aa\r\n\r\n\r\n        delta_box_width = 0.2\r\n        delta_box_height = 0.5\r\n        width_pad = 2*delta_box_width\r\n        height_pad = 0.1\r\n        nx_graph = nx.drawing.nx_pydot.from_pydot(graph)\r\n        labelwidths = []\r\n        labelheights = []\r\n        for node in nx_graph.nodes():\r\n            name = attributes[node][\"label\"]\r\n            linesep = \"\\n\"\r\n            is_html = self.is_html(name)\r\n            name = self.split_name(name, linesep=linesep)\r\n\r\n            #Dont count HTML tags\r\n            html_chars = [\"<\", \">\", \"SUB,\" ,\"/SUB\"]\r\n            no_html_name = name\r\n            for s in html_chars:\r\n                no_html_name = no_html_name.replace(s, \"\")\r\n            names = no_html_name.split(linesep)\r\n\r\n            if is_html==False: #Convert to html \r\n                name =\"<\"+name+\">\"\r\n            name = name.replace(linesep, \"<br />\")\r\n            if add_brackets:\r\n                name =\"<&#60;\" + name[1:]\r\n                name = name[:-1] + \"&#62;>\"\r\n            char_count_list = [len(s) for s in names if s]\r\n            if len(char_count_list)>0:\r\n                char_count = max(char_count_list)\r\n                linecount = len(names)\r\n            else:\r\n                char_count = 0\r\n                linecount = 0\r\n            attributes[node][\"label\"] = name\r\n            attributes[node][\"labelcharcount\"] = char_count\r\n            attributes[node][\"labellinecount\"] = linecount\r\n            attributes[node][\"fontname\"] = fontname\r\n\r\n\r\n        a_fontsize = 0\r\n        b_fontsize = max_fontsize\r\n\r\n        a_char_width = delta_box_width\r\n        b_char_width = width_pad\r\n\r\n        a_line_height = delta_box_height\r\n        b_line_height = height_pad\r\n\r\n        for node in nx_graph.nodes():\r\n            deg = nx_graph.degree(node)\r\n            fontsize = a_fontsize*deg + b_fontsize\r\n            name = attributes[node][\"label\"]\r\n            # if \"\\n\" in name:\r\n            labelwidth = attributes[node][\"labelcharcount\"]\r\n            labelheight = attributes[node][\"labellinecount\"]\r\n            # labelwidth = attributes[node][\"labelwidth\"]\r\n            # labelheight = attributes[node][\"labelheight\"]\r\n            \r\n            width = a_char_width*labelwidth + b_char_width\r\n            # height = (a_line_height*deg + b_height)*2\r\n            height = a_line_height*labelheight + b_line_height\r\n\r\n            # else:\r\n            #     width = a_char_width*len(attributes[node][\"label\"]) + b_char_width\r\n            #     height = a_line_height*deg + b_line_height\r\n\r\n\r\n            if node not in attributes:\r\n                attributes[node] = {}\r\n\r\n            attributes[node][\"fontsize\"] = fontsize\r\n\r\n            if \"width\" not in attributes[node]:\r\n                attributes[node][\"width\"] = width\r\n            if \"height\" not in attributes[node]:\r\n                attributes[node][\"height\"] = height\r\n            cls = self.object_dict[node].__class__\r\n            if cls in fill_colors:\r\n                attributes[node][\"fillcolor\"] = fill_colors[cls] \r\n            elif issubclass(cls, tuple(fill_colors.keys())):\r\n                c = [color for c, color in fill_colors.items() if issubclass(cls, c)]\r\n                if len(c)>1:\r\n                    colors = c[0]\r\n                    for color in c[1:]:\r\n                        colors += \":\" + color #Currently, the gradient colors are limited to 2\r\n                    c = f\"\\\"{colors}\\\"\"\r\n                else:\r\n                    c = c[0]\r\n                attributes[node][\"fillcolor\"] = c\r\n                \r\n            else:\r\n                attributes[node][\"fillcolor\"] = fill_default\r\n            \r\n            if cls in border_colors:\r\n                attributes[node][\"color\"] = border_colors[cls] \r\n            elif issubclass(cls, tuple(border_colors.keys())):\r\n                c = [c for c in border_colors.keys() if issubclass(cls, c)][0]\r\n                attributes[node][\"color\"] = border_colors[c]\r\n            else:\r\n                attributes[node][\"color\"] = border_default\r\n\r\n            c = [c for c in subgraphs.keys() if issubclass(cls, c)][0]\r\n            subgraph = subgraphs[c]\r\n            name = node\r\n            if len(subgraph.get_node(name))==1:\r\n                subgraph.get_node(name)[0].obj_dict[\"attributes\"].update(attributes[node])\r\n            elif len(subgraph.get_node(name))==0: #If the name is not present, try with quotes\r\n                 name = \"\\\"\" + node + \"\\\"\"\r\n                 subgraph.get_node(name)[0].obj_dict[\"attributes\"].update(attributes[node])\r\n            else:\r\n                print([el.id for el in self.object_dict.values()])\r\n                raise Exception(f\"Multiple identical node names found in subgraph\")\r\n        logger.info(\"[Model Class] : Exited from Create System Graph Function\")\r\n\r\n    def draw_object_graph(self, filename=\"object_graph\"):\r\n        graph = self.object_graph\r\n        self.draw_graph(filename, graph)\r\n\r\n    def draw_system_graph_no_cycles(self):\r\n        filename = \"system_graph_no_cycles\"\r\n        graph = self.system_graph_no_cycles\r\n        self.draw_graph(filename, graph)\r\n\r\n    def draw_system_graph(self):\r\n        filename = \"system_graph\"\r\n        graph = self.system_graph\r\n        self.draw_graph(filename, graph)\r\n\r\n    def draw_execution_graph(self):\r\n        filename = \"execution_graph\"\r\n        graph = self.execution_graph\r\n        self.draw_graph(filename, graph)\r\n\r\n    def get_font(self):\r\n        font_files = matplotlib.font_manager.findSystemFonts(fontpaths=None)\r\n        preferred_font = \"Helvetica-Bold\".lower()\r\n        preferred_font = \"CMUNBTL\".lower()\r\n        found_preferred_font = False\r\n        for font in font_files:\r\n            s = os.path.split(font)\r\n            if preferred_font in s[1].lower():\r\n                found_preferred_font = True\r\n                break\r\n\r\n        if found_preferred_font==False:\r\n            font = matplotlib.font_manager.findfont(matplotlib.font_manager.FontProperties(family=['sans-serif']))\r\n\r\n        fontpath = os.path.split(font)[0]\r\n        fontname = os.path.split(font)[1]\r\n\r\n        fontname = \"CMU Typewriter Text\"\r\n        # \"CMU Typewriter Text:style=Bold\"\r\n        # fontname = \"CMU Typewriter Text Variable Width:style=Medium\"\r\n\r\n        return fontpath, fontname\r\n\r\n    def unflatten(self, filename):\r\n        app_path = shutil.which(\"unflatten\")\r\n        args = [app_path, \"-f\", f\"-l 3\", f\"-o{filename}_unflatten.dot\", f\"{filename}.dot\"]\r\n        subprocess.run(args=args)\r\n\r\n    def draw_graph(self, filename, graph, args=None):\r\n        fontpath, fontname = self.get_font()\r\n        \r\n        light_grey = \"#71797E\"\r\n        graph_filename = os.path.join(self.graph_path, f\"{filename}.png\")\r\n        graph.write(f'{filename}.dot', prog=\"dot\")\r\n        # self.unflatten(filename)\r\n        # If Python can't find the dot executeable, change \"app_path\" variable to the full path\r\n        app_path = shutil.which(\"dot\")\r\n        if args is None:\r\n            args = [app_path,\r\n                    \"-q\",\r\n                    \"-Tpng\",\r\n                    \"-Kdot\",\r\n                    # \"-Gfontpath=C:/Windows/Fonts/\"\r\n                    f\"-Gfontpath={fontpath}\",\r\n                    # f\"-Gfontpath=\\\"C:/Users/jabj/AppData/Local/Microsoft/Windows/Fonts/\\\"\",\r\n                    # \"-Gfontname=lmroman12-bold.otf\",\r\n                    # f\"-Gfontname=\\\"{fontname}\\\"\",\r\n                    \"-Nstyle=filled\",\r\n                    \"-Nshape=box\",\r\n                    \"-Nfontcolor=white\",\r\n                    f\"-Nfontname=Helvetica bold\",\r\n                    \"-Nfixedsize=true\",\r\n                    # \"-Gnodesep=3\",\r\n                    \"-Gnodesep=0.1\",\r\n                    \"-Efontname=Helvetica\",\r\n                    \"-Efontsize=21\",\r\n                    \"-Epenwidth=2\",\r\n                    \"-Eminlen=1\",\r\n                    f\"-Ecolor={light_grey}\",\r\n                    \"-Gcompound=true\",\r\n                    \"-Grankdir=TB\",\r\n                    \"-Gsplines=true\", #true\r\n                    \"-Gmargin=0\",\r\n                    # \"-Gratio=compress\", #####################################################\r\n                    \"-Gsize=10!\",\r\n                    \"-Gratio=auto\", #0.5 #auto\r\n                    \"-Gpack=true\",\r\n                    \"-Gdpi=1000\",\r\n                    \"-Grepulsiveforce=0.5\",\r\n                    \"-Gremincross=true\",\r\n                    \"-Gstart=1\",\r\n                    \"-q\",\r\n                    # \"-Gbgcolor=#EDEDED\",\r\n                    f\"-o{graph_filename}\",\r\n                    f\"{filename}.dot\"] #_unflatten\r\n        else:\r\n            args_ = [app_path]\r\n            args_.extend(args)\r\n            args_.extend([f\"-o{graph_filename}\", f\"{filename}.dot\"])\r\n            args = args_\r\n        subprocess.run(args=args)\r\n        os.remove(f\"{filename}.dot\")\r\n\r\n    def _depth_first_search_recursive(self, component, visited, exception_classes, exception_classes_exact):\r\n        visited.append(component)\r\n        attributes = dir(component)\r\n        attributes = [attr for attr in attributes if attr[:2]!=\"__\"]#Remove callables\r\n        for attr in attributes:\r\n            obj = rgetattr(component, attr)\r\n            if obj is not None and inspect.ismethod(obj)==False:\r\n                if isinstance(obj, list):\r\n                    for receiver_component in obj:\r\n                        if isinstance(receiver_component, exception_classes)==False and receiver_component not in visited and istype(receiver_component, exception_classes_exact)==False:\r\n                            visited = self._depth_first_search_recursive(receiver_component, visited, exception_classes, exception_classes_exact)\r\n                else:\r\n                    receiver_component = obj\r\n                    if isinstance(receiver_component, exception_classes)==False and receiver_component not in visited and istype(receiver_component, exception_classes_exact)==False:\r\n                        visited = self._depth_first_search_recursive(receiver_component, visited, exception_classes, exception_classes_exact)\r\n        return visited\r\n\r\n    def _depth_first_search(self, obj):\r\n        visited = []\r\n        visited = self._depth_first_search_recursive(obj, visited)\r\n        return visited\r\n\r\n    def _flatten(self, _list):\r\n        return [item for sublist in _list for item in sublist]\r\n\r\n    def _depth_first_search_recursive_system(self, component, visited):\r\n        visited.append(component)\r\n        # Recur for all the vertices adjacent to this vertex\r\n        for connection in component.connectedThrough:\r\n            connection_point = connection.connectsSystemAt\r\n            receiver_component = connection_point.connectionPointOf\r\n            if receiver_component not in visited:\r\n                visited = self._depth_first_search_recursive_system(receiver_component, visited)\r\n        return visited\r\n \r\n    def _depth_first_search_system(self, component):\r\n        visited = []\r\n        visited = self._depth_first_search_recursive_system(component, visited)\r\n        return visited\r\n\r\n    def get_subgraph_dict_no_cycles(self):\r\n        self.system_subgraph_dict_no_cycles = copy.deepcopy(self.system_subgraph_dict)\r\n        subgraphs = self.system_graph_no_cycles.get_subgraphs()\r\n        for subgraph in subgraphs:\r\n            subgraph.get_nodes()\r\n            if len(subgraph.get_nodes())>0:\r\n                node = subgraph.get_nodes()[0].obj_dict[\"name\"].replace('\"',\"\")\r\n                self.system_subgraph_dict_no_cycles[self._component_dict_no_cycles[node].__class__] = subgraph\r\n\r\n\r\n    def get_component_dict_no_cycles_old(self):\r\n        self._component_dict_no_cycles = copy.deepcopy(self.component_dict)\r\n        self.system_graph_no_cycles = copy.deepcopy(self.system_graph)\r\n        self.get_subgraph_dict_no_cycles()\r\n        self.required_initialization_connections = []\r\n\r\n        controller_instances = [v for v in self._component_dict_no_cycles.values() if isinstance(v, base.Controller)]\r\n        for controller in controller_instances:\r\n            controlled_component = controller.observes.isPropertyOf\r\n            assert controlled_component is not None, f\"The attribute \\\"isPropertyOf\\\" is None for property \\\"{controller.observes}\\\" of component \\\"{controller.id}\\\"\"\r\n            visited = self._depth_first_search_system(controller)\r\n\r\n            for reachable_component in visited:\r\n                for connection in reachable_component.connectedThrough:\r\n                    connection_point = connection.connectsSystemAt\r\n                    receiver_component = connection_point.connectionPointOf\r\n                    if controlled_component==receiver_component:\r\n                        controlled_component.connectsAt.remove(connection_point)\r\n                        reachable_component.connectedThrough.remove(connection)\r\n                        edge_label = self.get_edge_label(connection.senderPropertyName, connection_point.receiverPropertyName)\r\n                        status = self._del_edge(self.system_graph_no_cycles, reachable_component.id, controlled_component.id, label=edge_label)\r\n                        assert status, \"del_edge returned False. Check if additional characters should be added to \\\"disallowed_characters\\\".\"\r\n\r\n                        self.required_initialization_connections.append(connection)\r\n\r\n    def get_base_component(self, key):\r\n        \"\"\"\r\n        Assumes that there is a 1-to-1 mapping\r\n        \"\"\"\r\n        assert len(self.instance_map[self.component_dict[key]])==1, f\"The mapping for component \\\"{key}\\\" is not 1-to-1\"\r\n        return next(iter(self.instance_map[self.component_dict[key]]))\r\n\r\n    def get_component_dict_no_cycles(self):\r\n        self._component_dict_no_cycles = copy.deepcopy(self.component_dict)\r\n        self.system_graph_no_cycles = copy.deepcopy(self.system_graph)\r\n        self.get_subgraph_dict_no_cycles()\r\n        self.required_initialization_connections = []\r\n\r\n        controller_instances = [v for v in self._component_dict_no_cycles.values() if isinstance(v, base.Controller)]\r\n        for controller in controller_instances:\r\n            modeled_components = self.instance_map[self.component_dict[controller.id]]\r\n            base_controller = [v for v in modeled_components if isinstance(v, base.Controller)][0]\r\n            controlled_components = [self._component_dict_no_cycles[self.instance_map_reversed[c.isPropertyOf].id] for c in base_controller.controls]\r\n            assert len(controlled_components)!=0, f\"No controlled components found for controller with id: {controller.id}\"\r\n            visited = self._depth_first_search_system(controller)\r\n\r\n            for controlled_component in controlled_components:\r\n                for reachable_component in visited:\r\n                    for connection in reachable_component.connectedThrough:\r\n                        connection_point = connection.connectsSystemAt\r\n                        receiver_component = connection_point.connectionPointOf\r\n                        if controlled_component==receiver_component:\r\n                            controlled_component.connectsAt.remove(connection_point)\r\n                            reachable_component.connectedThrough.remove(connection)\r\n                            edge_label = self.get_edge_label(connection.senderPropertyName, connection_point.receiverPropertyName)\r\n                            status = self._del_edge(self.system_graph_no_cycles, reachable_component.id, controlled_component.id, label=edge_label)\r\n                            assert status, \"del_edge returned False. Check if additional characters should be added to \\\"disallowed_characters\\\".\"\r\n\r\n                            self.required_initialization_connections.append(connection)\r\n\r\n    def _set_addUncertainty(self, addUncertainty=None, filter=\"physicalSystem\"):\r\n        allowed_filters = [\"all\", \"physicalSystem\"]\r\n        assert isinstance(addUncertainty, bool), \"Argument addUncertainty must be True or False\"\r\n        assert filter in allowed_filters, f\"The \\\"filter\\\" argument must be one of the following: {', '.join(allowed_filters)} - \\\"{filter}\\\" was provided.\"\r\n        sensor_instances = self.get_component_by_class(self.component_dict, base.Sensor)\r\n        meter_instances = self.get_component_by_class(self.component_dict, base.Meter)\r\n        instances = sensor_instances\r\n        instances.extend(meter_instances)\r\n        if filter==\"all\":\r\n            for instance in instances:\r\n                instance.addUncertainty = addUncertainty\r\n        elif filter==\"physicalSystem\":\r\n            for instance in instances:\r\n                if instance.isPhysicalSystem: #Only set the variable if the measuring device is real data supplied as input to the model\r\n                    instance.initialize()\r\n                    instance.addUncertainty = addUncertainty\r\n\r\n    def load_chain_log(self, filename):\r\n        with open(filename, 'rb') as handle:\r\n            self.chain_log = pickle.load(handle)\r\n            self.chain_log[\"chain.T\"] = 1/self.chain_log[\"chain.betas\"]\r\n\r\n    def set_trackGradient(self, trackGradient):\r\n        assert isinstance(trackGradient, bool), \"Argument trackGradient must be True or False\" \r\n        for component in self.flat_execution_order:\r\n            component.trackGradient = trackGradient\r\n\r\n    def map_execution_order(self):\r\n        self.execution_order = [[self.component_dict[component.id] for component in component_group] for component_group in self.execution_order]\r\n\r\n    def map_required_initialization_connections(self):\r\n        self.required_initialization_connections = [connection for no_cycle_connection in self.required_initialization_connections for connection in self.component_dict[no_cycle_connection.connectsSystem.id].connectedThrough if connection.senderPropertyName==no_cycle_connection.senderPropertyName]\r\n\r\n    def check_for_for_missing_initial_values(self):\r\n        for connection in self.required_initialization_connections:\r\n            component = connection.connectsSystem\r\n            if connection.senderPropertyName not in component.output:\r\n                raise Exception(f\"The component with id: \\\"{component.id}\\\" and class: \\\"{component.__class__.__name__}\\\" is missing an initial value for the output: {connection.senderPropertyName}\")\r\n            elif component.output[connection.senderPropertyName] is None:\r\n                raise Exception(f\"The component with id: \\\"{component.id}\\\" and class: \\\"{component.__class__.__name__}\\\" is missing an initial value for the output: {connection.senderPropertyName}\")\r\n                \r\n    def _get_execution_order_old(self):\r\n        self.get_component_dict_no_cycles_old()\r\n        initComponents = [v for v in self._component_dict_no_cycles.values() if len(v.connectsAt)==0]\r\n        self.activeComponents = initComponents\r\n        self.execution_order = []\r\n        while len(self.activeComponents)>0:\r\n            self._traverse()\r\n\r\n        self.map_execution_order()\r\n        self.map_required_initialization_connections()\r\n        self.flat_execution_order = self._flatten(self.execution_order)\r\n        assert len(self.flat_execution_order)==len(self._component_dict_no_cycles), f\"Cycles detected in the model. Inspect the generated file \\\"system_graph.png\\\" to see where.\"\r\n\r\n    def _get_execution_order(self):\r\n        self.get_component_dict_no_cycles()\r\n        initComponents = [v for v in self._component_dict_no_cycles.values() if len(v.connectsAt)==0]\r\n        self.activeComponents = initComponents\r\n        self.execution_order = []\r\n        while len(self.activeComponents)>0:\r\n            self._traverse()\r\n\r\n        self.map_execution_order()\r\n        self.map_required_initialization_connections()\r\n        self.flat_execution_order = self._flatten(self.execution_order)\r\n        assert len(self.flat_execution_order)==len(self._component_dict_no_cycles), f\"Cycles detected in the model. Inspect the generated file \\\"system_graph.png\\\" to see where.\"\r\n\r\n    def _traverse(self):\r\n        activeComponentsNew = []\r\n        self.component_group = []\r\n        for component in self.activeComponents:\r\n            self.component_group.append(component)\r\n            for connection in component.connectedThrough:\r\n                connection_point = connection.connectsSystemAt\r\n                receiver_component = connection_point.connectionPointOf\r\n                receiver_component.connectsAt.remove(connection_point)\r\n                if len(receiver_component.connectsAt)==0:\r\n                    activeComponentsNew.append(receiver_component)\r\n        self.activeComponents = activeComponentsNew\r\n        self.execution_order.append(self.component_group)\r\n\r\n\r\n\r\n    ###### METHODS NOT CURRENTLY USED ######\r\n    def get_leaf_subsystems(self, system):\r\n        for sub_system in system.hasSubSystem:\r\n            if sub_system.hasSubSystem is None:\r\n                self.leaf_subsystems.append(sub_system)\r\n            else:\r\n                self.get_leaf_subsystems(sub_system)\r\n\r\n\r\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n    \r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/twin4build/model/model.py b/twin4build/model/model.py
--- a/twin4build/model/model.py	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ b/twin4build/model/model.py	(date 1716281439713)
@@ -3163,8 +3163,8 @@
         # self.add_outdoor_environment_system()
         if semantic_model_filename is not None:
             self.read_datamodel_config(semantic_model_filename)
-            self._create_object_graph(self.component_base_dict)
-            self.draw_object_graph(filename="object_graph_input")
+            #self._create_object_graph(self.component_base_dict)
+            #self.draw_object_graph(filename="object_graph_input")
             self.apply_model_extensions()
 
         if fcn is not None:
@@ -3183,11 +3183,11 @@
 
         self.validate_model()
         self._create_system_graph()
-        self.draw_system_graph()
+        #self.draw_system_graph()
         self._get_execution_order_old()
         self._create_flat_execution_graph()
-        self.draw_system_graph_no_cycles()
-        self.draw_execution_graph()
+        #self.draw_system_graph_no_cycles()
+        #self.draw_execution_graph()
         if do_load_parameters:
             self._load_parameters()
 
@@ -3240,7 +3240,7 @@
         if semantic_model_filename is not None:
             self.read_datamodel_config(semantic_model_filename)
             self._create_object_graph(self.component_base_dict)
-            self.draw_object_graph(filename="object_graph_input")
+            #self.draw_object_graph(filename="object_graph_input")
             self.parse_semantic_model()
 
 
@@ -3248,7 +3248,7 @@
             self.read_input_config(input_config)
 
         self._create_object_graph(self.component_base_dict)
-        self.draw_object_graph(filename="object_graph_parsed")
+        #self.draw_object_graph(filename="object_graph_parsed")
         # self._create_object_graph(self.component_dict)
         # self.draw_object_graph(filename="object_graph_completed")
         if infer_connections:
@@ -3266,7 +3266,7 @@
             self._create_signature_graphs()
         
         self._create_system_graph()
-        self.draw_system_graph()
+        #self.draw_system_graph()
         # self._get_execution_order()
         # self._create_flat_execution_graph()
         # self.draw_system_graph_no_cycles()
@@ -3275,8 +3275,8 @@
         self.validate_model()
         self._get_execution_order()
         self._create_flat_execution_graph()
-        self.draw_system_graph_no_cycles()
-        self.draw_execution_graph()
+        #self.draw_system_graph_no_cycles()
+        #self.draw_execution_graph()
         self._load_parameters()
 
     def fcn(self):
Index: twin4build/estimator/tests/test_load_emcee_chain.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import matplotlib.pyplot as plt\r\nimport matplotlib\r\nimport pickle\r\nimport math\r\nimport numpy as np\r\nimport os\r\nimport datetime\r\nimport sys\r\nimport corner\r\nimport seaborn as sns\r\nimport copy\r\nfrom dateutil import tz\r\nfrom io import StringIO\r\nfrom matplotlib.colors import LinearSegmentedColormap\r\nif __name__ == '__main__':\r\n    uppath = lambda _path,n: os.sep.join(_path.split(os.sep)[:-n])\r\n    file_path = uppath(os.path.abspath(__file__), 4)\r\n    sys.path.append(file_path)\r\nfrom twin4build.utils.uppath import uppath\r\nfrom twin4build.simulator.simulator import Simulator\r\nfrom twin4build.model.model import Model\r\nfrom twin4build.model.tests.test_LBNL_bypass_coil_model import fcn\r\nimport twin4build.utils.plot.plot as plot\r\n\r\ndef test_load_emcee_chain():\r\n    # flat_attr_list = [\"m1_flow_nominal\", \"m2_flow_nominal\", \"tau1\", \"tau2\", \"tau_m\", \"nominalUa.hasValue\", \"workingPressure.hasValue\", \"flowCoefficient.hasValue\", \"waterFlowRateMax\", \"c1\", \"c2\", \"c3\", \"c4\", \"eps_motor\", \"f_motorToAir\", \"kp\", \"Ti\", \"Td\"]\r\n    # flat_attr_list = [r\"$\\dot{m}_{w,nom}$\", r\"$\\dot{m}_{a,nom}$\", r\"$\\tau_1$\", r\"$\\tau_2$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\Delta P_{sys}$\", r\"$K_{v}$\", r\"$\\dot{m}_{w,nom}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$\\epsilon$\", r\"$f_{motorToAir}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\"]\r\n    # flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\Delta P_{fixed}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{comb}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\"]\r\n    # flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$\\dot{m}_{pump,w,nom}$\", r\"$\\Delta P_{check}$\", r\"$\\Delta P_{coil}$\", r\"$T_{rise}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{comb}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\"]\r\n    # flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$\\dot{m}_{p,w,nom}$\", r\"$\\Delta P_{check}$\", r\"$\\Delta P_{coil}$\", r\"$\\Delta P_{p,nom}$\", r\"$\\Delta P_{v,nom}$\", r\"$\\Delta P_{sys}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{comb}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\"]\r\n    # flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$\\dot{m}_{p,w,nom}$\", r\"$\\Delta P_{check}$\", r\"$\\Delta P_{coil}$\", r\"$\\Delta P_{p,nom}$\", r\"$\\Delta P_{sys}$\", r\"$T_{rise}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{comb}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\"]\r\n    # flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$\\dot{m}_{pump,w,nom}$\", r\"$\\Delta P_{check}$\", r\"$\\Delta P_{coil}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{comb}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\"]\r\n    flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$\\dot{m}_{pump,w,nom}$\", r\"$\\Delta P_{check}$\", r\"$\\Delta P_{coil}$\", r\"$\\Delta P_{pump}$\", r\"$\\Delta P_{sys}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{comb}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\", ]\r\n    flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$\\dot{m}_{pump,w,nom}$\", r\"$\\Delta P_{check}$\", r\"$\\Delta P_{coil}$\", r\"$\\Delta P_{pump}$\", r\"$\\Delta P_{sys}$\", r\"$T_{w,inlet}$\", r\"$T_{w,outlet}$\", r\"$T_{a,outlet}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{comb}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\", \"a1\", \"tau1\", \"a2\", \"tau2\", \"a3\", \"tau3\", \"a4\", \"tau4\", \"a5\", \"tau5\"]\r\n    flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$\\dot{m}_{pump,w,nom}$\", r\"$\\Delta P_{check}$\", r\"$\\Delta P_{coil}$\", r\"$\\Delta P_{pump}$\", r\"$\\Delta P_{sys}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{comb}$\", r\"$K_p$\", r\"$T_i$\", r\"$T_d$\", r\"$a_1$\", r\"$tau_1$\", r\"$a_2$\", r\"$tau_2$\", \"a3\", \"tau3\", \"a4\", \"tau4\", \"a5\", \"tau5\"]\r\n    flat_attr_list = [r\"$\\dot{m}_{c,w,nom}$\", r\"$\\dot{m}_{c,a,nom}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$UA_{nom}$\", r\"$\\dot{m}_{v,w,nom}$\", r\"$\\dot{m}_{p,w,nom}$\", r\"$\\Delta P_{cv}$\", r\"$\\Delta P_{c}$\", r\"$\\Delta P_{p}$\", r\"$\\Delta P_{s}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f$\", r\"$K_P$\", r\"$T_I$\", r\"$T_D$\"]\r\n    flat_attr_list = [r\"$\\overline{\\dot{m}}_{c,w}$\", r\"$\\overline{\\dot{m}}_{c,a}$\", r\"$\\tau_w$\", r\"$\\tau_a$\", r\"$\\tau_m$\", r\"$\\overline{UA}$\", r\"$\\overline{\\dot{m}}_{v,w}$\", r\"$\\overline{\\dot{m}}_{cv,w}$\", r\"$K_{cv}$\", r\"$\\Delta P_{s,res}$\", r\"$\\overline{\\Delta P}_{c}$\", r\"$\\Delta P_{p}$\", r\"$\\Delta P_{s}$\", r\"$c_1$\", r\"$c_2$\", r\"$c_3$\", r\"$c_4$\", r\"$f_{tot}$\", r\"$K_P$\", r\"$T_I$\", r\"$T_D$\"]\r\n\r\n    # \"KvCheckValve\", \"dpFixedSystem\",\r\n\r\n    colors = sns.color_palette(\"deep\")\r\n    blue = colors[0]\r\n    orange = colors[1]\r\n    green = colors[2]\r\n    red = colors[3]\r\n    purple = colors[4]\r\n    brown = colors[5]\r\n    pink = colors[6]\r\n    grey = colors[7]\r\n    beis = colors[8]\r\n    sky_blue = colors[9]\r\n    plot.load_params()\r\n\r\n    do_analysis_plots = False #############################################\r\n    assume_uncorrelated_noise = False\r\n\r\n    if do_analysis_plots:\r\n        do_iac_plot = True\r\n        do_logl_plot = True\r\n        do_trace_plot = True\r\n        do_jump_plot = True\r\n        do_corner_plot = True\r\n        do_inference = False\r\n    else:\r\n        do_iac_plot = False\r\n        do_logl_plot = False\r\n        do_trace_plot = False\r\n        do_jump_plot = False\r\n        do_corner_plot = False\r\n        do_inference = True\r\n\r\n    \r\n    do_swap_plot = False\r\n    \r\n    assert (do_iac_plot and do_inference)!=True\r\n\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230829_155706_chain_log.pickle\")\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230830_194210_chain_log.pickle\")\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230902_183719_chain_log.pickle\")\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230904_171903_chain_log.pickle\")\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230905_092246_chain_log.pickle\")\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230907_160103_chain_log.pickle\")\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230908_114136_chain_log.pickle\")\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230908_233103_chain_log.pickle\") #No flow dependence\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230911_113906_chain_log.pickle\") #No flow dependence\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230912_120849_chain_log.pickle\") #No flow dependence\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230913_093046_chain_log.pickle\") #No flow dependence\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230914_164406_chain_log.pickle\") #No flow dependence\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230915_091654_chain_log.pickle\") #No flow dependence\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230923_164550_chain_log.pickle\") #T_max=1e+5\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230923_192545_chain_log.pickle\") #T_max=inf\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230923_194507_chain_log.pickle\") #T_max=inf, Tau=300\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230923_234059_chain_log.pickle\") #T_max=inf, 8*walkers\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230925_102035_chain_log.pickle\") #Tinf_fanLimits_coilFlowDependent , 8*walkers\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230926_131018_chain_log.pickle\") #10 temps , 4*walkers\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230926_225917_chain_log.pickle\") #10 temps , 4*walkers\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230927_135449_chain_log.pickle\") #10 temps , 4*walkers, 30tau\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230927_154822_chain_log.pickle\") #1 temps , 30*walkers, 30tau\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230928_102504_chain_log.pickle\") #10 temps , 4*walkers, 30tau\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230928_124040_chain_log.pickle\") #15 temps , 8*walkers, 30tau\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230929_101059_chain_log.pickle\") #15 temps , 8*walkers, 30tau, large water massflow         CURRENT BEST\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230930_175014_chain_log.pickle\") #15 temps , 8*walkers, 200tau, large water massflow\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20230930_181209_chain_log.pickle\") #15 temps , 8*walkers, 200tau, large water massflow, gaussian x0\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231001_162530_chain_log.pickle\") #1 temps , 500walkers, 200tau, large water massflow\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231002_141008_chain_log.pickle\") #12 temps , 8*walkers, 30tau, large water massflow\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231002_160750_chain_log.pickle\") #12 temps , 8*walkers, 30tau, large water massflow\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231005_134721_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231005_215753_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, large massflow\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231009_132524_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231009_153513_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, lower UA\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231010_120630_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231011_131932_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol, valve more parameters\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231012_154701_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol, valve more parameters, lower UA\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231013_123013_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231017_074841_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231018_092240_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), \"chain_logs\", \"20231018_135249_chain_log.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231205_110432_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231205_110432_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231205_164843_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231206_131318_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231206_212149_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231207_160247_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231208_160545_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231219_155600_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20231229_103204_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240102_141037_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240103_140207_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240104_094246_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240104_171830_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240105_165854_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240107_224328_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240107_224328_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240108_175437_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240109_110253_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240109_143730_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240110_093807_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240110_141839_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240110_174122_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240108_175437_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240111_114834_.pickle\") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240111_164945_.pickle\") # assume_uncorrelated_noise = True, uniform prior\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240112_120101_.pickle\") # assume_uncorrelated_noise = False, gaussian prior, Exp-squared\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240115_135515_.pickle\") # assume_uncorrelated_noise = False, uniform prior, Exp-squared\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240116_085308_.pickle\") # assume_uncorrelated_noise = False, uniform prior, Matern 3/2\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240117_164040_.pickle\") # assume_uncorrelated_noise = False, gaussian model prior, uniform noise prior, Matern 3/2\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240121_111340_.pickle\") # assume_uncorrelated_noise = False, uniform prior, Matern 5/2\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240122_084923_.pickle\") # assume_uncorrelated_noise = False, gaussian model prior, uniform noise prior, Exp-squared\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240122_123919_.pickle\") # assume_uncorrelated_noise = False, gaussian model prior, uniform noise prior, Exp-squared, \r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240125_155122_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, \r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240129_164944_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240130_121316_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240130_160539_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240131_072240_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240131_083244_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240201_110142_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240201_140753_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240202_110521_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240202_123159_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240202_125602_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240202_133846_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240202_150303_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240202_160320_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240203_063309_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240203_071409_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240203_073057_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240203_083515_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240204_071648_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240204_103156_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240205_140422_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240205_160725_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240206_082238_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240206_104252_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240206_115255_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240206_132242_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240206_134422_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240206_141502_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240206_154844_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240207_084503_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240207_172222_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240208_113647_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240208_133307_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240209_083923_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240209_121135_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240209_142113_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240209_161142_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240210_085932_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), \"generated_files\", \"model_parameters\", \"chain_logs\", \"model_20240211_094648_.pickle\") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"model_20240211_094648_.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240212_161904.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240213_093536.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240222_154216.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240223_075319.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240226_150659.pickle\")\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240226_120030.pickle\")\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240227_183054.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240227_115853.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240228_081523.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240228_223049.pickle\")\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240228_155339.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240229_100544.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240229_130556.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240229_222938.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240302_010809.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240304_084842.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240304_143757.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240305_013720.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240306_082449.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240307_013709.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240306_135237.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240307_174318.pickle\")\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240307_130004.pickle\") #Really good no gp\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240309_021817.pickle\")\r\n\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240308_154530.pickle\")\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240307_164717.pickle\")\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240313_161609.pickle\")\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240314_145953.pickle\")\r\n\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240315_033100.pickle\")\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240315_055118.pickle\")\r\n\r\n\r\n    ######\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240315_060209.pickle\")\r\n\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240316_001905.pickle\") #gaussian\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240315_200758.pickle\") #uniform ###########################################\r\n\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240315_161324.pickle\") #gaussian\r\n    \r\n\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240316_192229.pickle\") #uniform\r\n\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240404_073632.pickle\") #uniform ###########################################\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240405_004803.pickle\") #uniform ###########################################\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240408_185151.pickle\") #uniform a=5, good ###########################################\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240408_083352.pickle\") #uniform a=5 ###########################################\r\n\r\n\r\n    \r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240409_144236.pickle\") #uniform a=5, 2-day, only model ###########################################\r\n    # loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240410_114906.pickle\") #uniform a=5, 2-day ###########################################\r\n\r\n\r\n    ############################################### Udskiftes\r\n    loaddir = os.path.join(r\"C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\python\\BuildingEnergyModel\\remote_results\\chain_logs\\chain_logs\", \"20240411_205028.pickle\") #uniform a=5, 1-day, err=0.1 ###########################################\r\n############################################################################################################\r\n    \r\n\r\n\r\n\r\n    with open(loaddir, 'rb') as handle:\r\n        result = pickle.load(handle)\r\n\r\n    # c = result[\"component_id\"]\r\n    # c = [s.replace(\"+\", \"_\") for s in c]\r\n    # result[\"component_id\"] = c\r\n    # with open(loaddir, 'wb') as handle:\r\n    #     pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n\r\n    \r\n\r\n\r\n    result[\"chain.T\"] = 1/result[\"chain.betas\"] ##################################\r\n    \r\n    burnin = 2000#int(result[\"chain.x\"].shape[0])-3000 #100\r\n    #########################################\r\n    list_ = [\"integratedAutoCorrelatedTime\"]#, \"chain.jumps_accepted\", \"chain.jumps_proposed\", \"chain.swaps_accepted\", \"chain.swaps_proposed\"]\r\n    for key in list_:\r\n        result[key] = np.array(result[key])\r\n    #########################################\r\n\r\n    vmin = np.min(result[\"chain.betas\"])\r\n    vmax = np.max(result[\"chain.betas\"])\r\n\r\n    print(result[\"chain.x\"].shape)\r\n\r\n\r\n    # cm = plt.get_cmap('RdYlBu', ntemps)\r\n    # cm_sb = sns.color_palette(\"vlag_r\", n_colors=ntemps, center=\"dark\") #vlag_r\r\n    \r\n#################################################################\r\n    # logl = result[\"chain.logl\"]\r\n    # logl[np.abs(logl)>1e+9] = np.nan\r\n    # print(logl[:,0,:].max())\r\n    # indices = np.where(logl[:,0,:] == logl[:,0,:].max())\r\n    # s0 = indices[0][0]\r\n    # s1 = indices[1][0]\r\n    # a = result[\"chain.x\"][s0, 0, s1, :]\r\n    # a = np.resize(a, (1,2,1,a.shape[0]))\r\n    # result[\"chain.x\"] = a\r\n    # for key in result.keys():\r\n    #     # if key not in list_:\r\n    #     if isinstance(result[key], list):\r\n    #         result[key] = np.array(result[key])\r\n########################################################\r\n\r\n    ndim = result[\"chain.x\"].shape[3]\r\n    ntemps = result[\"chain.x\"].shape[1]\r\n    nwalkers = result[\"chain.x\"].shape[2] #Round up to nearest even number and multiply by 2\r\n\r\n\r\n    cm_sb = sns.diverging_palette(210, 0, s=50, l=50, n=ntemps, center=\"dark\") #vlag_r\r\n    cm_sb_rev = list(reversed(cm_sb))\r\n    cm_mpl = LinearSegmentedColormap.from_list(\"seaborn\", cm_sb)#, N=ntemps)\r\n    cm_mpl_rev = LinearSegmentedColormap.from_list(\"seaborn_rev\", cm_sb_rev, N=ntemps)\r\n\r\n    # startTime = datetime.datetime(year=2022, month=1, day=1, hour=0, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    # endTime = datetime.datetime(year=2022, month=2, day=15, hour=0, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    # startTime = datetime.datetime(year=2022, month=2, day=8, hour=10, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    # endTime = datetime.datetime(year=2022, month=2, day=8, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    \r\n    stepSize = 60\r\n    model = Model(id=\"test_load_emcee_chain\", saveSimulationResult=True)\r\n    model.load_model(infer_connections=False, fcn=fcn)\r\n    simulator = Simulator(model)\r\n\r\n    startTime_test1 = datetime.datetime(year=2022, month=2, day=6, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test1 = datetime.datetime(year=2022, month=2, day=6, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test2 = datetime.datetime(year=2022, month=2, day=7, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test2 = datetime.datetime(year=2022, month=2, day=7, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test3 = datetime.datetime(year=2022, month=2, day=8, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test3 = datetime.datetime(year=2022, month=2, day=8, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test4 = datetime.datetime(year=2022, month=2, day=9, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test4 = datetime.datetime(year=2022, month=2, day=9, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test5 = datetime.datetime(year=2022, month=2, day=10, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))  \r\n    endTime_test5 = datetime.datetime(year=2022, month=2, day=10, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test6 = datetime.datetime(year=2022, month=2, day=11, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test6 = datetime.datetime(year=2022, month=2, day=11, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n\r\n    startTime_test7 = datetime.datetime(year=2022, month=2, day=12, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test7 = datetime.datetime(year=2022, month=2, day=12, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test8 = datetime.datetime(year=2022, month=2, day=13, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test8 = datetime.datetime(year=2022, month=2, day=13, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test9 = datetime.datetime(year=2022, month=2, day=14, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test9 = datetime.datetime(year=2022, month=2, day=14, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test10 = datetime.datetime(year=2022, month=2, day=15, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test10 = datetime.datetime(year=2022, month=2, day=15, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test11 = datetime.datetime(year=2022, month=2, day=16, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test11 = datetime.datetime(year=2022, month=2, day=16, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    startTime_test12 = datetime.datetime(year=2022, month=2, day=17, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n    endTime_test12 = datetime.datetime(year=2022, month=2, day=17, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n\r\n\r\n    startTime_test = [startTime_test1, startTime_test2, startTime_test3, startTime_test4, startTime_test5, startTime_test6, startTime_test7, startTime_test8, startTime_test9, startTime_test10]\r\n    endTime_test = [endTime_test1, endTime_test2, endTime_test3, endTime_test4, endTime_test5, endTime_test6, endTime_test7, endTime_test8, endTime_test9, endTime_test10]\r\n    stepSize_test = [stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize]\r\n\r\n    startTime_test = [startTime_test3, startTime_test4, startTime_test5, startTime_test6, startTime_test7, startTime_test8, startTime_test9, startTime_test10]\r\n    endTime_test = [endTime_test3, endTime_test4, endTime_test5, endTime_test6, endTime_test7, endTime_test8, endTime_test9, endTime_test10]\r\n    stepSize_test = [stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize]\r\n\r\n    startTime_test = [startTime_test10]#, startTime_test11, startTime_test12] ########### Plot only one day\r\n    endTime_test = [endTime_test10]#, endTime_test11, endTime_test12]\r\n    stepSize_test = [stepSize]#, stepSize, stepSize]\r\n\r\n\r\n    coil = model.component_dict[\"coil_pump_valve\"]\r\n    fan = model.component_dict[\"fan\"]\r\n    controller = model.component_dict[\"controller\"]\r\n\r\n\r\n    # targetParameters = {\r\n    #             # coil: [\"m1_flow_nominal\", \"m2_flow_nominal\", \"tau1\", \"tau2\", \"tau_m\", \"nominalUa.hasValue\", \"mFlowValve_nominal\", \"mFlowPump_nominal\", \"dpCheckValve_nominal\", \"dp1_nominal\", \"dpPump\", \"dpSystem\", \"tau_w_inlet\", \"tau_w_outlet\", \"tau_air_outlet\"],\r\n    #             coil: [\"m1_flow_nominal\", \"m2_flow_nominal\", \"tau1\", \"tau2\", \"tau_m\", \"nominalUa.hasValue\", \"mFlowValve_nominal\", \"mFlowPump_nominal\", \"dpCheckValve_nominal\", \"dp1_nominal\", \"dpPump\", \"dpSystem\"],\r\n    #             fan: [\"c1\", \"c2\", \"c3\", \"c4\", \"f_total\"],\r\n    #             controller: [\"kp\", \"Ti\", \"Td\"]}\r\n    \r\n    targetParameters = {\r\n                    coil: [\"m1_flow_nominal\", \"m2_flow_nominal\", \"tau1\", \"tau2\", \"tau_m\", \"nominalUa.hasValue\", \"mFlowValve_nominal\", \"mFlowPump_nominal\", \"KvCheckValve\", \"dpFixedSystem\", \"dp1_nominal\", \"dpPump\", \"dpSystem\"],\r\n                    # coil: [\"m1_flow_nominal\", \"m2_flow_nominal\", \"tau1\", \"tau2\", \"tau_m\", \"nominalUa.hasValue\", \"mFlowValve_nominal\", \"mFlowPump_nominal\", \"dpCheckValve_nominal\", \"dp1_nominal\", \"dpPump\", \"dpSystem\"],\r\n                    fan: [\"c1\", \"c2\", \"c3\", \"c4\", \"f_total\"],\r\n                    controller: [\"kp\", \"Ti\", \"Td\"]}\r\n            \r\n    percentile = 2\r\n    # targetMeasuringDevices = {model.component_dict[\"valve position sensor\"]: {\"standardDeviation\": 0.01/percentile, \"scale_factor\": 1},\r\n    #                         model.component_dict[\"coil inlet water temperature sensor\"]: {\"standardDeviation\": 0.1/percentile, \"scale_factor\": 1},\r\n    #                         model.component_dict[\"coil outlet water temperature sensor\"]: {\"standardDeviation\": 0.1/percentile, \"scale_factor\": 1},\r\n    #                             model.component_dict[\"coil outlet air temperature sensor\"]: {\"standardDeviation\": 0.1/percentile, \"scale_factor\": 1},\r\n    #                             model.component_dict[\"fan power meter\"]: {\"standardDeviation\": 80/percentile, \"scale_factor\": 1000}}\r\n    \r\n    targetMeasuringDevices = {model.component_dict[\"coil outlet air temperature sensor\"]: {\"standardDeviation\": 0.1/percentile, \"scale_factor\": 1},\r\n                                model.component_dict[\"coil outlet water temperature sensor\"]: {\"standardDeviation\": 0.1/percentile, \"scale_factor\": 1},\r\n                                model.component_dict[\"fan power meter\"]: {\"standardDeviation\": 80/percentile, \"scale_factor\": 1000},\r\n                                model.component_dict[\"valve position sensor\"]: {\"standardDeviation\": 0.01/percentile, \"scale_factor\": 1},\r\n                                model.component_dict[\"coil inlet water temperature sensor\"]: {\"standardDeviation\": 0.1/percentile, \"scale_factor\": 1}}\r\n\r\n    n_par = result[\"n_par\"]\r\n    n_par_map = result[\"n_par_map\"]\r\n    print(result[\"n_par\"])\r\n    print(result[\"n_par_map\"])\r\n    # n_par = len(flat_attr_list) if result[\"n_par\"]<=len(flat_attr_list) else result[\"n_par\"]\r\n    # print(n_par_map)\r\n    # # Get number of gaussian process parameters\r\n    # for j, measuring_device in enumerate(targetMeasuringDevices):\r\n    #     source_component = [cp.connectsSystemThrough.connectsSystem for cp in measuring_device.connectsAt][0]\r\n    #     n_par += len(source_component.input)+3\r\n    #     n_par_map[measuring_device.id] = len(source_component.input)+3\r\n    # print(n_par)\r\n    # print(n_par_map)\r\n\r\n\r\n    if assume_uncorrelated_noise==False:\r\n        for j, measuring_device in enumerate(targetMeasuringDevices):\r\n            # print(n_par_map[measuring_device.id])\r\n            for i in range(n_par_map[measuring_device.id]):\r\n                if i==0:\r\n                    s = f\"$a_{str(j)}$\"\r\n                    s = r'{}'.format(s)\r\n                    flat_attr_list.append(s)\r\n                # elif i==1:\r\n                #     s = r'$\\gamma_{%.0f}$' % (j,)\r\n                #     flat_attr_list.append(s)\r\n                # elif i==2:\r\n                #     s = r'$\\mathrm{ln}P_{%.0f}$' % (j,)\r\n                #     flat_attr_list.append(s)\r\n                else:\r\n                    s = r'$l_{%.0f,%.0f}$' % (j,i-1, )\r\n                    flat_attr_list.append(s)\r\n\r\n        # result[\"stepSize_train\"] = stepSize\r\n        # result[\"startTime_train\"] = startTime\r\n        # result[\"endTime_train\"] = endTime\r\n\r\n        # standardDeviation = np.array([0.01/percentile, 0.5/2, 0.5/2, 0.5/2, 80/2])\r\n\r\n\r\n        # flat_component_list = [obj.id for obj, attr_list in targetParameters.items() for i in range(len(attr_list))]\r\n        # flat_attr_list = [attr for attr_list in targetParameters.values() for attr in attr_list]\r\n\r\n        # result[\"component_list\"] = flat_component_list\r\n        # result[\"attr_list\"] = flat_attr_list\r\n\r\n        # with open(loaddir, 'wb') as handle:\r\n        #     pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n                    \r\n\r\n    if do_inference:\r\n        model.load_chain_log(loaddir)\r\n\r\n        startTime_train1 = datetime.datetime(year=2022, month=2, day=1, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        endTime_train1 = datetime.datetime(year=2022, month=2, day=1, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        startTime_train2 = datetime.datetime(year=2022, month=2, day=2, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        endTime_train2 = datetime.datetime(year=2022, month=2, day=2, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        startTime_train3 = datetime.datetime(year=2022, month=2, day=3, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        endTime_train3 = datetime.datetime(year=2022, month=2, day=3, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        startTime_train4 = datetime.datetime(year=2022, month=2, day=4, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        endTime_train4 = datetime.datetime(year=2022, month=2, day=4, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        startTime_train5 = datetime.datetime(year=2022, month=2, day=5, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        endTime_train5 = datetime.datetime(year=2022, month=2, day=5, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        startTime_train6 = datetime.datetime(year=2022, month=2, day=6, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        endTime_train6 = datetime.datetime(year=2022, month=2, day=6, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        startTime_train7 = datetime.datetime(year=2022, month=2, day=7, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        endTime_train7 = datetime.datetime(year=2022, month=2, day=7, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        model.chain_log[\"startTime_train\"] = [startTime_train1, startTime_train2, startTime_train3, startTime_train4, startTime_train5, startTime_train6, startTime_train7]\r\n        model.chain_log[\"endTime_train\"] = [endTime_train1, endTime_train2, endTime_train3, endTime_train4, endTime_train5, endTime_train6, endTime_train7]\r\n        model.chain_log[\"stepSize_train\"] = [stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize]\r\n\r\n        # startTime_train1 = datetime.datetime(year=2022, month=2, day=1, hour=8, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        # endTime_train1 = datetime.datetime(year=2022, month=2, day=3, hour=22, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n        # model.chain_log[\"startTime_train\"] = [startTime_train1]\r\n        # model.chain_log[\"endTime_train\"] = [endTime_train1]\r\n        # model.chain_log[\"stepSize_train\"] = [stepSize]\r\n        # model.chain_log[\"n_par\"] = n_par\r\n        # model.chain_log[\"n_par_map\"] = n_par_map\r\n        print(result[\"chain.x\"].shape)\r\n        parameter_chain = result[\"chain.x\"][burnin:,0,:,:]\r\n        parameter_chain = parameter_chain[::100,:,:]\r\n        print(parameter_chain.shape)\r\n        del result\r\n        del model.chain_log[\"chain.x\"]\r\n\r\n\r\n        # ylims = ([20, 23], [19.5, 25], [None, None], [0,1], [19.5, 28])\r\n        ylims = ([0,1], [19.5, 28.5], [19.5, 25.5], [20, 23.5], [None, None])\r\n        \r\n        assert len(flat_attr_list) == ndim, f\"Number of parameters in flat_attr_list ({len(flat_attr_list)}) does not match number of parameters in chain.x ({ndim})\"\r\n        # parameter_chain = result[\"chain.x\"][-1:,0,:,:] #[-1:,0,:,:]\r\n        parameter_chain = parameter_chain.reshape((parameter_chain.shape[0]*parameter_chain.shape[1], parameter_chain.shape[2]))\r\n        fig, axes = simulator.run_emcee_inference(model, parameter_chain, targetParameters, targetMeasuringDevices, startTime_test, endTime_test, stepSize_test, assume_uncorrelated_noise=assume_uncorrelated_noise)\r\n        ylabels = [r\"$u_v [1]$\", r\"$T_{c,w,in} [^\\circ\\!C]$\", r\"$T_{c,w,out} [^\\circ\\!C]$\", r\"$T_{c,a,out} [^\\circ\\!C]$\", r\"$\\dot{P}_f [W]$\"]\r\n        # fig.subplots_adjust(hspace=0.3)\r\n        # fig.set_size_inches((15,10))\r\n        for ax, ylabel, ylim in zip(axes, ylabels, ylims):\r\n            # ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5), prop={'size': 12})\r\n            # pos = ax.get_position()\r\n            # pos.x0 = 0.15       # for example 0.2, choose your value\r\n            # pos.x1 = 0.99       # for example 0.2, choose your value\r\n\r\n            # ax.set_position(pos)\r\n            ax.tick_params(axis='y', labelsize=10)\r\n            # ax.locator_params(axis='y', nbins=3)\r\n            ax.set_ylim(ylim)\r\n            ax.yaxis.set_major_locator(plt.MaxNLocator(3))\r\n            ax.text(-0.07, 0.5, ylabel, fontsize=14, rotation=\"horizontal\", ha=\"right\", transform=ax.transAxes)\r\n            ax.xaxis.label.set_color(\"black\")\r\n\r\n        \r\n        # axes[3].plot(simulator.dateTimeSteps, model.component_dict[\"Supply air temperature setpoint\"].savedOutput[\"scheduleValue\"], color=\"blue\", label=\"setpoint\", linewidth=0.5)\r\n        # axes[3].plot(simulator.dateTimeSteps, model.component_dict[\"fan inlet air temperature sensor\"].get_physical_readings(startTime, endTime, stepSize)[0:-1], color=\"green\", label=\"inlet air\", linewidth=0.5)\r\n        fig.savefig(r'C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\LBNL_inference_plot.png', dpi=300)\r\n        # ax.plot(simulator.dateTimeSteps, simulator.model.component_dict[])\r\n\r\n\r\n    \r\n\r\n    if do_inference==False:\r\n        assert len(flat_attr_list) == ndim, f\"Number of parameters in flat_attr_list ({len(flat_attr_list)}) does not match number of parameters in chain.x ({ndim})\"\r\n        \r\n        plt.rcParams['mathtext.fontset'] = 'cm'\r\n\r\n\r\n\r\n        if assume_uncorrelated_noise==False:\r\n            attr_list_model = flat_attr_list[:-n_par]\r\n            attr_list_noise = flat_attr_list[-n_par:]\r\n            flat_attr_list__ = [attr_list_model, attr_list_noise]\r\n            list_ = [\"chain.x\"]\r\n            result_model = result.copy()\r\n            result_noise = result.copy()\r\n            for key in list_:\r\n                result_key = result[key]\r\n                result_model[key] = result_key[...,:-n_par]\r\n                result_noise[key] = result_key[...,-n_par:]\r\n            result_list = [result_model, result_noise]\r\n        else:\r\n            flat_attr_list__ = [flat_attr_list]\r\n            result_list = [result]\r\n\r\n        if do_jump_plot:\r\n            fig_jump, ax_jump = plt.subplots(layout='compressed')\r\n            fig_jump.set_size_inches((17, 12))\r\n            fig_jump.suptitle(\"Jumps\", fontsize=20)\r\n            # n_checkpoints = result[\"chain.jumps_proposed\"].shape[0]\r\n            # for i_checkpoint in range(n_checkpoints):\r\n            #     for i in range(ntemps):\r\n            #         ax_jump.scatter([i_checkpoint]*nwalkers, result[\"chain.jumps_accepted\"][i_checkpoint,i,:]/result[\"chain.jumps_proposed\"][i_checkpoint,i,:], color=cm_sb[i], s=20, alpha=1)\r\n\r\n            n_it = result[\"chain.jump_acceptance\"].shape[0]\r\n            # for i_walker in range(nwalkers):\r\n            for i in range(ntemps):\r\n                if i==0: #######################################################################\r\n                    ax_jump.plot(range(n_it), result[\"chain.jump_acceptance\"][:,i], color=cm_sb[i])\r\n        if do_logl_plot:\r\n            fig_logl, ax_logl = plt.subplots(layout='compressed')\r\n            fig_logl.set_size_inches((17/4, 12/4))\r\n            fig_logl.suptitle(\"Log-likelihood\", fontsize=20)\r\n            # logl = np.abs(result_[\"chain.logl\"])\r\n            logl = result[\"chain.logl\"]\r\n            logl[np.abs(logl)>1e+9] = np.nan\r\n            \r\n            indices = np.where(logl[:,0,:] == np.nanmax(logl[:,0,:]))\r\n            print(logl[:,0,:].max())\r\n            s0 = indices[0][0]\r\n            s1 = indices[1][0]\r\n            print(\"logl_max: \", logl[s0,0,s1])\r\n            # print(\"x_max: \", result[\"chain.x\"][s0, 0, s1, :])\r\n            \r\n            n_it = result[\"chain.logl\"].shape[0]\r\n            for i_walker in range(nwalkers):\r\n                for i in range(ntemps):\r\n                    if i==0: #######################################################################\r\n                        ax_logl.plot(range(n_it), logl[:,i,i_walker], color=cm_sb[i])\r\n                        # ax_logl.set_yscale('log')\r\n\r\n        for ii, (flat_attr_list_, result_) in enumerate(zip(flat_attr_list__, result_list)):\r\n            nparam = len(flat_attr_list_)\r\n            ncols = 3\r\n            nrows = math.ceil(nparam/ncols)\r\n            print(nparam, ncols, nrows)\r\n\r\n\r\n            ndim = result_[\"chain.x\"].shape[3]\r\n            ntemps = result_[\"chain.x\"].shape[1]\r\n            nwalkers = result_[\"chain.x\"].shape[2] #Round up to nearest even number and multiply by 2\r\n            \r\n            # cm = plt.get_cmap('RdYlBu', ntemps)\r\n            # cm_sb = sns.color_palette(\"vlag_r\", n_colors=ntemps, center=\"dark\") #vlag_r\r\n            cm_sb = sns.diverging_palette(210, 0, s=50, l=50, n=ntemps, center=\"dark\") #vlag_r\r\n            cm_sb_rev = list(reversed(cm_sb))\r\n            cm_mpl = LinearSegmentedColormap.from_list(\"seaborn\", cm_sb)#, N=ntemps)\r\n            cm_mpl_rev = LinearSegmentedColormap.from_list(\"seaborn_rev\", cm_sb_rev, N=ntemps)\r\n\r\n            fig_trace_beta, axes_trace = plt.subplots(nrows=nrows, ncols=ncols, layout='compressed')\r\n            fig_trace_beta.set_size_inches((17, 12))\r\n            \r\n\r\n            # list_ = [\"chain.logl\", \"chain.logP\", \"chain.x\", \"chain.betas\"]\r\n            # for key in list_:\r\n            #     for i, arr in enumerate(result[key]):\r\n            #         result[key][i] = arr[-nsample_checkpoint:]\r\n                \r\n            # for key in result.keys():\r\n            #     result[key] = np.concatenate(result[key],axis=0)\r\n                # result[\"chain.jumps_accepted\"].append(chain.jumps_accepted)\r\n                # result[\"chain.jumps_proposed\"].append(chain.jumps_proposed)\r\n                # result[\"chain.logl\"].append(chain.logl)\r\n                # result[\"chain.logP\"].append(chain.logP)\r\n                # result[\"chain.swaps_accepted\"].append(chain.swaps_accepted)\r\n                # result[\"chain.swaps_proposed\"].append(chain.swaps_proposed)\r\n                # result[\"chain.x\"].append(chain.x)\r\n                # result[\"chain.betas\"].append(chain.betas)\r\n\r\n            # vmin = np.min(result[\"chain.T\"])\r\n            # vmax = np.max(result[\"chain.T\"])\r\n            \r\n            \r\n\r\n\r\n\r\n            if do_iac_plot:\r\n                fig_iac = fig_trace_beta\r\n                axes_iac = copy.deepcopy(axes_trace)\r\n                for j, attr in enumerate(flat_attr_list_):\r\n                    row = math.floor(j/ncols)\r\n                    col = int(j-ncols*row)\r\n                    axes_iac[row, col] = axes_trace[row, col].twinx()\r\n                # fig_iac, axes_iac = plt.subplots(nrows=nrows, ncols=ncols, layout='compressed')\r\n                # fig_iac.set_size_inches((17, 12))\r\n                # fig_iac.suptitle(\"Integrated AutoCorrelated Time\", fontsize=20)\r\n                iac = result_[\"integratedAutoCorrelatedTime\"][:-1]\r\n                n_it = iac.shape[0]\r\n                for i in range(ntemps):\r\n                    beta = result_[\"chain.betas\"][:, i]\r\n                    for j, attr in enumerate(flat_attr_list_):\r\n                        row = math.floor(j/ncols)\r\n                        col = int(j-ncols*row)\r\n                        \r\n                        if ntemps>1:\r\n                            sc = axes_iac[row, col].plot(range(n_it), iac[:,i,j], color=red, alpha=1, zorder=1)\r\n                        else:\r\n                            sc = axes_iac[row, col].plot(range(n_it), iac[:,i,j], color=red, alpha=1, zorder=1)\r\n                \r\n                # add heristic tau = N/50 line\r\n                heuristic_line = np.arange(n_it)/20\r\n                for j, attr in enumerate(flat_attr_list_):\r\n                    row = math.floor(j/ncols)\r\n                    col = int(j-ncols*row)\r\n                    axes_iac[row, col].plot(range(n_it), heuristic_line, color=\"black\", linewidth=1, linestyle=\"dashed\", alpha=1, label=r\"$\\tau=N/50$\")\r\n                    axes_iac[row, col].set_ylim([0-0.05*iac.max(), iac.max()+0.05*iac.max()])\r\n                # fig_iac.legend()\r\n                \r\n            \r\n\r\n            \r\n            if do_trace_plot:\r\n                \r\n                chain_logl = result_[\"chain.logl\"]\r\n                bool_ = chain_logl<-5e+9\r\n                chain_logl[bool_] = np.nan\r\n                chain_logl[np.isnan(chain_logl)] = np.nanmin(chain_logl)\r\n\r\n                for nt in reversed(range(ntemps)):\r\n                    for nw in range(nwalkers):\r\n                        x = result_[\"chain.x\"][:, nt, nw, :]\r\n                        T = result_[\"chain.T\"][:, nt]\r\n                        beta = result_[\"chain.betas\"][:, nt]\r\n                        logl = chain_logl[:, nt, nw]\r\n                        # alpha = (max_alpha-min_alpha)*(logl-logl_min)/(logl_max-logl_min) + min_alpha\r\n                        # alpha = (max_alpha-min_alpha)*(T-vmin)/(vmax-vmin) + min_alpha\r\n                        # alpha = (max_alpha-min_alpha)*(beta-vmin)/(vmax-vmin) + min_alpha\r\n                        # Trace plots\r\n                        \r\n                        \r\n                        for j, attr in enumerate(flat_attr_list_):\r\n                            row = math.floor(j/ncols)\r\n                            col = int(j-ncols*row)\r\n                            # sc = axes_trace[row, col].scatter(range(x[:,j].shape[0]), x[:,j], c=T, norm=matplotlib.colors.LogNorm(vmin=vmin, vmax=vmax), s=0.3, cmap=cm_mpl, alpha=0.1)\r\n                            if ntemps>1:\r\n                                \r\n                                sc = axes_trace[row, col].scatter(range(x[:,j].shape[0]), x[:,j], c=beta, vmin=vmin, vmax=vmax, s=0.3, cmap=cm_mpl_rev, alpha=0.1)\r\n                            else:\r\n                                sc = axes_trace[row, col].scatter(range(x[:,j].shape[0]), x[:,j], s=0.3, color=cm_sb[0], alpha=0.1)\r\n                                \r\n                            axes_trace[row, col].axvline(burnin, color=\"black\", linewidth=1, alpha=0.8)#, linestyle=\"--\")\r\n\r\n                            # if plotted==False:\r\n                            #     axes_trace[row, col].text(x_left+dx/2, 0.44, 'Burnin', ha='center', va='center', rotation='horizontal', fontsize=15, transform=axes_trace[row, col].transAxes)\r\n                            #     axes_trace[row, col].arrow(x_right, 0.5, -dx, 0, head_width=0.1, head_length=0.05, color=\"black\", transform=axes_trace[row, col].transAxes)\r\n                            #     axes_trace[row, col].arrow(x_left, 0.5, dx, 0, head_width=0.1, head_length=0.05, color=\"black\", transform=axes_trace[row, col].transAxes)\r\n                            #     axes_trace[row, col].set_ylabel(attr, fontsize=20)\r\n                            #     plotted = True\r\n\r\n\r\n\r\n                x_left = 0.1\r\n                x_mid_left = 0.515\r\n                x_right = 0.9\r\n                x_mid_right = 0.58\r\n                dx_left = x_mid_left-x_left\r\n                dx_right = x_right-x_mid_right\r\n\r\n                fontsize = 12\r\n                for j, attr in enumerate(flat_attr_list_):\r\n                    row = math.floor(j/ncols)\r\n                    col = int(j-ncols*row)\r\n                    axes_trace[row, col].axvline(burnin, color=\"black\", linestyle=\":\", linewidth=1.5, alpha=0.5)\r\n                    y = np.array([-np.inf, np.inf])\r\n                    x1 = -burnin\r\n                    x2 = burnin\r\n                    axes_trace[row, col].fill_betweenx(y, x1, x2=0)\r\n                    axes_trace[row, col].text(x_left+dx_left/2, 0.44, 'Burn-in', ha='center', va='center', rotation='horizontal', fontsize=fontsize, transform=axes_trace[row, col].transAxes)\r\n                    # axes_trace[row, col].arrow(x_mid_left, 0.5, -dx_left, 0, head_width=0.1, head_length=0.05, color=\"black\", transform=axes_trace[row, col].transAxes)\r\n                    # axes_trace[row, col].arrow(x_left, 0.5, dx_left, 0, head_width=0.1, head_length=0.05, color=\"black\", transform=axes_trace[row, col].transAxes)\r\n\r\n                    axes_trace[row, col].text(x_mid_right+dx_right/2, 0.44, 'Posterior', ha='center', va='center', rotation='horizontal', fontsize=fontsize, transform=axes_trace[row, col].transAxes)\r\n                    # axes_trace[row, col].arrow(x_right, 0.5, -dx_right, 0, head_width=0.1, head_length=0.05, color=\"black\", transform=axes_trace[row, col].transAxes)\r\n                    # axes_trace[row, col].arrow(x_mid_right, 0.5, dx_right, 0, head_width=0.1, head_length=0.05, color=\"black\", transform=axes_trace[row, col].transAxes)\r\n                    axes_trace[row, col].set_ylabel(attr, fontsize=20)\r\n                    axes_trace[row, col].ticklabel_format(style='plain', useOffset=False)\r\n\r\n                    # arrow = axes_trace[row, col].annotate('', \r\n                    #                                     xy =(x_left, 0.5),\r\n                    #                                     xytext =(x_mid_left, 0.5), \r\n                    #                                     arrowprops = dict(\r\n                    #                                         arrowstyle=\"|-|,widthA=0.7, widthB=0.7\"\r\n                    #                                     ))\r\n                    \r\n                    # arrow = axes_trace[row, col].annotate('', \r\n                    #                                     xy =(x_mid_right, 0.5),\r\n                    #                                     xytext =(x_right, 0.5), \r\n                    #                                     arrowprops = dict(\r\n                    #                                         arrowstyle=\"|-|,widthA=0.7, widthB=0.7\"\r\n                    #                                     ))\r\n                                                    \r\n                # fig_trace.legend(labels, loc='lower right', bbox_to_anchor=(1,-0.1), ncol=len(labels))#, bbox_transform=fig.transFigure)\r\n                if ntemps>1:\r\n                    cb = fig_trace_beta.colorbar(sc, ax=axes_trace)\r\n                    cb.set_label(label=r\"$T$\", size=30)#, weight='bold')\r\n                    cb.solids.set(alpha=1)\r\n                    # fig_trace_beta.tight_layout()\r\n                    dist = (vmax-vmin)/(ntemps)/2\r\n                    tick_start = vmin+dist\r\n                    tick_end = vmax-dist\r\n                    tick_locs = np.linspace(tick_start, tick_end, ntemps)[::-1]\r\n                    cb.set_ticks(tick_locs)\r\n                    labels = list(result_[\"chain.T\"][0,:])\r\n                    inf_label = r\"$\\infty$\"\r\n                    labels[-1] = inf_label\r\n                    ticklabels = [str(round(float(label), 1)) if isinstance(label, str)==False else label for label in labels] #round(x, 2)\r\n                    cb.set_ticklabels(ticklabels, size=12)\r\n\r\n                    for tick in cb.ax.get_yticklabels():\r\n                        tick.set_fontsize(12)\r\n                        txt = tick.get_text()\r\n                        if txt==inf_label:\r\n                            tick.set_fontsize(20)\r\n                            # tick.set_text()\r\n                            # tick.set_ha(\"center\")\r\n                            # tick.set_va(\"center_baseline\")\r\n                if ii==0:\r\n                    fig_trace_beta.savefig(r'C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\LBNL_trace_plot.png', dpi=300)\r\n\r\n            if do_swap_plot and ntemps>1:\r\n                fig_swap, ax_swap = plt.subplots(layout='compressed')\r\n                fig_swap.set_size_inches((17, 12))\r\n                fig_swap.suptitle(\"Swaps\", fontsize=20)\r\n                n = ntemps-1\r\n                for i in range(n):\r\n                    if i==0: #######################################################################\r\n                        ax_swap.plot(range(result_[\"chain.swaps_accepted\"][:,i].shape[0]), result_[\"chain.swaps_accepted\"][:,i]/result_[\"chain.swaps_proposed\"][:,i], color=cm_sb[i])\r\n\r\n\r\n\r\n\r\n            if do_corner_plot:\r\n                # fig_corner, axes_corner = plt.subplots(nrows=ndim, ncols=ndim, layout='compressed')\r\n                \r\n                parameter_chain = result_[\"chain.x\"][burnin:,0,:,:]\r\n                parameter_chain = parameter_chain.reshape(parameter_chain.shape[0]*parameter_chain.shape[1],parameter_chain.shape[2])\r\n                fig_corner = corner.corner(parameter_chain, fig=None, labels=flat_attr_list_, labelpad=-0.2, show_titles=True, color=cm_sb[0], plot_contours=True, bins=15, hist_bin_factor=5, max_n_ticks=3, quantiles=[0.16, 0.5, 0.84], title_kwargs={\"fontsize\": 10, \"ha\": \"left\", \"position\": (0.03, 1.01)})\r\n                fig_corner.set_size_inches((12, 12))\r\n                pad = 0.025\r\n                fig_corner.subplots_adjust(left=pad, bottom=pad, right=1-pad, top=1-pad, wspace=0.08, hspace=0.08)\r\n                axes = fig_corner.get_axes()\r\n                for ax in axes:\r\n                    ax.set_xticks([], minor=True)\r\n                    ax.set_xticks([])\r\n                    ax.set_yticks([], minor=True)\r\n                    ax.set_yticks([])\r\n\r\n                    ax.xaxis.set_ticklabels([])\r\n                    ax.yaxis.set_ticklabels([])\r\n\r\n                median = np.median(parameter_chain, axis=0)\r\n                corner.overplot_lines(fig_corner, median, color=red, linewidth=0.5)\r\n                corner.overplot_points(fig_corner, median.reshape(1,median.shape[0]), marker=\"s\", color=red)\r\n                if ii==0:\r\n                    fig_corner.savefig(r'C:\\Users\\jabj\\OneDrive - Syddansk Universitet\\PhD_Project_Jakob\\Twin4build\\LBNL_corner_plot.png', dpi=300)\r\n        # color = cm(1)\r\n        # fig_trace_loglike, axes_trace_loglike = plt.subplots(nrows=1, ncols=1)\r\n        # fig_trace_loglike.set_size_inches((17, 12))\r\n        # fig_trace_loglike.suptitle(\"Trace plots of log likelihoods\")\r\n        # vmin = np.nanmin(-chain_logl)\r\n        # vmax = np.nanmax(-chain_logl)\r\n        # for nt in range(1):\r\n        #     for nw in range(nwalkers):\r\n        #         logl = chain_logl[:, nt, nw]\r\n        #         axes_trace_loglike.scatter(range(logl.shape[0]), -logl, color=color, s=4, alpha=0.8)\r\n        # axes_trace_loglike.set_yscale(\"log\")\r\n        # plt.show()\r\n        \r\n    plt.show()\r\n\r\n\r\nif __name__==\"__main__\":\r\n    test_load_emcee_chain()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/twin4build/estimator/tests/test_load_emcee_chain.py b/twin4build/estimator/tests/test_load_emcee_chain.py
--- a/twin4build/estimator/tests/test_load_emcee_chain.py	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ b/twin4build/estimator/tests/test_load_emcee_chain.py	(date 1717757387110)
@@ -21,6 +21,7 @@
 from twin4build.model.model import Model
 from twin4build.model.tests.test_LBNL_bypass_coil_model import fcn
 import twin4build.utils.plot.plot as plot
+from test_plot_emcee_chain import plot_jump_plot, plot_logl_plot, plot_iac_plot, plot_trace_plot, plot_swap_plot, plot_corner_plot
 
 def test_load_emcee_chain():
     # flat_attr_list = ["m1_flow_nominal", "m2_flow_nominal", "tau1", "tau2", "tau_m", "nominalUa.hasValue", "workingPressure.hasValue", "flowCoefficient.hasValue", "waterFlowRateMax", "c1", "c2", "c3", "c4", "eps_motor", "f_motorToAir", "kp", "Ti", "Td"]
@@ -51,7 +52,7 @@
     sky_blue = colors[9]
     plot.load_params()
 
-    do_analysis_plots = False #############################################
+    do_analysis_plots = True #############################################
     assume_uncorrelated_noise = False
 
     if do_analysis_plots:
@@ -246,10 +247,12 @@
     ############################################### Udskiftes
     loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240411_205028.pickle") #uniform a=5, 1-day, err=0.1 ###########################################
 ############################################################################################################
-    
+    loaddir = os.path.join(r"D:\Twin4Build\RemoteResults\chain_logs\20240602_083640.pickle") # Initial run
+
 
 
 
+
     with open(loaddir, 'rb') as handle:
         result = pickle.load(handle)
 
@@ -259,9 +262,7 @@
     # with open(loaddir, 'wb') as handle:
     #     pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)
 
-    
 
-
     result["chain.T"] = 1/result["chain.betas"] ##################################
     
     burnin = 2000#int(result["chain.x"].shape[0])-3000 #100
@@ -274,6 +275,8 @@
     vmin = np.min(result["chain.betas"])
     vmax = np.max(result["chain.betas"])
 
+
+
     print(result["chain.x"].shape)
 
 
@@ -316,6 +319,7 @@
     model.load_model(infer_connections=False, fcn=fcn)
     simulator = Simulator(model)
 
+
     startTime_test1 = datetime.datetime(year=2022, month=2, day=6, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
     endTime_test1 = datetime.datetime(year=2022, month=2, day=6, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
     startTime_test2 = datetime.datetime(year=2022, month=2, day=7, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
@@ -434,8 +438,27 @@
 
         # with open(loaddir, 'wb') as handle:
         #     pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)
-                    
+
+        print("model_load_chain_log")
 
+
+        print(model.load_chain_log(loaddir))
+        print(model.chain_log["chain.x"].shape)
+
+        # Works:
+        #plot_jump_plot(model)
+
+        # Works:
+        plot_logl_plot(model)
+
+        # Works:
+        #plot_trace_plot(model)
+
+        # Works:
+        #plot_swap_plot(model)
+
+        #plot_corner_plot(model)
+
     if do_inference:
         model.load_chain_log(loaddir)
 
@@ -499,24 +522,20 @@
         
         # axes[3].plot(simulator.dateTimeSteps, model.component_dict["Supply air temperature setpoint"].savedOutput["scheduleValue"], color="blue", label="setpoint", linewidth=0.5)
         # axes[3].plot(simulator.dateTimeSteps, model.component_dict["fan inlet air temperature sensor"].get_physical_readings(startTime, endTime, stepSize)[0:-1], color="green", label="inlet air", linewidth=0.5)
-        fig.savefig(r'C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\LBNL_inference_plot.png', dpi=300)
+        fig.savefig(r'C:\Users\AUTH\Desktop\Python_Projects\Twin4Build\twin4build\estimator\tests\generated_files\LBNL_inference_plot.png', dpi=300)
         # ax.plot(simulator.dateTimeSteps, simulator.model.component_dict[])
 
-
-    
-
     if do_inference==False:
         assert len(flat_attr_list) == ndim, f"Number of parameters in flat_attr_list ({len(flat_attr_list)}) does not match number of parameters in chain.x ({ndim})"
         
         plt.rcParams['mathtext.fontset'] = 'cm'
 
-
-
         if assume_uncorrelated_noise==False:
             attr_list_model = flat_attr_list[:-n_par]
             attr_list_noise = flat_attr_list[-n_par:]
             flat_attr_list__ = [attr_list_model, attr_list_noise]
             list_ = ["chain.x"]
+            print(list_)
             result_model = result.copy()
             result_noise = result.copy()
             for key in list_:
@@ -542,6 +561,7 @@
             for i in range(ntemps):
                 if i==0: #######################################################################
                     ax_jump.plot(range(n_it), result["chain.jump_acceptance"][:,i], color=cm_sb[i])
+                    print("ax_jump_plot type:" + str(type(ax_jump)))
         if do_logl_plot:
             fig_logl, ax_logl = plt.subplots(layout='compressed')
             fig_logl.set_size_inches((17/4, 12/4))
@@ -570,6 +590,10 @@
             nrows = math.ceil(nparam/ncols)
             print(nparam, ncols, nrows)
 
+            print("result_")
+
+            print(result_)
+
 
             ndim = result_["chain.x"].shape[3]
             ntemps = result_["chain.x"].shape[1]
@@ -604,8 +628,8 @@
 
             # vmin = np.min(result["chain.T"])
             # vmax = np.max(result["chain.T"])
-            
-            
+
+
 
 
 
@@ -620,7 +644,9 @@
                 # fig_iac.set_size_inches((17, 12))
                 # fig_iac.suptitle("Integrated AutoCorrelated Time", fontsize=20)
                 iac = result_["integratedAutoCorrelatedTime"][:-1]
+
                 n_it = iac.shape[0]
+
                 for i in range(ntemps):
                     beta = result_["chain.betas"][:, i]
                     for j, attr in enumerate(flat_attr_list_):
@@ -750,7 +776,7 @@
                             # tick.set_ha("center")
                             # tick.set_va("center_baseline")
                 if ii==0:
-                    fig_trace_beta.savefig(r'C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\LBNL_trace_plot.png', dpi=300)
+                    fig_trace_beta.savefig(r'C:\Users\AUTH\Desktop\Python_Projects\Twin4Build\twin4build\estimator\tests\generated_files\LBNL_trace_plot.png', dpi=300)
 
             if do_swap_plot and ntemps>1:
                 fig_swap, ax_swap = plt.subplots(layout='compressed')
@@ -787,7 +813,7 @@
                 corner.overplot_lines(fig_corner, median, color=red, linewidth=0.5)
                 corner.overplot_points(fig_corner, median.reshape(1,median.shape[0]), marker="s", color=red)
                 if ii==0:
-                    fig_corner.savefig(r'C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\LBNL_corner_plot.png', dpi=300)
+                    fig_corner.savefig(r'C:\Users\AUTH\Desktop\Python_Projects\Twin4Build\twin4build\estimator\tests\generated_files\LBNL_corner_plot.png', dpi=300)
         # color = cm(1)
         # fig_trace_loglike, axes_trace_loglike = plt.subplots(nrows=1, ncols=1)
         # fig_trace_loglike.set_size_inches((17, 12))
Index: twin4build/model/tests/test_LBNL_bypass_coil_model.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os\r\nimport sys\r\nimport datetime\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport seaborn as sns\r\nimport unittest\r\nfrom dateutil import tz\r\n###Only for testing before distributing package\r\nif __name__ == '__main__':\r\n    uppath = lambda _path,n: os.sep.join(_path.split(os.sep)[:-n])\r\n    file_path = uppath(os.path.abspath(__file__), 4)\r\n    print(file_path)\r\n    sys.path.append(file_path)\r\n\r\nimport twin4build as tb\r\nfrom twin4build.saref.measurement.measurement import Measurement\r\nfrom twin4build.saref.property_value.property_value import PropertyValue\r\nfrom twin4build.utils.plot.plot import get_fig_axes, load_params\r\nfrom twin4build.model.model import Model\r\nfrom twin4build.simulator.simulator import Simulator\r\nfrom twin4build.monitor.monitor import Monitor\r\nfrom twin4build.utils.piecewise_linear_schedule import PiecewiseLinearScheduleSystem\r\nfrom twin4build.saref.device.meter.meter_system import MeterSystem\r\nfrom twin4build.saref.property_.power.power import Power\r\nfrom twin4build.saref.property_.flow.flow import Flow\r\nfrom twin4build.saref.property_.opening_position.opening_position import OpeningPosition\r\nfrom twin4build.saref.property_.temperature.temperature import Temperature\r\nfrom twin4build.saref.device.sensor.sensor_system import SensorSystem\r\nfrom twin4build.utils.on_off_system import OnOffSystem\r\nimport twin4build.components as components\r\nfrom twin4build.utils.uppath import uppath\r\nimport twin4build.utils.plot.plot as plot\r\nimport pandas as pd\r\n\r\n \r\ndef fcn(self):\r\n    # filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 1)), \"fan_airflow.csv\")\r\n    filename = \"fan_airflow.csv\"\r\n    fan_airflow_property = Flow()\r\n    fan_airflow_meter = components.MeterSystem(\r\n                    observes=fan_airflow_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    id=\"fan airflow meter\")\r\n\r\n    filename = \"supply_fan_power.csv\"\r\n    fan_power_property = Power()\r\n    fan_power_meter = components.MeterSystem(\r\n                    observes=fan_power_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    doUncertaintyAnalysis=False,\r\n                    id=\"fan power meter\")\r\n    \r\n    filename = \"fan_inlet_air_temperature.csv\"\r\n    fan_inlet_air_temperature_property = Temperature()\r\n    fan_inlet_air_temperature_sensor = components.SensorSystem(\r\n                    observes=fan_inlet_air_temperature_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    id=\"fan inlet air temperature sensor\")\r\n    \r\n    filename = \"coil_outlet_air_temperature.csv\"\r\n    coil_outlet_air_temperature_property = Temperature()\r\n    coil_outlet_air_temperature_sensor = components.SensorSystem(\r\n                    observes=coil_outlet_air_temperature_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    doUncertaintyAnalysis=False,\r\n                    id=\"coil outlet air temperature sensor\")\r\n    \r\n    filename = \"coil_outlet_water_temperature.csv\"\r\n    coil_outlet_water_temperature_property = Temperature()\r\n    coil_outlet_water_temperature_sensor = components.SensorSystem(\r\n                    observes=coil_outlet_water_temperature_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    doUncertaintyAnalysis=False,\r\n                    id=\"coil outlet water temperature sensor\")\r\n                    \r\n    filename = \"coil_inlet_water_temperature.csv\"\r\n    coil_inlet_water_temperature_property = Temperature()\r\n    coil_inlet_water_temperature_sensor = components.SensorSystem(\r\n                    observes=coil_inlet_water_temperature_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    id=\"coil inlet water temperature sensor\")\r\n\r\n    filename = \"coil_valve_position.csv\"\r\n    coil_valve_position_property = OpeningPosition()\r\n    coil_valve_position_sensor = components.SensorSystem(\r\n                    observes=coil_valve_position_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    doUncertaintyAnalysis=False,\r\n                    id=\"valve position sensor\")\r\n\r\n    filename = \"supply_water_temperature_setpoint.csv\"\r\n    # filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 1)), \"coil_supply_water_temperature_energykey.csv\")\r\n    supply_water_temperature_property = Temperature()\r\n    supply_water_temperature_sensor = components.SensorSystem(\r\n                    observes=supply_water_temperature_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    id=\"supply water temperature sensor\")\r\n    \r\n    filename = \"supply_air_temperature_setpoint.csv\"\r\n    # filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 1)), \"coil_supply_water_temperature_energykey.csv\")\r\n    supply_air_temperature_property = Temperature()\r\n    supply_air_temperature_setpoint = components.SensorSystem(\r\n                    observes=supply_air_temperature_property,\r\n                    filename=filename,\r\n                    saveSimulationResult = True,\r\n                    id=\"supply air temperature setpoint\")\r\n    \r\n    # supply_water_temperature_schedule = supply_air_temperature_setpoint_schedule = tb.ScheduleSystem(\r\n    #         weekDayRulesetDict = {\r\n    #             \"ruleset_default_value\": 45,\r\n    #             \"ruleset_start_minute\": [],\r\n    #             \"ruleset_end_minute\": [],\r\n    #             \"ruleset_start_hour\": [],\r\n    #             \"ruleset_end_hour\": [],\r\n    #             \"ruleset_value\": []},\r\n    #         saveSimulationResult = True,\r\n    #         id = \"supply water temperature schedule\")\r\n    \r\n\r\n    # filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 1)), \"return_airflow_temperature.csv\")\r\n    # return_airflow_temperature_property = Temperature()\r\n    # return_airflow_temperature_sensor = SensorSystem(\r\n    #                                 observes=return_airflow_temperature_property,\r\n    #                                 filename=filename,\r\n    #                                 saveSimulationResult = True,\r\n    #                                 doUncertaintyAnalysis=False,\r\n    #                                 id=\"return airflow temperature sensor\")\r\n    \r\n    coil = components.CoilPumpValveFMUSystem(\r\n                    airFlowRateMax=None,\r\n                    airFlowRateMin=None,\r\n                    nominalLatentCapacity=None,\r\n                    nominalSensibleCapacity=PropertyValue(hasValue=96000),\r\n                    nominalUa=PropertyValue(hasValue=1000),\r\n                    flowCoefficient=PropertyValue(hasValue=8.7),\r\n                    dp1_nominal=1500,\r\n                    dpSystem=0,\r\n                    tau_w_inlet=1,\r\n                    tau_w_outlet=1,\r\n                    tau_air_outlet=1,\r\n                    operationTemperatureMax=None,\r\n                    operationTemperatureMin=None,\r\n                    placementType=None,\r\n                    operationMode=None,\r\n                    saveSimulationResult = True,\r\n                    doUncertaintyAnalysis=False,\r\n                    id=\"coil_pump_valve\")\r\n\r\n    fan = components.FanFMUSystem(capacityControlType = None,\r\n                    motorDriveType = None,\r\n                    nominalAirFlowRate = PropertyValue(hasValue=11.55583), #11.55583\r\n                    nominalPowerRate = PropertyValue(hasValue=8000), #8000\r\n                    nominalRotationSpeed = None,\r\n                    nominalStaticPressure = None,\r\n                    nominalTotalPressure = PropertyValue(hasValue=557),\r\n                    operationTemperatureMax = None,\r\n                    operationTemperatureMin = None,\r\n                    operationalRiterial = None,\r\n                    operationMode = None,\r\n                    hasProperty = [fan_power_property, fan_airflow_property],\r\n                    saveSimulationResult=True,\r\n                    doUncertaintyAnalysis=False,\r\n                    id=\"fan\")\r\n    \r\n    controller = components.FMUPIDControllerSystem(subSystemOf = None,\r\n                                isContainedIn = None,\r\n                                observes = coil_outlet_air_temperature_property,\r\n                                saveSimulationResult=True,\r\n                                doUncertaintyAnalysis=False,\r\n                                id=\"controller\")\r\n    \r\n    # supply_air_temperature_setpoint_schedule = PiecewiseLinearScheduleSystem(\r\n    #         weekDayRulesetDict = {\r\n    #             \"ruleset_default_value\": {\"X\": [20, 22.5],\r\n    #                                       \"Y\": [23, 20.5]},\r\n    #             \"ruleset_start_minute\": [],\r\n    #             \"ruleset_end_minute\": [],\r\n    #             \"ruleset_start_hour\": [],\r\n    #             \"ruleset_end_hour\": [],\r\n    #             \"ruleset_value\": []},\r\n    #         saveSimulationResult = True,\r\n    #         id = \"Supply air temperature setpoint\")\r\n    \r\n    # supply_air_temperature_setpoint_schedule = tb.ScheduleSystem(\r\n    #         weekDayRulesetDict = {\r\n    #             \"ruleset_default_value\": 21,\r\n    #             \"ruleset_start_minute\": [],\r\n    #             \"ruleset_end_minute\": [],\r\n    #             \"ruleset_start_hour\": [],\r\n    #             \"ruleset_end_hour\": [],\r\n    #             \"ruleset_value\": []},\r\n    #         saveSimulationResult = True,\r\n    #         id = \"Supply air temperature setpoint\")\r\n    \r\n    # on_off = OnOffSystem(threshold=0.01,\r\n    #                      is_off_value=0,\r\n    #                      saveSimulationResult = True,\r\n    #                     id = \"On-off switch\")\r\n\r\n\r\n    coil_outlet_air_temperature_property.isPropertyOf = coil\r\n    coil_valve_position_property.isPropertyOf = coil\r\n\r\n\r\n\r\n    \r\n    self.add_connection(coil_outlet_air_temperature_sensor, controller, \"outletAirTemperature\", \"actualValue\")\r\n    # self.add_connection(return_airflow_temperature_sensor, supply_air_temperature_setpoint_schedule, \"returnAirTemperature\", \"returnAirTemperature\")\r\n    self.add_connection(controller, coil, \"inputSignal\", \"valvePosition\")\r\n    # self.add_connection(fan_airflow_meter, on_off, \"airFlowRate\", \"criteriaValue\")\r\n    # self.add_connection(supply_air_temperature_setpoint_schedule, on_off, \"scheduleValue\", \"value\")\r\n    # self.add_connection(supply_air_temperature_setpoint_schedule, on_off, \"scheduleValue\", \"value\")\r\n    self.add_connection(supply_air_temperature_setpoint, controller, \"supplyAirTemperatureSetpoint\", \"setpointValue\")\r\n    # self.add_connection(coil, coil_valve_position_sensor, \"valvePosition\", \"valvePosition\")\r\n    self.add_connection(controller, coil_valve_position_sensor, \"inputSignal\", \"valvePosition\")\r\n    self.add_connection(coil, coil_outlet_water_temperature_sensor, \"outletWaterTemperature\", \"outletWaterTemperature\")\r\n    self.add_connection(fan_inlet_air_temperature_sensor, fan, \"inletAirTemperature\", \"inletAirTemperature\")\r\n    self.add_connection(fan_airflow_meter, fan, \"airFlowRate\", \"airFlowRate\")\r\n    self.add_connection(coil, coil_outlet_air_temperature_sensor, \"outletAirTemperature\", \"outletAirTemperature\")\r\n    self.add_connection(coil, coil_inlet_water_temperature_sensor, \"inletWaterTemperature\", \"inletWaterTemperature\")\r\n    self.add_connection(supply_water_temperature_sensor, coil, \"supplyWaterTemperature\", \"supplyWaterTemperature\")\r\n    # self.add_connection(supply_water_temperature_schedule, coil, \"scheduleValue\", \"supplyWaterTemperature\")\r\n    self.add_connection(fan_airflow_meter, coil, \"airFlowRate\", \"airFlowRate\")\r\n    self.add_connection(fan, coil, \"outletAirTemperature\", \"inletAirTemperature\")\r\n    self.add_connection(fan, fan_power_meter, \"Power\", \"Power\")\r\n\r\ndef export_csv(simulator):\r\n    model = simulator.model\r\n    df_input = pd.DataFrame()\r\n    df_output = pd.DataFrame()\r\n    df_input.insert(0, \"time\", simulator.dateTimeSteps)\r\n    df_output.insert(0, \"time\", simulator.dateTimeSteps)\r\n\r\n    for component in model.get_component_by_class(model.component_dict, components.SensorSystem):\r\n        if component.isPhysicalSystem:\r\n            df = component.physicalSystem.df\r\n            print(component.savedInput.keys())\r\n            print(list(component.savedInput.keys())[0])\r\n            df.iloc[:,0] = component.savedInput[list(component.savedInput.keys())[0]]\r\n            name = component.filename.replace(\".csv\", \"_test_synthetic.csv\")\r\n            df.set_index(\"time\").to_csv(name)\r\n    \r\n    for component in model.get_component_by_class(model.component_dict, components.MeterSystem):\r\n        if component.isPhysicalSystem:\r\n            df = component.physicalSystem.df\r\n            df.iloc[:,0] = simulator.dateTimeSteps\r\n            df.iloc[:,1] = component.savedInput[list(component.savedInput.keys())[0]]\r\n            df.set_index(\"time\").to_csv(\"test_\"+component.filename)\r\n\r\n@unittest.skipIf(False, 'Currently not used')\r\ndef test_LBNL_bypass_coil_model():\r\n    colors = sns.color_palette(\"deep\")\r\n    blue = colors[0]\r\n    orange = colors[1]\r\n    green = colors[2]\r\n    red = colors[3]\r\n    purple = colors[4]\r\n    brown = colors[5]\r\n    pink = colors[6]\r\n    grey = colors[7]\r\n    beis = colors[8]\r\n    sky_blue = colors[9]\r\n    load_params()\r\n\r\n\r\n    stepSize = 60\r\n    startTime = datetime.datetime(year=2022, month=2, day=1, hour=0, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\")) \r\n    endTime = datetime.datetime(year=2022, month=2, day=2, hour=0, minute=0, second=0, tzinfo=tz.gettz(\"Europe/Copenhagen\"))\r\n\r\n    model = Model(id=\"test_LBNL_bypass_coil_model\", saveSimulationResult=True)\r\n    model.load_model(infer_connections=False, fcn=fcn)\r\n\r\n\r\n    \r\n\r\n    ################################ SET PARAMETERS #################################\r\n    coil = model.component_dict[\"coil_pump_valve\"]\r\n    # valve = model.component_dict[\"valve\"]\r\n    fan = model.component_dict[\"fan\"]\r\n    controller = model.component_dict[\"controller\"]\r\n\r\n    x0 = {coil: [1.5, 10, 15, 15, 15, 2000, 1, 1, 5000, 2000, 25000, 25000, 1, 1, 1],\r\n            fan: [0.08, -0.05, 1.31, -0.55, 0.89],\r\n            controller: [1, 0.1, 0.1]}\r\n    targetParameters = {\r\n                    coil: [\"m1_flow_nominal\", \"m2_flow_nominal\", \"tau1\", \"tau2\", \"tau_m\", \"nominalUa.hasValue\", \"mFlowValve_nominal\", \"mFlowPump_nominal\", \"dpCheckValve_nominal\", \"dp1_nominal\", \"dpPump\", \"dpSystem\", \"tau_w_inlet\", \"tau_w_outlet\", \"tau_air_outlet\"],\r\n                    fan: [\"c1\", \"c2\", \"c3\", \"c4\", \"f_total\"],\r\n                    controller: [\"kp\", \"Ti\", \"Td\"]}\r\n    \r\n\r\n    theta = np.array([val for lst in x0.values() for val in lst])\r\n    flat_component_list = [obj for obj, attr_list in targetParameters.items() for i in range(len(attr_list))]\r\n    flat_attr_list = [attr for attr_list in targetParameters.values() for attr in attr_list]\r\n    model.set_parameters_from_array(theta, flat_component_list, flat_attr_list)\r\n    #################################################################\r\n    simulator = Simulator(model=model)\r\n    simulator.simulate(model=model,\r\n                    startTime=startTime,\r\n                    endTime=endTime,\r\n                    stepSize=stepSize)\r\n    \r\n    # export_csv(simulator)\r\n    # aa\r\n    \r\n\r\n    monitor = Monitor(model=model)\r\n    monitor.monitor(startTime=startTime,\r\n                    endTime=endTime,\r\n                    stepSize=stepSize,\r\n                    show=True)\r\n    \r\n    print(monitor.get_MSE())\r\n    print(monitor.get_RMSE())\r\n\r\n    \r\n\r\n\r\n\r\n    id_list = [\"fan power meter\", \"fan power meter\", \"coil outlet air temperature sensor\", \"coil outlet water temperature sensor\"]\r\n    # id_list = [\"Space temperature sensor\", \"VE02 Primary Airflow Temperature AHR sensor\", \"VE02 Primary Airflow Temperature AHC sensor\"]\r\n\r\n    # \"VE02 Primary Airflow Temperature AHR sensor\": \"VE02_FTG_MIDDEL\",\r\n    #                      \"VE02 Primary Airflow Temperature AHC sensor\": \"VE02_FTI1\",\r\n    fig,ax = plt.subplots()\r\n    ax.plot(model.component_dict[\"fan\"].savedInput[\"inletAirTemperature\"], label=\"inletAirTemperature\")\r\n    ax.plot(model.component_dict[\"fan\"].savedOutput[\"outletAirTemperature\"], label=\"outletAirTemperature\")\r\n    ax.legend()\r\n\r\n\r\n    # facecolor = tuple(list(beis)+[0.5])\r\n    # edgecolor = tuple(list((0,0,0))+[0.5])\r\n    # for id_ in id_list:\r\n    #     fig,axes = monitor.plot_dict[id_]\r\n    #     key = list(model.component_dict[id_].inputUncertainty.keys())[0]\r\n    #     output = np.array(model.component_dict[id_].savedOutput[key])\r\n    #     outputUncertainty = np.array(model.component_dict[id_].savedOutputUncertainty[key])\r\n    #     axes[0].fill_between(monitor.simulator.dateTimeSteps, y1=output-outputUncertainty, y2=output+outputUncertainty, facecolor=facecolor, edgecolor=edgecolor, label=\"Prediction uncertainty\")\r\n    #     for ax in axes:\r\n    #         myFmt = mdates.DateFormatter('%H')\r\n    #         ax.xaxis.set_major_formatter(myFmt)\r\n    #         h, l = ax.get_legend_handles_labels()\r\n    #         n = len(l)\r\n    #         box = ax.get_position()\r\n    #         ax.set_position([0.12, box.y0, box.width, box.height])\r\n    #         ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5,1.15), prop={'size': 8}, ncol=n)\r\n    #         ax.yaxis.label.set_size(15)\r\n        # for ax in axes:\r\n        #     h, l = ax.get_legend_handles_labels()\r\n        #     n = len(l)\r\n        #     box = ax.get_position()\r\n        #     ax.set_position([0.12, box.y0, box.width, box.height])\r\n        #     ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5,1.15), prop={'size': 8}, ncol=n)\r\n        #     ax.yaxis.label.set_size(15)\r\n        #     # ax.axvline(line_date, color=monitor.colors[3])\r\n        #     ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n\r\n    monitor.save_plots()\r\n    plot.plot_fan(model, monitor.simulator, \"fan\", show=False)\r\n\r\n\r\nif __name__==\"__main__\":\r\n    test_LBNL_bypass_coil_model()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/twin4build/model/tests/test_LBNL_bypass_coil_model.py b/twin4build/model/tests/test_LBNL_bypass_coil_model.py
--- a/twin4build/model/tests/test_LBNL_bypass_coil_model.py	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ b/twin4build/model/tests/test_LBNL_bypass_coil_model.py	(date 1716288929041)
@@ -171,7 +171,7 @@
                     doUncertaintyAnalysis=False,
                     id="fan")
     
-    controller = components.FMUPIDControllerSystem(subSystemOf = None,
+    controller = components.ControllerSystem(subSystemOf = None,
                                 isContainedIn = None,
                                 observes = coil_outlet_air_temperature_property,
                                 saveSimulationResult=True,
Index: twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/air_to_air_heat_recovery/tests/test_air_to_air_heat_recovery_calibration.py
===================================================================
diff --git a/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/air_to_air_heat_recovery/tests/test_air_to_air_heat_recovery_calibration.py b/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/air_to_air_heat_recovery/tests/test_air_to_air_heat_recovery_calibration.py
deleted file mode 100644
--- a/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/air_to_air_heat_recovery/tests/test_air_to_air_heat_recovery_calibration.py	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,191 +0,0 @@
-import os
-import sys
-import datetime
-from dateutil.tz import tzutc
-import pandas as pd
-import matplotlib.pyplot as plt
-import json
-import numpy as np
-import seaborn as sns
-from matplotlib.dates import MonthLocator, DateFormatter
-from matplotlib.ticker import FuncFormatter
-###Only for testing before distributing package
-if __name__ == '__main__':
-    uppath = lambda _path,n: os.sep.join(_path.split(os.sep)[:-n])
-    #change the number here according to your requirement
-    #desired path looks like this "D:\Projects\Twin4Build
-    file_path = uppath(os.path.abspath(__file__), 11)
-    print(file_path)
-    sys.path.append(file_path)
-
-from twin4build.utils.data_loaders.load_spreadsheet import load_spreadsheet
-from twin4build.utils.preprocessing.data_collection import DataCollection
-from twin4build.utils.preprocessing.data_sampler import data_sampler
-from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.air_to_air_heat_recovery.air_to_air_heat_recovery_system import AirToAirHeatRecoverySystem
-from twin4build.saref.measurement.measurement import Measurement
-
-from twin4build.logger.Logging import Logging
-
-logger = Logging.get_logger("ai_logfile")
-logger.info("[Test Air to Air Heat Recovery Calibration]")
-logger.disabled = True
-def test():
-    '''
-         It is a self-contained block of code that performs various tasks such as loading data from files,
-        creating instances of a AirToAirHeatRecoverySystem class, and plotting graphs using the Seaborn library.
-    '''
-    air_to_air_heat_recovery = AirToAirHeatRecoverySystem(
-                specificHeatCapacityAir = Measurement(hasValue=1000),
-                eps_75_h = 0.8,
-                eps_75_c = 0.8,
-                eps_100_h = 0.8,
-                eps_100_c = 0.8,
-                primaryAirFlowRateMax = Measurement(hasValue=35000/3600*1.225),
-                secondaryAirFlowRateMax = Measurement(hasValue=35000/3600*1.225),
-                subSystemOf = [],
-                input = {},
-                output = {},
-                savedInput = {},
-                savedOutput = {},
-                saveSimulationResult = True,
-                connectedThrough = [],
-                connectsAt = [],
-                id = "AirToAirHeatRecovery")
-    
-    logger.info("Entered in Test Function")
-
-    
-    colors = sns.color_palette("deep")
-    blue = colors[0]
-    orange = colors[1]
-    green = colors[2]
-    red = colors[3]
-    purple = colors[4]
-    brown = colors[5]
-    pink = colors[6]
-    grey = colors[7]
-    beis = colors[8]
-    sky_blue = colors[9]
-
-    input = pd.DataFrame()
-
-    stepSize = 600
-    startTime = datetime.datetime(year=2021, month=10, day=1, hour=0, minute=0, second=0, tzinfo=tzutc()) 
-    endTime = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0, tzinfo=tzutc())
-    format = "%m/%d/%Y %I:%M:%S %p"
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "weather_BMS.csv")
-    weather = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    temp = weather.copy()
-    # weather["outdoorTemperature"] = (weather["outdoorTemperature"]-32)*5/9 #convert from fahrenheit to celcius
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_efficiency.csv")
-    VE02_efficiency = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_airflowrate_supply_kg_s.csv")
-    VE02_primaryAirFlowRate = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_primaryAirFlowRate["primaryAirFlowRate"] = VE02_primaryAirFlowRate["primaryAirFlowRate"]*0.0283168466/60*1.225 #convert from cubic feet per minute to kg/s
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_airflowrate_return_kg_s.csv")
-    VE02_secondaryAirFlowRate = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_secondaryAirFlowRate["secondaryAirFlowRate"] = VE02_secondaryAirFlowRate["secondaryAirFlowRate"]*0.0283168466/60*1.225 #convert from cubic feet per minute to kg/s
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_FTU1.csv")
-    VE02_FTU1 = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_FTU1["FTU1"] = (VE02_FTU1["FTU1"]-32)*5/9 #convert from fahrenheit to celcius
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_FTG_MIDDEL.csv")
-    VE02_FTG_MIDDEL = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_FTG_MIDDEL["FTG_MIDDEL"] = (VE02_FTG_MIDDEL["FTG_MIDDEL"]-32)*5/9 #convert from fahrenheit to celcius
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_FTI_KALK_SV.csv")
-    VE02_FTI_KALK_SV = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_FTI_KALK_SV["FTI_KALK_SV"] = (VE02_FTI_KALK_SV["FTI_KALK_SV"]-32)*5/9 #convert from fahrenheit to celcius
-
-    
-    
-    # primaryTemperatureIn can be calculated based on logged efficiency and temperature measurements.
-    # However, primaryTemperatureIn should also be equal to outdoor temperature, which is available.
-    # Outdoor temperature is therefore currently used. 
-    primaryTemperatureIn = (VE02_efficiency["efficiency"]/100*VE02_FTU1["FTU1"]-VE02_FTG_MIDDEL["FTG_MIDDEL"])/(VE02_efficiency["efficiency"]/100-1)
-
-
-
-
-    input.insert(0, "time", VE02_FTI_KALK_SV["Time stamp"])
-    input.insert(0, "primaryAirFlowRate", VE02_primaryAirFlowRate["primaryAirFlowRate"])
-    input.insert(0, "secondaryAirFlowRate", VE02_secondaryAirFlowRate["secondaryAirFlowRate"])
-    # input.insert(0, "primaryTemperatureIn", primaryTemperatureIn)
-    input.insert(0, "primaryTemperatureIn", weather["outdoorTemperature"])
-    input.insert(0, "secondaryTemperatureIn", VE02_FTU1["FTU1"])
-    input.insert(0, "primaryTemperatureOutSetpoint", VE02_FTI_KALK_SV["FTI_KALK_SV"])
-    input.insert(0, "primaryTemperatureOut", VE02_FTG_MIDDEL["FTG_MIDDEL"])
-
-    axes = input.iloc[20000:21000,:].drop(columns=["primaryTemperatureOutSetpoint"]).set_index("time").plot(subplots=True)
-    for a in axes:
-        a.legend(loc='best', prop={'size': 15})
-    plt.show()
-
-
-    #Remove commissioning period 
-    remove_start_date = "2022-10-23 00:00:00+00:00"
-    remove_end_date = "2022-11-06 00:00:00+00:00"
-    input[(input["time"]>=remove_start_date) & (input["time"]<remove_end_date)] = np.nan
-    #Remove scenario period
-    remove_start_date = "2022-01-03 00:00:00+00:00"
-    remove_end_date = "2022-01-17 00:00:00+00:00"
-    input[(input["time"]>=remove_start_date) & (input["time"]<remove_end_date)] = np.nan
-
-    
-
-    tol = 1e-5
-    input_plot = input.iloc[20000:21000,:].reset_index(drop=True)
-    output_plot = input_plot["primaryTemperatureOut"].to_numpy()
-
-
-
-    input.replace([np.inf, -np.inf], np.nan, inplace=True)
-    input = (input.loc[(input["primaryAirFlowRate"]>tol) | (input["secondaryAirFlowRate"]>tol)]).dropna().reset_index(drop=True) # Filter data to remove 0 airflow data
-    output = input["primaryTemperatureOut"].to_numpy()
-    input.drop(columns=["primaryTemperatureOut"])
-
-
-
-    start_pred = air_to_air_heat_recovery.do_period(input_plot) ####
-    print("Before")
-    print(f"MSE: {np.nanmean((start_pred-output_plot)**2)}")
-    fig, ax = plt.subplots()
-    ax.plot(input_plot["time"], start_pred, color=blue, label="Before calibration")
-    ax.plot(input_plot["time"], output_plot, color="black", label="Measured")
-    
-    
-    air_to_air_heat_recovery.calibrate(input=input, output=output)
-    end_pred = air_to_air_heat_recovery.do_period(input_plot)
-    print("After")
-    print(f"MSE: {np.nanmean((end_pred-output_plot)**2)}")
-
-
-    ax.plot(input_plot["time"], end_pred, color=red, linestyle="dashed", label="After calibration")
-    fig.legend(prop={'size': 15})
-    ax.set_ylim([18,22])
-
-
-    dayfmt = DateFormatter("%d")
-    monthfmt = DateFormatter("%b")
-    yearfmt = DateFormatter("%Y")
-
-    def combinedfmt(x,pos):
-        string = dayfmt(x)
-        if string == "17":
-            string += "\n" + monthfmt(x) + "\n" + yearfmt(x)
-        return string
-
-    # ax.xaxis.set_major_locator(MonthLocator((1,4,7,10)))
-    ax.xaxis.set_major_formatter(FuncFormatter(combinedfmt))
-    plt.show()
-
-    logger.info("Exited from Test Function")
-
-
-if __name__ == '__main__':
-    test()
Index: twin4build/generated_files/cached_data/.gitignore
===================================================================
diff --git a/twin4build/generated_files/cached_data/.gitignore b/twin4build/generated_files/cached_data/.gitignore
deleted file mode 100644
--- a/twin4build/generated_files/cached_data/.gitignore	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,6 +0,0 @@
-# Ignore everything
-*
-
-# But not these files...
-!__init__.py
-!.gitignore
\ No newline at end of file
Index: twin4build/generated_files/fmu/.gitignore
===================================================================
diff --git a/twin4build/generated_files/fmu/.gitignore b/twin4build/generated_files/fmu/.gitignore
deleted file mode 100644
--- a/twin4build/generated_files/fmu/.gitignore	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,6 +0,0 @@
-# Ignore everything
-*
-
-# But not these files...
-!__init__.py
-!.gitignore
\ No newline at end of file
Index: twin4build/generated_files/model_parameters/chain_logs/.gitignore
===================================================================
diff --git a/twin4build/generated_files/model_parameters/chain_logs/.gitignore b/twin4build/generated_files/model_parameters/chain_logs/.gitignore
deleted file mode 100644
--- a/twin4build/generated_files/model_parameters/chain_logs/.gitignore	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,6 +0,0 @@
-# Ignore everything
-*
-
-# But not these files...
-!__init__.py
-!.gitignore
\ No newline at end of file
Index: twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/coil/coil_DryCoilDiscretizedEthyleneGlycolWater30Percent_wbypass_FMUmodel.py
===================================================================
diff --git a/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/coil/coil_DryCoilDiscretizedEthyleneGlycolWater30Percent_wbypass_FMUmodel.py b/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/coil/coil_DryCoilDiscretizedEthyleneGlycolWater30Percent_wbypass_FMUmodel.py
deleted file mode 100644
--- a/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/coil/coil_DryCoilDiscretizedEthyleneGlycolWater30Percent_wbypass_FMUmodel.py	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,181 +0,0 @@
-from .coil import Coil
-from typing import Union
-import twin4build.saref.measurement.measurement as measurement
-from twin4build.utils.fmu.fmu_component import FMUComponent, unzip_fmu
-from twin4build.utils.constants import Constants
-from twin4build.utils.uppath import uppath
-from scipy.optimize import least_squares
-import numpy as np
-import os
-import sys
-from twin4build.saref.property_.temperature.temperature import Temperature
-from twin4build.saref.property_.flow.flow import Flow
-from twin4build.utils.fmu.unit_converters.functions import to_degC_from_degK, to_degK_from_degC, do_nothing, regularize
-from twin4build.utils.signature_pattern.signature_pattern import SignaturePattern, Node, Exact, IgnoreIntermediateNodes
-from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.coil.coil import Coil
-# import twin4build as tb
-import twin4build.base as base
-
-def get_signature_pattern():
-
-    sp = SignaturePattern(ownedBy="CoilPumpValveFMUSystem")
-
-    node0 = Node(cls=base.Meter, id="<n<SUB>1</SUB>(Meter)>")
-    node1 = Node(cls=base.Coil, id="<n<SUB>2</SUB>(Coil)>")
-    node2 = Node(cls=base.Pump, id="<n<SUB>3</SUB>(Pump)>")
-    node3 = Node(cls=base.Valve, id="<n<SUB>4</SUB>(Valve)>")
-    node4 = Node(cls=base.Valve, id="<n<SUB>5</SUB>(Valve)>")
-    node5 = Node(cls=base.OpeningPosition, id="<n<SUB>5</SUB>(OpeningPosition)>")
-    node6 = Node(cls=base.Controller, id="<n<SUB>6</SUB>(Controller)>")
-    node7 = Node(cls=base.Sensor, id="<n<SUB>7</SUB>(Sensor)>")
-    node8 = Node(cls=(base.Fan, base.AirToAirHeatRecovery, base.Coil), id="<n<SUB>8</SUB>(Fan|AirToAirHeatRecovery|Coil)>")
-    
-
-    sp.add_edge(IgnoreIntermediateNodes(object=node0, subject=node1, predicate="connectedBefore"))
-    sp.add_edge(Exact(object=node1, subject=node3, predicate="connectedBefore"))
-    sp.add_edge(Exact(object=node3, subject=node2, predicate="connectedBefore"))
-    sp.add_edge(Exact(object=node1, subject=node4, predicate="connectedBefore"))
-    sp.add_edge(Exact(object=node4, subject=node5, predicate="hasProperty"))
-    sp.add_edge(Exact(object=node6, subject=node5, predicate="controls"))
-    sp.add_edge(IgnoreIntermediateNodes(object=node2, subject=node1, predicate="connectedBefore"))
-    sp.add_edge(IgnoreIntermediateNodes(object=node7, subject=node2, predicate="connectedBefore"))
-    sp.add_edge(IgnoreIntermediateNodes(object=node8, subject=node1, predicate="connectedBefore"))
-
-    sp.add_input("airFlowRate", node0)
-    sp.add_input("inletAirTemperature", node8, ("outletAirTemperature", "primaryTemperatureOut", "outletAirTemperature"))
-    sp.add_input("supplyWaterTemperature", node7, "supplyWaterTemperature")
-    sp.add_input("valvePosition", node6, "inputSignal")
-
-    sp.add_parameter("nominalUa.hasValue", node1, "nominalUa.hasValue")
-    sp.add_parameter("flowCoefficient", node4, "flowCoefficient")
-
-    sp.add_modeled_node(node1)
-    sp.add_modeled_node(node2)
-    sp.add_modeled_node(node3)
-    sp.add_modeled_node(node4)
-
-    return sp
-
-class CoilPumpValveFMUSystem(FMUComponent, Coil, base.Valve, base.Pump):
-    sp = [get_signature_pattern()]
-    def __init__(self,
-                m1_flow_nominal=None,
-                m2_flow_nominal=None,
-                tau1=None,
-                tau2=None,
-                tau_m=None,
-                mFlowValve_nominal=None,
-                flowCoefficient=None,
-                mFlowPump_nominal=None,
-                dpCheckValve_nominal=None,
-                dp1_nominal=None,
-                dpPump=None,
-                dpValve_nominal=None,
-                dpSystem=None,
-                tau_w_inlet=None,
-                tau_w_outlet=None,
-                tau_air_outlet=None,
-                **kwargs):
-        Coil.__init__(self, **kwargs)
-        base.Valve.__init__(self, **kwargs)
-        base.Pump.__init__(self, **kwargs)
-        self.start_time = 0
-        # fmu_filename = "coil_0wbypass_0FMUmodel_new.fmu" #3 pipes
-        fmu_filename = "coil_0wbypass_0FMUmodel.fmu"
-        self.fmu_path = os.path.join(uppath(os.path.abspath(__file__), 1), fmu_filename)
-        self.unzipdir = unzip_fmu(self.fmu_path)
-
-        self.m1_flow_nominal = m1_flow_nominal
-        self.m2_flow_nominal = m2_flow_nominal
-        self.tau1 = tau1
-        self.tau2 = tau2
-        self.tau_m = tau_m
-        self.mFlowValve_nominal = mFlowValve_nominal
-        self.flowCoefficient = flowCoefficient
-        self.mFlowPump_nominal = mFlowPump_nominal
-        self.dpCheckValve_nominal = dpCheckValve_nominal
-        self.dp1_nominal = dp1_nominal
-        self.dpPump = dpPump
-        self.dpValve_nominal = dpValve_nominal
-        self.dpSystem = dpSystem
-        self.tau_w_inlet = tau_w_inlet
-        self.tau_w_outlet = tau_w_outlet
-        self.tau_air_outlet = tau_air_outlet
-
-        self.input = {"valvePosition": None,
-                      "airFlowRate": None,
-                      "supplyWaterTemperature": None,
-                      "inletAirTemperature": None}
-        
-        self.output = {"outletWaterTemperature": None, 
-                       "outletAirTemperature": None,
-                       "inletWaterTemperature": None,
-                       "valvePosition": None}
-        
-        
-        self.FMUinputMap = {"valvePosition": "u",
-                            "airFlowRate": "inlet2.m_flow",
-                            "supplyWaterTemperature": "supplyWaterTemperature",
-                            "inletAirTemperature": "inlet2.forward.T"}
-        
-        self.FMUoutputMap = {"outletWaterTemperature": "outletWaterTemperature", 
-                            "outletAirTemperature": "outletAirTemperature",
-                            "inletWaterTemperature": "inletWaterTemperature",
-                            "valvePosition": "u"}
-        
-        self.FMUparameterMap = {"m1_flow_nominal": "m1_flow_nominal",
-                                "m2_flow_nominal": "m2_flow_nominal",
-                                "tau1": "tau1",
-                                "tau2": "tau2",
-                                "tau_m": "tau_m",
-                                "nominalUa.hasValue": "UA_nominal",
-                                "mFlowValve_nominal": "mFlowValve_nominal",
-                                "flowCoefficient": "Kv",
-                                "mFlowPump_nominal": "mFlowPump_nominal",
-                                "dpCheckValve_nominal": "dpCheckValve_nominal",
-                                "dp1_nominal": "dp1_nominal",
-                                "dpPump": "dpPump",
-                                "dpSystem": "dpSystem",
-                                "tau_w_inlet": "tau_w_inlet",
-                                "tau_w_outlet": "tau_w_outlet",
-                                "tau_air_outlet": "tau_air_outlet"}
-        
-        self.input_unit_conversion = {"valvePosition": do_nothing,
-                                      "airFlowRate": regularize(0.01),
-                                      "supplyWaterTemperature": to_degK_from_degC,
-                                      "inletAirTemperature": to_degK_from_degC}
-        
-        self.output_unit_conversion = {"outletWaterTemperature": to_degC_from_degK,
-                                      "outletAirTemperature": to_degC_from_degK,
-                                      "inletWaterTemperature": to_degC_from_degK,
-                                      "valvePosition": do_nothing}
-
-        self.INITIALIZED = False
-        self._config = {"parameters": list(self.FMUparameterMap.keys())}
-
-    @property
-    def config(self):
-        return self._config
-
-    def cache(self,
-            startTime=None,
-            endTime=None,
-            stepSize=None):
-        pass
-
-    def initialize(self,
-                    startTime=None,
-                    endTime=None,
-                    stepSize=None):
-        '''
-            This function initializes the FMU component by setting the start_time and fmu_filename attributes, 
-            and then sets the parameters for the FMU model.
-        '''
-        if self.INITIALIZED:
-            self.reset()
-        else:
-            self.initialize_fmu()
-            self.INITIALIZED = True
-
-
-        
\ No newline at end of file
Index: twin4build/generated_files/plots/.gitignore
===================================================================
diff --git a/twin4build/generated_files/plots/.gitignore b/twin4build/generated_files/plots/.gitignore
deleted file mode 100644
--- a/twin4build/generated_files/plots/.gitignore	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,4 +0,0 @@
-*
-
-!__init__.py
-!.gitignore
\ No newline at end of file
Index: twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/air_to_air_heat_recovery/tests/Dynamic_air_to_air_heat_recovery_calibration.py
===================================================================
diff --git a/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/air_to_air_heat_recovery/tests/Dynamic_air_to_air_heat_recovery_calibration.py b/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/air_to_air_heat_recovery/tests/Dynamic_air_to_air_heat_recovery_calibration.py
deleted file mode 100644
--- a/twin4build/saref4bldg/physical_object/building_object/building_device/distribution_device/distribution_flow_device/energy_conversion_device/air_to_air_heat_recovery/tests/Dynamic_air_to_air_heat_recovery_calibration.py	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,202 +0,0 @@
-import os
-import sys
-import datetime
-from dateutil.tz import tzutc
-import pandas as pd
-import matplotlib.pyplot as plt
-import json
-import numpy as np
-
-###Only for testing before distributing package
-if __name__ == '__main__':
-    uppath = lambda _path,n: os.sep.join(_path.split(os.sep)[:-n])
-    #change the number here according to your requirement
-    #desired path looks like this "D:\Projects\Twin4Build
-    file_path = uppath(os.path.abspath(__file__), 11)
-    #file_path = uppath(os.path.abspath(__file__), 9)
-    sys.path.append(file_path)
-
-    calibrated_path = file_path+"/calibrated_folder"
-    if not os.path.exists(calibrated_path):
-         os.makedirs(calibrated_path)
-
-
-
-from twin4build.utils.data_loaders.load_spreadsheet import load_spreadsheet
-from twin4build.utils.preprocessing.data_collection import DataCollection
-from twin4build.utils.preprocessing.data_sampler import data_sampler
-from twin4build.saref4bldg.physical_object.building_object.building_device.distribution_device.distribution_flow_device.energy_conversion_device.air_to_air_heat_recovery.air_to_air_heat_recovery_system import AirToAirHeatRecoverySystem
-from twin4build.saref.measurement.measurement import Measurement
-#import pwlf
-
-
-from twin4build.logger.Logging import Logging
-
-logger = Logging.get_logger("ai_logfile")
-
-class dynamic_calibration_heat_recovery:
-    '''
-        initializes the class with input and output data, 
-        sets the parameters for an AirToAirHeatRecoverySystem, and calls the save_plots() method.
-    '''
-    def __init__(self,input_X,output_Y):
-        self.input_data  = input_X
-        self.output_data = output_Y
-        self.model_set_parameters()
-        #self.data_prep_method()
-        self.save_plots()
-
-        logger.info("[Dynamic Calibration Heat Recovery Class] : Entered in Initialise Function")
-
-    def model_set_parameters(self):
-        '''
-             creates an AirToAirHeatRecoverySystem object with specific parameter values.
-        '''
-        self.air_to_air_heat_recovery = AirToAirHeatRecoverySystem(
-                specificHeatCapacityAir = Measurement(hasValue=1000),
-                eps_75_h = 0.8,
-                eps_75_c = 0.8,
-                eps_100_h = 0.8,
-                eps_100_c = 0.8,
-                primaryAirFlowRateMax = Measurement(hasValue=25000/3600*1.225),
-                secondaryAirFlowRateMax = Measurement(hasValue=25000/3600*1.225),
-                subSystemOf = [],
-                input = {},
-                output = {},
-                savedInput = {},
-                savedOutput = {},
-                saveSimulationResult = True,
-                connectedThrough = [],
-                connectsAt = [],
-                id = "AirToAirHeatRecovery")
-
-    def save_plots(self):
-        # These lines are specific to this code. Please change if required
-        #input_plot = self.input_data.iloc[20000:21000,:].reset_index(drop=True)
-        #output_plot = self.input_plot["primaryTemperatureOut"].to_numpy()
-
-        logger.info("[Dynamic Calibration Heat Recovery Class] : Entered in Save Plots Function")
-
-
-        input_plot = self.input_data
-        output_plot =self.output_data
-
-        start_pred = self.air_to_air_heat_recovery.do_period(input_plot) ####
-        fig, ax = plt.subplots(2)
-        ax[0].plot(start_pred, color="black", linestyle="dashed", label="predicted")
-        ax[0].plot(output_plot, color="blue", label="Measured")
-        ax[0].set_title('Before calibration')
-        fig.legend()
-        self.input_data.set_index("time")
-        self.input_data.plot(subplots=True)
-        end_pred = self.air_to_air_heat_recovery.do_period(input_plot)
-        ax[1].plot(end_pred, color="black", linestyle="dashed", label="predicted")
-        ax[1].plot(output_plot, color="blue", label="Measured")
-        ax[1].set_title('After calibration')
-        for a in ax:
-            a.set_ylim([18,22])
-
-        plt.show()
-
-        logger.info("[Dynamic Calibration Heat Recovery Class] : Exited from Save Plots Function")
-
-
-    def calibrate_results(self):
-        return(self.air_to_air_heat_recovery.calibrate(self.input_data, self.output_data))
-
-def read_data():
-    '''
-        This is a Python function that reads data from several CSV files using a custom function 
-        "load_spreadsheet" with a defined file path, time range, and date format. 
-        The data is loaded into pandas DataFrames and then processed, including conversions
-        from imperial to metric units. Finally, the processed data is inserted into a pandas DataFrame called "input" 
-        that is returned as output from the function. The primaryTemperatureIn column of "input" is calculated as a function of other columns.
-    '''
-
-    logger.info("[Dynamic Calibration Heat Recovery Class] : Entered in Read Data Function")
-
-
-    input = pd.DataFrame()
-
-    stepSize = 600
-    startTime = datetime.datetime(year=2021, month=10, day=1, hour=0, minute=0, second=0, tzinfo=tzutc()) 
-    endTime = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0, tzinfo=tzutc())
-    format = "%m/%d/%Y %I:%M:%S %p"
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "weather_BMS.csv")
-    weather = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    temp = weather.copy()
-    # weather["outdoorTemperature"] = (weather["outdoorTemperature"]-32)*5/9 #convert from fahrenheit to celcius
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_efficiency.csv")
-    VE02_efficiency = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_airflowrate_supply_kg_s.csv")
-    VE02_primaryAirFlowRate = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_primaryAirFlowRate["primaryAirFlowRate"] = VE02_primaryAirFlowRate["primaryAirFlowRate"]*0.0283168466/60*1.225 #convert from cubic feet per minute to kg/s
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_airflowrate_return_kg_s.csv")
-    VE02_secondaryAirFlowRate = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_secondaryAirFlowRate["secondaryAirFlowRate"] = VE02_secondaryAirFlowRate["secondaryAirFlowRate"]*0.0283168466/60*1.225 #convert from cubic feet per minute to kg/s
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_FTU1.csv")
-    VE02_FTU1 = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_FTU1["FTU1"] = (VE02_FTU1["FTU1"]-32)*5/9 #convert from fahrenheit to celcius
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_FTG_MIDDEL.csv")
-    VE02_FTG_MIDDEL = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_FTG_MIDDEL["FTG_MIDDEL"] = (VE02_FTG_MIDDEL["FTG_MIDDEL"]-32)*5/9 #convert from fahrenheit to celcius
-
-    filename = os.path.join(os.path.abspath(uppath(os.path.abspath(__file__), 10)), "test", "data", "time_series_data", "VE02_FTI_KALK_SV.csv")
-    VE02_FTI_KALK_SV = load_spreadsheet(filename=filename, stepSize=stepSize, start_time=startTime, end_time=endTime, format=format, dt_limit=9999)
-    # VE02_FTI_KALK_SV["FTI_KALK_SV"] = (VE02_FTI_KALK_SV["FTI_KALK_SV"]-32)*5/9 #convert from fahrenheit to celcius
-
-    
-    
-    # primaryTemperatureIn can be calculated based on logged efficiency and temperature measurements.
-    # However, primaryTemperatureIn should also be equal to outdoor temperature, which is available.
-    # Outdoor temperature is therefore currently used. 
-    primaryTemperatureIn = (VE02_efficiency["efficiency"]/100*VE02_FTU1["FTU1"]-VE02_FTG_MIDDEL["FTG_MIDDEL"])/(VE02_efficiency["efficiency"]/100-1)
-
-
-
-
-    input.insert(0, "time", VE02_FTI_KALK_SV["Time stamp"])
-    input.insert(0, "primaryAirFlowRate", VE02_primaryAirFlowRate["primaryAirFlowRate"])
-    input.insert(0, "secondaryAirFlowRate", VE02_secondaryAirFlowRate["secondaryAirFlowRate"])
-    # input.insert(0, "primaryTemperatureIn", primaryTemperatureIn)
-    input.insert(0, "primaryTemperatureIn", weather["outdoorTemperature"])
-    input.insert(0, "secondaryTemperatureIn", VE02_FTU1["FTU1"])
-    input.insert(0, "primaryTemperatureOutSetpoint", VE02_FTI_KALK_SV["FTI_KALK_SV"])
-    input.insert(0, "primaryTemperatureOut", VE02_FTG_MIDDEL["FTG_MIDDEL"])
-
-
-    tol = 1e-5
-    
-    input.replace([np.inf, -np.inf], np.nan, inplace=True)
-    input = (input.loc[(input["primaryAirFlowRate"]>tol) | (input["secondaryAirFlowRate"]>tol)]).dropna().reset_index(drop=True) # Filter data to remove 0 airflow data
-    output = input["primaryTemperatureOut"].to_numpy()
-    input.drop(columns=["primaryTemperatureOut"])
-
-    logger.info("[Dynamic Calibration Heat Recovery Class] : Exited from Read Data Function")
-
-
-    return (input,output)
-
-if __name__ == '__main__':
-    #use id as used into id = "AirToAirHeatRecovery"
-    AirToAirHeatRecovery_units = {"AirToAirHeatRecovery_1":
-                                {"input_filename":"",
-                                "output_filename" :""
-                                },
-                            }
-    calibrated_variable_dict = {}
-
-    for AirToAirHeatRecovery_unit in AirToAirHeatRecovery_units.keys():
-        input_X,output_Y = read_data()
-        air_to_heat_recovery_cls_obj = dynamic_calibration_heat_recovery(input_X,output_Y)
-        calibrated_variable_dict[AirToAirHeatRecovery_unit] = air_to_heat_recovery_cls_obj.calibrate_results()
-
-    calibrated_full_path = calibrated_path+"/calibrated_air_to_heat_recovery_parameters.json"
-    with open(calibrated_full_path, "w") as outfile:
-        json.dump(calibrated_variable_dict, outfile)
\ No newline at end of file
Index: twin4build/utils/data_loaders/tests/test_query.json
===================================================================
diff --git a/twin4build/utils/data_loaders/tests/test_query.json b/twin4build/utils/data_loaders/tests/test_query.json
deleted file mode 100644
--- a/twin4build/utils/data_loaders/tests/test_query.json	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,4 +0,0 @@
-{
-    "ksql": "SELECT DATA FROM OU44_KNX_SENSORS WHERE LOCATION_ROOM LIKE 'Undervisning 20-601b-2' AND SENSOR_TYPE LIKE 'Tilstedevrelse log';",
-    "streamsProperties": {"ksql.query.pull.table.scan.enabled": true, "auto.offset.reset": "earliest"}
-}
\ No newline at end of file
Index: twin4build/generated_files/model_parameters/.gitignore
===================================================================
diff --git a/twin4build/generated_files/model_parameters/.gitignore b/twin4build/generated_files/model_parameters/.gitignore
deleted file mode 100644
--- a/twin4build/generated_files/model_parameters/.gitignore	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,6 +0,0 @@
-# Ignore everything
-*
-
-# But not these files...
-!.gitignore
-!chain_logs
\ No newline at end of file
Index: twin4build/generated_files/graphs/.gitignore
===================================================================
diff --git a/twin4build/generated_files/graphs/.gitignore b/twin4build/generated_files/graphs/.gitignore
deleted file mode 100644
--- a/twin4build/generated_files/graphs/.gitignore	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ /dev/null	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
@@ -1,6 +0,0 @@
-# Ignore everything
-*
-
-# But not these files...
-!__init__.py
-!.gitignore
\ No newline at end of file
Index: twin4build/estimator/tests/test_load_emcee_chain_1.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/twin4build/estimator/tests/test_load_emcee_chain_1.py b/twin4build/estimator/tests/test_load_emcee_chain_1.py
new file mode 100644
--- /dev/null	(date 1716281320381)
+++ b/twin4build/estimator/tests/test_load_emcee_chain_1.py	(date 1716281320381)
@@ -0,0 +1,831 @@
+import matplotlib.pyplot as plt
+import matplotlib
+import pickle
+import math
+import numpy as np
+import os
+import datetime
+import sys
+import corner
+import seaborn as sns
+import copy
+from dateutil import tz
+from io import StringIO
+from matplotlib.colors import LinearSegmentedColormap
+if __name__ == '__main__':
+    uppath = lambda _path,n: os.sep.join(_path.split(os.sep)[:-n])
+    file_path = uppath(os.path.abspath(__file__), 4)
+    sys.path.append(file_path)
+from twin4build.utils.uppath import uppath
+from twin4build.simulator.simulator import Simulator
+from twin4build.model.model import Model
+from twin4build.model.tests.test_LBNL_bypass_coil_model import fcn
+import twin4build.utils.plot.plot as plot
+from test_plot_emcee_chain import plot_jump_plot, plot_logl_plot, plot_iac_plot, plot_trace_plot, plot_swap_plot, plot_corner_plot
+
+def test_load_emcee_chain():
+    # flat_attr_list = ["m1_flow_nominal", "m2_flow_nominal", "tau1", "tau2", "tau_m", "nominalUa.hasValue", "workingPressure.hasValue", "flowCoefficient.hasValue", "waterFlowRateMax", "c1", "c2", "c3", "c4", "eps_motor", "f_motorToAir", "kp", "Ti", "Td"]
+    # flat_attr_list = [r"$\dot{m}_{w,nom}$", r"$\dot{m}_{a,nom}$", r"$\tau_1$", r"$\tau_2$", r"$\tau_m$", r"$UA_{nom}$", r"$\Delta P_{sys}$", r"$K_{v}$", r"$\dot{m}_{w,nom}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$\epsilon$", r"$f_{motorToAir}$", r"$K_p$", r"$T_i$", r"$T_d$"]
+    # flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\Delta P_{fixed}$", r"$\dot{m}_{v,w,nom}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{comb}$", r"$K_p$", r"$T_i$", r"$T_d$"]
+    # flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\dot{m}_{v,w,nom}$", r"$\dot{m}_{pump,w,nom}$", r"$\Delta P_{check}$", r"$\Delta P_{coil}$", r"$T_{rise}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{comb}$", r"$K_p$", r"$T_i$", r"$T_d$"]
+    # flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\dot{m}_{v,w,nom}$", r"$\dot{m}_{p,w,nom}$", r"$\Delta P_{check}$", r"$\Delta P_{coil}$", r"$\Delta P_{p,nom}$", r"$\Delta P_{v,nom}$", r"$\Delta P_{sys}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{comb}$", r"$K_p$", r"$T_i$", r"$T_d$"]
+    # flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\dot{m}_{v,w,nom}$", r"$\dot{m}_{p,w,nom}$", r"$\Delta P_{check}$", r"$\Delta P_{coil}$", r"$\Delta P_{p,nom}$", r"$\Delta P_{sys}$", r"$T_{rise}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{comb}$", r"$K_p$", r"$T_i$", r"$T_d$"]
+    # flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\dot{m}_{v,w,nom}$", r"$\dot{m}_{pump,w,nom}$", r"$\Delta P_{check}$", r"$\Delta P_{coil}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{comb}$", r"$K_p$", r"$T_i$", r"$T_d$"]
+    flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\dot{m}_{v,w,nom}$", r"$\dot{m}_{pump,w,nom}$", r"$\Delta P_{check}$", r"$\Delta P_{coil}$", r"$\Delta P_{pump}$", r"$\Delta P_{sys}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{comb}$", r"$K_p$", r"$T_i$", r"$T_d$", ]
+    flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\dot{m}_{v,w,nom}$", r"$\dot{m}_{pump,w,nom}$", r"$\Delta P_{check}$", r"$\Delta P_{coil}$", r"$\Delta P_{pump}$", r"$\Delta P_{sys}$", r"$T_{w,inlet}$", r"$T_{w,outlet}$", r"$T_{a,outlet}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{comb}$", r"$K_p$", r"$T_i$", r"$T_d$", "a1", "tau1", "a2", "tau2", "a3", "tau3", "a4", "tau4", "a5", "tau5"]
+    flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\dot{m}_{v,w,nom}$", r"$\dot{m}_{pump,w,nom}$", r"$\Delta P_{check}$", r"$\Delta P_{coil}$", r"$\Delta P_{pump}$", r"$\Delta P_{sys}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{comb}$", r"$K_p$", r"$T_i$", r"$T_d$", r"$a_1$", r"$tau_1$", r"$a_2$", r"$tau_2$", "a3", "tau3", "a4", "tau4", "a5", "tau5"]
+    flat_attr_list = [r"$\dot{m}_{c,w,nom}$", r"$\dot{m}_{c,a,nom}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$UA_{nom}$", r"$\dot{m}_{v,w,nom}$", r"$\dot{m}_{p,w,nom}$", r"$\Delta P_{cv}$", r"$\Delta P_{c}$", r"$\Delta P_{p}$", r"$\Delta P_{s}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f$", r"$K_P$", r"$T_I$", r"$T_D$"]
+    flat_attr_list = [r"$\overline{\dot{m}}_{c,w}$", r"$\overline{\dot{m}}_{c,a}$", r"$\tau_w$", r"$\tau_a$", r"$\tau_m$", r"$\overline{UA}$", r"$\overline{\dot{m}}_{v,w}$", r"$\overline{\dot{m}}_{cv,w}$", r"$K_{cv}$", r"$\Delta P_{s,res}$", r"$\overline{\Delta P}_{c}$", r"$\Delta P_{p}$", r"$\Delta P_{s}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{tot}$", r"$K_P$", r"$T_I$", r"$T_D$"]
+
+    # "KvCheckValve", "dpFixedSystem",
+
+    colors = sns.color_palette("deep")
+    blue = colors[0]
+    orange = colors[1]
+    green = colors[2]
+    red = colors[3]
+    purple = colors[4]
+    brown = colors[5]
+    pink = colors[6]
+    grey = colors[7]
+    beis = colors[8]
+    sky_blue = colors[9]
+    plot.load_params()
+
+    do_analysis_plots = True #############################################
+    assume_uncorrelated_noise = False
+
+    if do_analysis_plots:
+        do_iac_plot = True
+        do_logl_plot = True
+        do_trace_plot = True
+        do_jump_plot = True
+        do_corner_plot = True
+        do_inference = False
+    else:
+        do_iac_plot = False
+        do_logl_plot = False
+        do_trace_plot = False
+        do_jump_plot = False
+        do_corner_plot = False
+        do_inference = True
+
+    
+    do_swap_plot = False
+    
+    assert (do_iac_plot and do_inference)!=True
+
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230829_155706_chain_log.pickle")
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230830_194210_chain_log.pickle")
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230902_183719_chain_log.pickle")
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230904_171903_chain_log.pickle")
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230905_092246_chain_log.pickle")
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230907_160103_chain_log.pickle")
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230908_114136_chain_log.pickle")
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230908_233103_chain_log.pickle") #No flow dependence
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230911_113906_chain_log.pickle") #No flow dependence
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230912_120849_chain_log.pickle") #No flow dependence
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230913_093046_chain_log.pickle") #No flow dependence
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230914_164406_chain_log.pickle") #No flow dependence
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230915_091654_chain_log.pickle") #No flow dependence
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230923_164550_chain_log.pickle") #T_max=1e+5
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230923_192545_chain_log.pickle") #T_max=inf
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230923_194507_chain_log.pickle") #T_max=inf, Tau=300
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230923_234059_chain_log.pickle") #T_max=inf, 8*walkers
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230925_102035_chain_log.pickle") #Tinf_fanLimits_coilFlowDependent , 8*walkers
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230926_131018_chain_log.pickle") #10 temps , 4*walkers
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230926_225917_chain_log.pickle") #10 temps , 4*walkers
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230927_135449_chain_log.pickle") #10 temps , 4*walkers, 30tau
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230927_154822_chain_log.pickle") #1 temps , 30*walkers, 30tau
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230928_102504_chain_log.pickle") #10 temps , 4*walkers, 30tau
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230928_124040_chain_log.pickle") #15 temps , 8*walkers, 30tau
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230929_101059_chain_log.pickle") #15 temps , 8*walkers, 30tau, large water massflow         CURRENT BEST
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230930_175014_chain_log.pickle") #15 temps , 8*walkers, 200tau, large water massflow
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20230930_181209_chain_log.pickle") #15 temps , 8*walkers, 200tau, large water massflow, gaussian x0
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231001_162530_chain_log.pickle") #1 temps , 500walkers, 200tau, large water massflow
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231002_141008_chain_log.pickle") #12 temps , 8*walkers, 30tau, large water massflow
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231002_160750_chain_log.pickle") #12 temps , 8*walkers, 30tau, large water massflow
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231005_134721_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231005_215753_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, large massflow
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231009_132524_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231009_153513_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, lower UA
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231010_120630_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231011_131932_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol, valve more parameters
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231012_154701_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol, valve more parameters, lower UA
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231013_123013_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231017_074841_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, change prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231018_092240_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 2), "chain_logs", "20231018_135249_chain_log.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231205_110432_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231205_110432_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231205_164843_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231206_131318_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231206_212149_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231207_160247_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231208_160545_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231219_155600_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20231229_103204_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240102_141037_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240103_140207_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240104_094246_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240104_171830_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240105_165854_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240107_224328_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240107_224328_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240108_175437_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240109_110253_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240109_143730_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240110_093807_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240110_141839_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240110_174122_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240108_175437_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240111_114834_.pickle") #15 temps , 8*walkers, 30tau, test bypass valve, lower massflow and pressure, gaussian prior, GlycolEthanol, valve more parameters, lower UA, lower massflow, Kp
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240111_164945_.pickle") # assume_uncorrelated_noise = True, uniform prior
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240112_120101_.pickle") # assume_uncorrelated_noise = False, gaussian prior, Exp-squared
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240115_135515_.pickle") # assume_uncorrelated_noise = False, uniform prior, Exp-squared
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240116_085308_.pickle") # assume_uncorrelated_noise = False, uniform prior, Matern 3/2
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240117_164040_.pickle") # assume_uncorrelated_noise = False, gaussian model prior, uniform noise prior, Matern 3/2
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240121_111340_.pickle") # assume_uncorrelated_noise = False, uniform prior, Matern 5/2
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240122_084923_.pickle") # assume_uncorrelated_noise = False, gaussian model prior, uniform noise prior, Exp-squared
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240122_123919_.pickle") # assume_uncorrelated_noise = False, gaussian model prior, uniform noise prior, Exp-squared, 
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240125_155122_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, 
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240129_164944_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240130_121316_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240130_160539_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240131_072240_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240131_083244_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240201_110142_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240201_140753_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240202_110521_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240202_123159_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Exp-squared, ExpSine2Kernel
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240202_125602_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240202_133846_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240202_150303_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240202_160320_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240203_063309_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240203_071409_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240203_073057_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240203_083515_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240204_071648_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240204_103156_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240205_140422_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240205_160725_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240206_082238_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240206_104252_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240206_115255_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240206_132242_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240206_134422_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240206_141502_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240206_154844_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240207_084503_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240207_172222_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240208_113647_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240208_133307_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240209_083923_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240209_121135_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240209_142113_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240209_161142_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    # loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240210_085932_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(uppath(os.path.abspath(__file__), 1), "generated_files", "model_parameters", "chain_logs", "model_20240211_094648_.pickle") # assume_uncorrelated_noise = False, uniform model prior, uniform noise prior, Matern32
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "model_20240211_094648_.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240212_161904.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240213_093536.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240222_154216.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240223_075319.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240226_150659.pickle")
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240226_120030.pickle")
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240227_183054.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240227_115853.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240228_081523.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240228_223049.pickle")
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240228_155339.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240229_100544.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240229_130556.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240229_222938.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240302_010809.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240304_084842.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240304_143757.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240305_013720.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240306_082449.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240307_013709.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240306_135237.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240307_174318.pickle")
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240307_130004.pickle") #Really good no gp
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240309_021817.pickle")
+
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240308_154530.pickle")
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240307_164717.pickle")
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240313_161609.pickle")
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240314_145953.pickle")
+
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240315_033100.pickle")
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240315_055118.pickle")
+
+
+    ######
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240315_060209.pickle")
+
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240316_001905.pickle") #gaussian
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240315_200758.pickle") #uniform ###########################################
+
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240315_161324.pickle") #gaussian
+    
+
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240316_192229.pickle") #uniform
+
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240404_073632.pickle") #uniform ###########################################
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240405_004803.pickle") #uniform ###########################################
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240408_185151.pickle") #uniform a=5, good ###########################################
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240408_083352.pickle") #uniform a=5 ###########################################
+
+
+    
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240409_144236.pickle") #uniform a=5, 2-day, only model ###########################################
+    # loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240410_114906.pickle") #uniform a=5, 2-day ###########################################
+
+
+    ############################################### Udskiftes
+    loaddir = os.path.join(r"C:\Users\jabj\OneDrive - Syddansk Universitet\PhD_Project_Jakob\Twin4build\python\BuildingEnergyModel\remote_results\chain_logs\chain_logs", "20240411_205028.pickle") #uniform a=5, 1-day, err=0.1 ###########################################
+############################################################################################################
+    loaddir = os.path.join(r"C:\Users\AUTH\Downloads\20240411_205028.pickle")
+
+
+    with open(loaddir, 'rb') as handle:
+        result = pickle.load(handle)
+
+    # c = result["component_id"]
+    # c = [s.replace("+", "_") for s in c]
+    # result["component_id"] = c
+    # with open(loaddir, 'wb') as handle:
+    #     pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)
+
+
+    result["chain.T"] = 1/result["chain.betas"] ##################################
+    
+    burnin = 2000#int(result["chain.x"].shape[0])-3000 #100
+    #########################################
+    list_ = ["integratedAutoCorrelatedTime"]#, "chain.jumps_accepted", "chain.jumps_proposed", "chain.swaps_accepted", "chain.swaps_proposed"]
+    for key in list_:
+        result[key] = np.array(result[key])
+    #########################################
+
+    vmin = np.min(result["chain.betas"])
+    vmax = np.max(result["chain.betas"])
+
+
+
+    print(result["chain.x"].shape)
+
+
+    # cm = plt.get_cmap('RdYlBu', ntemps)
+    # cm_sb = sns.color_palette("vlag_r", n_colors=ntemps, center="dark") #vlag_r
+    
+#################################################################
+    # logl = result["chain.logl"]
+    # logl[np.abs(logl)>1e+9] = np.nan
+    # print(logl[:,0,:].max())
+    # indices = np.where(logl[:,0,:] == logl[:,0,:].max())
+    # s0 = indices[0][0]
+    # s1 = indices[1][0]
+    # a = result["chain.x"][s0, 0, s1, :]
+    # a = np.resize(a, (1,2,1,a.shape[0]))
+    # result["chain.x"] = a
+    # for key in result.keys():
+    #     # if key not in list_:
+    #     if isinstance(result[key], list):
+    #         result[key] = np.array(result[key])
+########################################################
+
+    ndim = result["chain.x"].shape[3]
+    ntemps = result["chain.x"].shape[1]
+    nwalkers = result["chain.x"].shape[2] #Round up to nearest even number and multiply by 2
+
+
+    cm_sb = sns.diverging_palette(210, 0, s=50, l=50, n=ntemps, center="dark") #vlag_r
+    cm_sb_rev = list(reversed(cm_sb))
+    cm_mpl = LinearSegmentedColormap.from_list("seaborn", cm_sb)#, N=ntemps)
+    cm_mpl_rev = LinearSegmentedColormap.from_list("seaborn_rev", cm_sb_rev, N=ntemps)
+
+    # startTime = datetime.datetime(year=2022, month=1, day=1, hour=0, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    # endTime = datetime.datetime(year=2022, month=2, day=15, hour=0, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    # startTime = datetime.datetime(year=2022, month=2, day=8, hour=10, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    # endTime = datetime.datetime(year=2022, month=2, day=8, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    
+    stepSize = 60
+    model = Model(id="test_load_emcee_chain", saveSimulationResult=True)
+    model.load_model(infer_connections=False, fcn=fcn)
+    simulator = Simulator(model)
+
+
+    startTime_test1 = datetime.datetime(year=2022, month=2, day=6, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test1 = datetime.datetime(year=2022, month=2, day=6, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test2 = datetime.datetime(year=2022, month=2, day=7, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test2 = datetime.datetime(year=2022, month=2, day=7, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test3 = datetime.datetime(year=2022, month=2, day=8, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test3 = datetime.datetime(year=2022, month=2, day=8, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test4 = datetime.datetime(year=2022, month=2, day=9, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test4 = datetime.datetime(year=2022, month=2, day=9, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test5 = datetime.datetime(year=2022, month=2, day=10, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))  
+    endTime_test5 = datetime.datetime(year=2022, month=2, day=10, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test6 = datetime.datetime(year=2022, month=2, day=11, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test6 = datetime.datetime(year=2022, month=2, day=11, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+
+    startTime_test7 = datetime.datetime(year=2022, month=2, day=12, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test7 = datetime.datetime(year=2022, month=2, day=12, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test8 = datetime.datetime(year=2022, month=2, day=13, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test8 = datetime.datetime(year=2022, month=2, day=13, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test9 = datetime.datetime(year=2022, month=2, day=14, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test9 = datetime.datetime(year=2022, month=2, day=14, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test10 = datetime.datetime(year=2022, month=2, day=15, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test10 = datetime.datetime(year=2022, month=2, day=15, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test11 = datetime.datetime(year=2022, month=2, day=16, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test11 = datetime.datetime(year=2022, month=2, day=16, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    startTime_test12 = datetime.datetime(year=2022, month=2, day=17, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+    endTime_test12 = datetime.datetime(year=2022, month=2, day=17, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+
+
+    startTime_test = [startTime_test1, startTime_test2, startTime_test3, startTime_test4, startTime_test5, startTime_test6, startTime_test7, startTime_test8, startTime_test9, startTime_test10]
+    endTime_test = [endTime_test1, endTime_test2, endTime_test3, endTime_test4, endTime_test5, endTime_test6, endTime_test7, endTime_test8, endTime_test9, endTime_test10]
+    stepSize_test = [stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize]
+
+    startTime_test = [startTime_test3, startTime_test4, startTime_test5, startTime_test6, startTime_test7, startTime_test8, startTime_test9, startTime_test10]
+    endTime_test = [endTime_test3, endTime_test4, endTime_test5, endTime_test6, endTime_test7, endTime_test8, endTime_test9, endTime_test10]
+    stepSize_test = [stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize]
+
+    startTime_test = [startTime_test10]#, startTime_test11, startTime_test12] ########### Plot only one day
+    endTime_test = [endTime_test10]#, endTime_test11, endTime_test12]
+    stepSize_test = [stepSize]#, stepSize, stepSize]
+
+
+    coil = model.component_dict["coil_pump_valve"]
+    fan = model.component_dict["fan"]
+    controller = model.component_dict["controller"]
+
+
+    # targetParameters = {
+    #             # coil: ["m1_flow_nominal", "m2_flow_nominal", "tau1", "tau2", "tau_m", "nominalUa.hasValue", "mFlowValve_nominal", "mFlowPump_nominal", "dpCheckValve_nominal", "dp1_nominal", "dpPump", "dpSystem", "tau_w_inlet", "tau_w_outlet", "tau_air_outlet"],
+    #             coil: ["m1_flow_nominal", "m2_flow_nominal", "tau1", "tau2", "tau_m", "nominalUa.hasValue", "mFlowValve_nominal", "mFlowPump_nominal", "dpCheckValve_nominal", "dp1_nominal", "dpPump", "dpSystem"],
+    #             fan: ["c1", "c2", "c3", "c4", "f_total"],
+    #             controller: ["kp", "Ti", "Td"]}
+    
+    targetParameters = {
+                    coil: ["m1_flow_nominal", "m2_flow_nominal", "tau1", "tau2", "tau_m", "nominalUa.hasValue", "mFlowValve_nominal", "mFlowPump_nominal", "KvCheckValve", "dpFixedSystem", "dp1_nominal", "dpPump", "dpSystem"],
+                    # coil: ["m1_flow_nominal", "m2_flow_nominal", "tau1", "tau2", "tau_m", "nominalUa.hasValue", "mFlowValve_nominal", "mFlowPump_nominal", "dpCheckValve_nominal", "dp1_nominal", "dpPump", "dpSystem"],
+                    fan: ["c1", "c2", "c3", "c4", "f_total"],
+                    controller: ["kp", "Ti", "Td"]}
+            
+    percentile = 2
+    # targetMeasuringDevices = {model.component_dict["valve position sensor"]: {"standardDeviation": 0.01/percentile, "scale_factor": 1},
+    #                         model.component_dict["coil inlet water temperature sensor"]: {"standardDeviation": 0.1/percentile, "scale_factor": 1},
+    #                         model.component_dict["coil outlet water temperature sensor"]: {"standardDeviation": 0.1/percentile, "scale_factor": 1},
+    #                             model.component_dict["coil outlet air temperature sensor"]: {"standardDeviation": 0.1/percentile, "scale_factor": 1},
+    #                             model.component_dict["fan power meter"]: {"standardDeviation": 80/percentile, "scale_factor": 1000}}
+    
+    targetMeasuringDevices = {model.component_dict["coil outlet air temperature sensor"]: {"standardDeviation": 0.1/percentile, "scale_factor": 1},
+                                model.component_dict["coil outlet water temperature sensor"]: {"standardDeviation": 0.1/percentile, "scale_factor": 1},
+                                model.component_dict["fan power meter"]: {"standardDeviation": 80/percentile, "scale_factor": 1000},
+                                model.component_dict["valve position sensor"]: {"standardDeviation": 0.01/percentile, "scale_factor": 1},
+                                model.component_dict["coil inlet water temperature sensor"]: {"standardDeviation": 0.1/percentile, "scale_factor": 1}}
+
+    n_par = result["n_par"]
+    n_par_map = result["n_par_map"]
+    print(result["n_par"])
+    print(result["n_par_map"])
+    # n_par = len(flat_attr_list) if result["n_par"]<=len(flat_attr_list) else result["n_par"]
+    # print(n_par_map)
+    # # Get number of gaussian process parameters
+    # for j, measuring_device in enumerate(targetMeasuringDevices):
+    #     source_component = [cp.connectsSystemThrough.connectsSystem for cp in measuring_device.connectsAt][0]
+    #     n_par += len(source_component.input)+3
+    #     n_par_map[measuring_device.id] = len(source_component.input)+3
+    # print(n_par)
+    # print(n_par_map)
+
+
+    if assume_uncorrelated_noise==False:
+        for j, measuring_device in enumerate(targetMeasuringDevices):
+            # print(n_par_map[measuring_device.id])
+            for i in range(n_par_map[measuring_device.id]):
+                if i==0:
+                    s = f"$a_{str(j)}$"
+                    s = r'{}'.format(s)
+                    flat_attr_list.append(s)
+                # elif i==1:
+                #     s = r'$\gamma_{%.0f}$' % (j,)
+                #     flat_attr_list.append(s)
+                # elif i==2:
+                #     s = r'$\mathrm{ln}P_{%.0f}$' % (j,)
+                #     flat_attr_list.append(s)
+                else:
+                    s = r'$l_{%.0f,%.0f}$' % (j,i-1, )
+                    flat_attr_list.append(s)
+
+        # result["stepSize_train"] = stepSize
+        # result["startTime_train"] = startTime
+        # result["endTime_train"] = endTime
+
+        # standardDeviation = np.array([0.01/percentile, 0.5/2, 0.5/2, 0.5/2, 80/2])
+
+
+        # flat_component_list = [obj.id for obj, attr_list in targetParameters.items() for i in range(len(attr_list))]
+        # flat_attr_list = [attr for attr_list in targetParameters.values() for attr in attr_list]
+
+        # result["component_list"] = flat_component_list
+        # result["attr_list"] = flat_attr_list
+
+        # with open(loaddir, 'wb') as handle:
+        #     pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)
+
+        print("model_load_chain_log")
+
+
+        print(model.load_chain_log(loaddir))
+        print(model.chain_log["chain.x"].shape)
+
+        #plot_jump_plot(model)
+
+        #plot_logl_plot(model)
+
+        #plot_trace_plot(model)test_load_emcee_chain.py
+
+        #plot_iac_plot(model)
+
+        #plot_swap_plot(model)
+
+        plot_corner_plot(model)
+
+    if do_inference:
+        model.load_chain_log(loaddir)
+
+        startTime_train1 = datetime.datetime(year=2022, month=2, day=1, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        endTime_train1 = datetime.datetime(year=2022, month=2, day=1, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        startTime_train2 = datetime.datetime(year=2022, month=2, day=2, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        endTime_train2 = datetime.datetime(year=2022, month=2, day=2, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        startTime_train3 = datetime.datetime(year=2022, month=2, day=3, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        endTime_train3 = datetime.datetime(year=2022, month=2, day=3, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        startTime_train4 = datetime.datetime(year=2022, month=2, day=4, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        endTime_train4 = datetime.datetime(year=2022, month=2, day=4, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        startTime_train5 = datetime.datetime(year=2022, month=2, day=5, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        endTime_train5 = datetime.datetime(year=2022, month=2, day=5, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        startTime_train6 = datetime.datetime(year=2022, month=2, day=6, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        endTime_train6 = datetime.datetime(year=2022, month=2, day=6, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        startTime_train7 = datetime.datetime(year=2022, month=2, day=7, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        endTime_train7 = datetime.datetime(year=2022, month=2, day=7, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        model.chain_log["startTime_train"] = [startTime_train1, startTime_train2, startTime_train3, startTime_train4, startTime_train5, startTime_train6, startTime_train7]
+        model.chain_log["endTime_train"] = [endTime_train1, endTime_train2, endTime_train3, endTime_train4, endTime_train5, endTime_train6, endTime_train7]
+        model.chain_log["stepSize_train"] = [stepSize, stepSize, stepSize, stepSize, stepSize, stepSize, stepSize]
+
+        # startTime_train1 = datetime.datetime(year=2022, month=2, day=1, hour=8, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        # endTime_train1 = datetime.datetime(year=2022, month=2, day=3, hour=22, minute=0, second=0, tzinfo=tz.gettz("Europe/Copenhagen"))
+        # model.chain_log["startTime_train"] = [startTime_train1]
+        # model.chain_log["endTime_train"] = [endTime_train1]
+        # model.chain_log["stepSize_train"] = [stepSize]
+        # model.chain_log["n_par"] = n_par
+        # model.chain_log["n_par_map"] = n_par_map
+        print(result["chain.x"].shape)
+        parameter_chain = result["chain.x"][burnin:,0,:,:]
+        parameter_chain = parameter_chain[::100,:,:]
+        print(parameter_chain.shape)
+        del result
+        del model.chain_log["chain.x"]
+
+
+        # ylims = ([20, 23], [19.5, 25], [None, None], [0,1], [19.5, 28])
+        ylims = ([0,1], [19.5, 28.5], [19.5, 25.5], [20, 23.5], [None, None])
+        
+        assert len(flat_attr_list) == ndim, f"Number of parameters in flat_attr_list ({len(flat_attr_list)}) does not match number of parameters in chain.x ({ndim})"
+        # parameter_chain = result["chain.x"][-1:,0,:,:] #[-1:,0,:,:]
+        parameter_chain = parameter_chain.reshape((parameter_chain.shape[0]*parameter_chain.shape[1], parameter_chain.shape[2]))
+        fig, axes = simulator.run_emcee_inference(model, parameter_chain, targetParameters, targetMeasuringDevices, startTime_test, endTime_test, stepSize_test, assume_uncorrelated_noise=assume_uncorrelated_noise)
+        ylabels = [r"$u_v [1]$", r"$T_{c,w,in} [^\circ\!C]$", r"$T_{c,w,out} [^\circ\!C]$", r"$T_{c,a,out} [^\circ\!C]$", r"$\dot{P}_f [W]$"]
+        # fig.subplots_adjust(hspace=0.3)
+        # fig.set_size_inches((15,10))
+        for ax, ylabel, ylim in zip(axes, ylabels, ylims):
+            # ax.legend(loc="center left", bbox_to_anchor=(1,0.5), prop={'size': 12})
+            # pos = ax.get_position()
+            # pos.x0 = 0.15       # for example 0.2, choose your value
+            # pos.x1 = 0.99       # for example 0.2, choose your value
+
+            # ax.set_position(pos)
+            ax.tick_params(axis='y', labelsize=10)
+            # ax.locator_params(axis='y', nbins=3)
+            ax.set_ylim(ylim)
+            ax.yaxis.set_major_locator(plt.MaxNLocator(3))
+            ax.text(-0.07, 0.5, ylabel, fontsize=14, rotation="horizontal", ha="right", transform=ax.transAxes)
+            ax.xaxis.label.set_color("black")
+
+        
+        # axes[3].plot(simulator.dateTimeSteps, model.component_dict["Supply air temperature setpoint"].savedOutput["scheduleValue"], color="blue", label="setpoint", linewidth=0.5)
+        # axes[3].plot(simulator.dateTimeSteps, model.component_dict["fan inlet air temperature sensor"].get_physical_readings(startTime, endTime, stepSize)[0:-1], color="green", label="inlet air", linewidth=0.5)
+        fig.savefig(r'C:\Users\AUTH\Desktop\Python_Projects\Twin4Build\twin4build\estimator\tests\generated_files\LBNL_inference_plot.png', dpi=300)
+        # ax.plot(simulator.dateTimeSteps, simulator.model.component_dict[])
+
+    if do_inference==False:
+        assert len(flat_attr_list) == ndim, f"Number of parameters in flat_attr_list ({len(flat_attr_list)}) does not match number of parameters in chain.x ({ndim})"
+        
+        plt.rcParams['mathtext.fontset'] = 'cm'
+
+
+
+        if assume_uncorrelated_noise==False:
+            attr_list_model = flat_attr_list[:-n_par]
+            attr_list_noise = flat_attr_list[-n_par:]
+            flat_attr_list__ = [attr_list_model, attr_list_noise]
+            list_ = ["chain.x"]
+            print(list_)
+            result_model = result.copy()
+            result_noise = result.copy()
+            for key in list_:
+                result_key = result[key]
+                result_model[key] = result_key[...,:-n_par]
+                result_noise[key] = result_key[...,-n_par:]
+            result_list = [result_model, result_noise]
+        else:
+            flat_attr_list__ = [flat_attr_list]
+            result_list = [result]
+
+        if do_jump_plot:
+            fig_jump, ax_jump = plt.subplots(layout='compressed')
+            fig_jump.set_size_inches((17, 12))
+            fig_jump.suptitle("Jumps", fontsize=20)
+            # n_checkpoints = result["chain.jumps_proposed"].shape[0]
+            # for i_checkpoint in range(n_checkpoints):
+            #     for i in range(ntemps):
+            #         ax_jump.scatter([i_checkpoint]*nwalkers, result["chain.jumps_accepted"][i_checkpoint,i,:]/result["chain.jumps_proposed"][i_checkpoint,i,:], color=cm_sb[i], s=20, alpha=1)
+
+            n_it = result["chain.jump_acceptance"].shape[0]
+            # for i_walker in range(nwalkers):
+            for i in range(ntemps):
+                if i==0: #######################################################################
+                    ax_jump.plot(range(n_it), result["chain.jump_acceptance"][:,i], color=cm_sb[i])
+                    print("ax_jump_plot type:" + str(type(ax_jump)))
+        if do_logl_plot:
+            fig_logl, ax_logl = plt.subplots(layout='compressed')
+            fig_logl.set_size_inches((17/4, 12/4))
+            fig_logl.suptitle("Log-likelihood", fontsize=20)
+            # logl = np.abs(result_["chain.logl"])
+            logl = result["chain.logl"]
+            logl[np.abs(logl)>1e+9] = np.nan
+            
+            indices = np.where(logl[:,0,:] == np.nanmax(logl[:,0,:]))
+            print(logl[:,0,:].max())
+            s0 = indices[0][0]
+            s1 = indices[1][0]
+            print("logl_max: ", logl[s0,0,s1])
+            # print("x_max: ", result["chain.x"][s0, 0, s1, :])
+            
+            n_it = result["chain.logl"].shape[0]
+            for i_walker in range(nwalkers):
+                for i in range(ntemps):
+                    if i==0: #######################################################################
+                        ax_logl.plot(range(n_it), logl[:,i,i_walker], color=cm_sb[i])
+                        # ax_logl.set_yscale('log')
+
+        for ii, (flat_attr_list_, result_) in enumerate(zip(flat_attr_list__, result_list)):
+            nparam = len(flat_attr_list_)
+            ncols = 3
+            nrows = math.ceil(nparam/ncols)
+            print(nparam, ncols, nrows)
+
+            print("result_")
+
+            print(result_)
+
+
+            ndim = result_["chain.x"].shape[3]
+            ntemps = result_["chain.x"].shape[1]
+            nwalkers = result_["chain.x"].shape[2] #Round up to nearest even number and multiply by 2
+            
+            # cm = plt.get_cmap('RdYlBu', ntemps)
+            # cm_sb = sns.color_palette("vlag_r", n_colors=ntemps, center="dark") #vlag_r
+            cm_sb = sns.diverging_palette(210, 0, s=50, l=50, n=ntemps, center="dark") #vlag_r
+            cm_sb_rev = list(reversed(cm_sb))
+            cm_mpl = LinearSegmentedColormap.from_list("seaborn", cm_sb)#, N=ntemps)
+            cm_mpl_rev = LinearSegmentedColormap.from_list("seaborn_rev", cm_sb_rev, N=ntemps)
+
+            fig_trace_beta, axes_trace = plt.subplots(nrows=nrows, ncols=ncols, layout='compressed')
+            fig_trace_beta.set_size_inches((17, 12))
+            
+
+            # list_ = ["chain.logl", "chain.logP", "chain.x", "chain.betas"]
+            # for key in list_:
+            #     for i, arr in enumerate(result[key]):
+            #         result[key][i] = arr[-nsample_checkpoint:]
+                
+            # for key in result.keys():
+            #     result[key] = np.concatenate(result[key],axis=0)
+                # result["chain.jumps_accepted"].append(chain.jumps_accepted)
+                # result["chain.jumps_proposed"].append(chain.jumps_proposed)
+                # result["chain.logl"].append(chain.logl)
+                # result["chain.logP"].append(chain.logP)
+                # result["chain.swaps_accepted"].append(chain.swaps_accepted)
+                # result["chain.swaps_proposed"].append(chain.swaps_proposed)
+                # result["chain.x"].append(chain.x)
+                # result["chain.betas"].append(chain.betas)
+
+            # vmin = np.min(result["chain.T"])
+            # vmax = np.max(result["chain.T"])
+
+
+
+
+
+            if do_iac_plot:
+                fig_iac = fig_trace_beta
+                axes_iac = copy.deepcopy(axes_trace)
+                for j, attr in enumerate(flat_attr_list_):
+                    row = math.floor(j/ncols)
+                    col = int(j-ncols*row)
+                    axes_iac[row, col] = axes_trace[row, col].twinx()
+                # fig_iac, axes_iac = plt.subplots(nrows=nrows, ncols=ncols, layout='compressed')
+                # fig_iac.set_size_inches((17, 12))
+                # fig_iac.suptitle("Integrated AutoCorrelated Time", fontsize=20)
+                iac = result_["integratedAutoCorrelatedTime"][:-1]
+
+                n_it = iac.shape[0]
+
+                for i in range(ntemps):
+                    beta = result_["chain.betas"][:, i]
+                    for j, attr in enumerate(flat_attr_list_):
+                        row = math.floor(j/ncols)
+                        col = int(j-ncols*row)
+                        
+                        if ntemps>1:
+                            sc = axes_iac[row, col].plot(range(n_it), iac[:,i,j], color=red, alpha=1, zorder=1)
+                        else:
+                            sc = axes_iac[row, col].plot(range(n_it), iac[:,i,j], color=red, alpha=1, zorder=1)
+                
+                # add heristic tau = N/50 line
+                heuristic_line = np.arange(n_it)/20
+                for j, attr in enumerate(flat_attr_list_):
+                    row = math.floor(j/ncols)
+                    col = int(j-ncols*row)
+                    axes_iac[row, col].plot(range(n_it), heuristic_line, color="black", linewidth=1, linestyle="dashed", alpha=1, label=r"$\tau=N/50$")
+                    axes_iac[row, col].set_ylim([0-0.05*iac.max(), iac.max()+0.05*iac.max()])
+                # fig_iac.legend()
+                
+            
+
+            
+            if do_trace_plot:
+                
+                chain_logl = result_["chain.logl"]
+                bool_ = chain_logl<-5e+9
+                chain_logl[bool_] = np.nan
+                chain_logl[np.isnan(chain_logl)] = np.nanmin(chain_logl)
+
+                for nt in reversed(range(ntemps)):
+                    for nw in range(nwalkers):
+                        x = result_["chain.x"][:, nt, nw, :]
+                        T = result_["chain.T"][:, nt]
+                        beta = result_["chain.betas"][:, nt]
+                        logl = chain_logl[:, nt, nw]
+                        # alpha = (max_alpha-min_alpha)*(logl-logl_min)/(logl_max-logl_min) + min_alpha
+                        # alpha = (max_alpha-min_alpha)*(T-vmin)/(vmax-vmin) + min_alpha
+                        # alpha = (max_alpha-min_alpha)*(beta-vmin)/(vmax-vmin) + min_alpha
+                        # Trace plots
+                        
+                        
+                        for j, attr in enumerate(flat_attr_list_):
+                            row = math.floor(j/ncols)
+                            col = int(j-ncols*row)
+                            # sc = axes_trace[row, col].scatter(range(x[:,j].shape[0]), x[:,j], c=T, norm=matplotlib.colors.LogNorm(vmin=vmin, vmax=vmax), s=0.3, cmap=cm_mpl, alpha=0.1)
+                            if ntemps>1:
+                                
+                                sc = axes_trace[row, col].scatter(range(x[:,j].shape[0]), x[:,j], c=beta, vmin=vmin, vmax=vmax, s=0.3, cmap=cm_mpl_rev, alpha=0.1)
+                            else:
+                                sc = axes_trace[row, col].scatter(range(x[:,j].shape[0]), x[:,j], s=0.3, color=cm_sb[0], alpha=0.1)
+                                
+                            axes_trace[row, col].axvline(burnin, color="black", linewidth=1, alpha=0.8)#, linestyle="--")
+
+                            # if plotted==False:
+                            #     axes_trace[row, col].text(x_left+dx/2, 0.44, 'Burnin', ha='center', va='center', rotation='horizontal', fontsize=15, transform=axes_trace[row, col].transAxes)
+                            #     axes_trace[row, col].arrow(x_right, 0.5, -dx, 0, head_width=0.1, head_length=0.05, color="black", transform=axes_trace[row, col].transAxes)
+                            #     axes_trace[row, col].arrow(x_left, 0.5, dx, 0, head_width=0.1, head_length=0.05, color="black", transform=axes_trace[row, col].transAxes)
+                            #     axes_trace[row, col].set_ylabel(attr, fontsize=20)
+                            #     plotted = True
+
+
+
+                x_left = 0.1
+                x_mid_left = 0.515
+                x_right = 0.9
+                x_mid_right = 0.58
+                dx_left = x_mid_left-x_left
+                dx_right = x_right-x_mid_right
+
+                fontsize = 12
+                for j, attr in enumerate(flat_attr_list_):
+                    row = math.floor(j/ncols)
+                    col = int(j-ncols*row)
+                    axes_trace[row, col].axvline(burnin, color="black", linestyle=":", linewidth=1.5, alpha=0.5)
+                    y = np.array([-np.inf, np.inf])
+                    x1 = -burnin
+                    x2 = burnin
+                    axes_trace[row, col].fill_betweenx(y, x1, x2=0)
+                    axes_trace[row, col].text(x_left+dx_left/2, 0.44, 'Burn-in', ha='center', va='center', rotation='horizontal', fontsize=fontsize, transform=axes_trace[row, col].transAxes)
+                    # axes_trace[row, col].arrow(x_mid_left, 0.5, -dx_left, 0, head_width=0.1, head_length=0.05, color="black", transform=axes_trace[row, col].transAxes)
+                    # axes_trace[row, col].arrow(x_left, 0.5, dx_left, 0, head_width=0.1, head_length=0.05, color="black", transform=axes_trace[row, col].transAxes)
+
+                    axes_trace[row, col].text(x_mid_right+dx_right/2, 0.44, 'Posterior', ha='center', va='center', rotation='horizontal', fontsize=fontsize, transform=axes_trace[row, col].transAxes)
+                    # axes_trace[row, col].arrow(x_right, 0.5, -dx_right, 0, head_width=0.1, head_length=0.05, color="black", transform=axes_trace[row, col].transAxes)
+                    # axes_trace[row, col].arrow(x_mid_right, 0.5, dx_right, 0, head_width=0.1, head_length=0.05, color="black", transform=axes_trace[row, col].transAxes)
+                    axes_trace[row, col].set_ylabel(attr, fontsize=20)
+                    axes_trace[row, col].ticklabel_format(style='plain', useOffset=False)
+
+                    # arrow = axes_trace[row, col].annotate('', 
+                    #                                     xy =(x_left, 0.5),
+                    #                                     xytext =(x_mid_left, 0.5), 
+                    #                                     arrowprops = dict(
+                    #                                         arrowstyle="|-|,widthA=0.7, widthB=0.7"
+                    #                                     ))
+                    
+                    # arrow = axes_trace[row, col].annotate('', 
+                    #                                     xy =(x_mid_right, 0.5),
+                    #                                     xytext =(x_right, 0.5), 
+                    #                                     arrowprops = dict(
+                    #                                         arrowstyle="|-|,widthA=0.7, widthB=0.7"
+                    #                                     ))
+                                                    
+                # fig_trace.legend(labels, loc='lower right', bbox_to_anchor=(1,-0.1), ncol=len(labels))#, bbox_transform=fig.transFigure)
+                if ntemps>1:
+                    cb = fig_trace_beta.colorbar(sc, ax=axes_trace)
+                    cb.set_label(label=r"$T$", size=30)#, weight='bold')
+                    cb.solids.set(alpha=1)
+                    # fig_trace_beta.tight_layout()
+                    dist = (vmax-vmin)/(ntemps)/2
+                    tick_start = vmin+dist
+                    tick_end = vmax-dist
+                    tick_locs = np.linspace(tick_start, tick_end, ntemps)[::-1]
+                    cb.set_ticks(tick_locs)
+                    labels = list(result_["chain.T"][0,:])
+                    inf_label = r"$\infty$"
+                    labels[-1] = inf_label
+                    ticklabels = [str(round(float(label), 1)) if isinstance(label, str)==False else label for label in labels] #round(x, 2)
+                    cb.set_ticklabels(ticklabels, size=12)
+
+                    for tick in cb.ax.get_yticklabels():
+                        tick.set_fontsize(12)
+                        txt = tick.get_text()
+                        if txt==inf_label:
+                            tick.set_fontsize(20)
+                            # tick.set_text()
+                            # tick.set_ha("center")
+                            # tick.set_va("center_baseline")
+                if ii==0:
+                    fig_trace_beta.savefig(r'C:\Users\AUTH\Desktop\Python_Projects\Twin4Build\twin4build\estimator\tests\generated_files\LBNL_trace_plot.png', dpi=300)
+
+            if do_swap_plot and ntemps>1:
+                fig_swap, ax_swap = plt.subplots(layout='compressed')
+                fig_swap.set_size_inches((17, 12))
+                fig_swap.suptitle("Swaps", fontsize=20)
+                n = ntemps-1
+                for i in range(n):
+                    if i==0: #######################################################################
+                        ax_swap.plot(range(result_["chain.swaps_accepted"][:,i].shape[0]), result_["chain.swaps_accepted"][:,i]/result_["chain.swaps_proposed"][:,i], color=cm_sb[i])
+
+
+
+
+            if do_corner_plot:
+                # fig_corner, axes_corner = plt.subplots(nrows=ndim, ncols=ndim, layout='compressed')
+                
+                parameter_chain = result_["chain.x"][burnin:,0,:,:]
+                parameter_chain = parameter_chain.reshape(parameter_chain.shape[0]*parameter_chain.shape[1],parameter_chain.shape[2])
+                fig_corner = corner.corner(parameter_chain, fig=None, labels=flat_attr_list_, labelpad=-0.2, show_titles=True, color=cm_sb[0], plot_contours=True, bins=15, hist_bin_factor=5, max_n_ticks=3, quantiles=[0.16, 0.5, 0.84], title_kwargs={"fontsize": 10, "ha": "left", "position": (0.03, 1.01)})
+                fig_corner.set_size_inches((12, 12))
+                pad = 0.025
+                fig_corner.subplots_adjust(left=pad, bottom=pad, right=1-pad, top=1-pad, wspace=0.08, hspace=0.08)
+                axes = fig_corner.get_axes()
+                for ax in axes:
+                    ax.set_xticks([], minor=True)
+                    ax.set_xticks([])
+                    ax.set_yticks([], minor=True)
+                    ax.set_yticks([])
+
+                    ax.xaxis.set_ticklabels([])
+                    ax.yaxis.set_ticklabels([])
+
+                median = np.median(parameter_chain, axis=0)
+                corner.overplot_lines(fig_corner, median, color=red, linewidth=0.5)
+                corner.overplot_points(fig_corner, median.reshape(1,median.shape[0]), marker="s", color=red)
+                if ii==0:
+                    fig_corner.savefig(r'C:\Users\AUTH\Desktop\Python_Projects\Twin4Build\twin4build\estimator\tests\generated_files\LBNL_corner_plot.png', dpi=300)
+        # color = cm(1)
+        # fig_trace_loglike, axes_trace_loglike = plt.subplots(nrows=1, ncols=1)
+        # fig_trace_loglike.set_size_inches((17, 12))
+        # fig_trace_loglike.suptitle("Trace plots of log likelihoods")
+        # vmin = np.nanmin(-chain_logl)
+        # vmax = np.nanmax(-chain_logl)
+        # for nt in range(1):
+        #     for nw in range(nwalkers):
+        #         logl = chain_logl[:, nt, nw]
+        #         axes_trace_loglike.scatter(range(logl.shape[0]), -logl, color=color, s=4, alpha=0.8)
+        # axes_trace_loglike.set_yscale("log")
+        # plt.show()
+        
+    plt.show()
+
+
+if __name__=="__main__":
+    test_load_emcee_chain()
\ No newline at end of file
Index: .idea/.gitignore
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/.gitignore b/.idea/.gitignore
new file mode 100644
--- /dev/null	(date 1716281320369)
+++ b/.idea/.gitignore	(date 1716281320369)
@@ -0,0 +1,8 @@
+# Default ignored files
+/shelf/
+/workspace.xml
+# Editor-based HTTP Client requests
+/httpRequests/
+# Datasource local storage ignored files
+/dataSources/
+/dataSources.local.xml
Index: twin4build/estimator/tests/test_plot_emcee_chain.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/twin4build/estimator/tests/test_plot_emcee_chain.py b/twin4build/estimator/tests/test_plot_emcee_chain.py
new file mode 100644
--- /dev/null	(date 1717404615253)
+++ b/twin4build/estimator/tests/test_plot_emcee_chain.py	(date 1717404615253)
@@ -0,0 +1,317 @@
+import matplotlib.pyplot as plt
+import matplotlib
+import pickle
+import math
+import numpy as np
+import os
+import datetime
+import sys
+import corner
+import seaborn as sns
+import copy
+from dateutil import tz
+from io import StringIO
+from matplotlib.colors import LinearSegmentedColormap
+if __name__ == '__main__':
+    uppath = lambda _path,n: os.sep.join(_path.split(os.sep)[:-n])
+    file_path = uppath(os.path.abspath(__file__), 4)
+    sys.path.append(file_path)
+from twin4build.utils.uppath import uppath
+from twin4build.simulator.simulator import Simulator
+from twin4build.model.model import Model
+from twin4build.model.tests.test_LBNL_bypass_coil_model import fcn
+import twin4build.utils.plot.plot as plot
+
+def iac_plot_preprocessing(model: Model, uncorrelated_noise: bool = True):
+
+    #test at sidste dimension p paramterlist, er det
+    n_par = model.chain_log["chain.x"]["n_par"]
+
+    flat_attr_list_ = [r"$\overline{\dot{m}}_{c,w}$", r"$\overline{\dot{m}}_{c,a}$", r"$\tau_w$", r"$\tau_a$",
+                      r"$\tau_m$", r"$\overline{UA}$", r"$\overline{\dot{m}}_{v,w}$", r"$\overline{\dot{m}}_{cv,w}$",
+                      r"$K_{cv}$", r"$\Delta P_{s,res}$", r"$\overline{\Delta P}_{c}$", r"$\Delta P_{p}$",
+                      r"$\Delta P_{s}$", r"$c_1$", r"$c_2$", r"$c_3$", r"$c_4$", r"$f_{tot}$", r"$K_P$", r"$T_I$",
+                      r"$T_D$"]
+
+
+    if uncorrelated_noise == True:
+        flat_attr_list__ = [flat_attr_list_]
+        result_list = model.chain_log["chain.x"]
+
+    if uncorrelated_noise == False:
+        attr_list_model = flat_attr_list_[:-n_par]
+        attr_list_noise = flat_attr_list_[-n_par:]
+        flat_attr_list__ = [attr_list_model, attr_list_noise]
+        list_ = ["chain.x"]
+        print(list_)
+        result_model = (model.chain_log("chain.x")).copy()
+        result_noise = (model.chain_log("chain.x")).copy()
+        for key in list_:
+            result_key = model.chain_log("chain.x")[key]
+            result_model[key] = result_key[..., :-n_par]
+            result_noise[key] = result_key[..., -n_par:]
+        result_list = [result_model, result_noise]
+
+    for ii, (flat_attr_list_, result_) in enumerate(zip(flat_attr_list__, result_list)):
+        nparam = len(flat_attr_list_)
+        ncols = 3
+        nrows = math.ceil(nparam / ncols)
+        print(nparam, ncols, nrows)
+
+        ndim = model.chain_log["chain.x"].shape[3]
+        ntemps = model.chain_log["chain.x"].shape[1]
+        nwalkers = model.chain_log["chain.x"].shape[2]  # Round up to nearest even number and multiply by 2
+
+        cm_sb = sns.diverging_palette(210, 0, s=50, l=50, n=ntemps, center="dark")  # vlag_r
+        cm_sb_rev = list(reversed(cm_sb))
+        cm_mpl = LinearSegmentedColormap.from_list("seaborn", cm_sb)  # , N=ntemps)
+        cm_mpl_rev = LinearSegmentedColormap.from_list("seaborn_rev", cm_sb_rev, N=ntemps)
+
+        fig_trace_beta, axes_trace = plt.subplots(nrows=nrows, ncols=ncols, layout='compressed')
+        fig_trace_beta.set_size_inches((17, 12))
+
+        return result_, fig_trace_beta , axes_trace , flat_attr_list_ , ncols , ntemps, cm_mpl_rev, nwalkers, cm_sb
+
+def plot_jump_plot(model: Model):
+
+    ntemps = model.chain_log["chain.x"].shape[1]
+
+    cm_sb = sns.diverging_palette(210, 0, s=50, l=50, n=ntemps, center="dark")
+
+    fig_jump, ax_jump = plt.subplots(layout='compressed')
+    fig_jump.set_size_inches((17, 12))
+    fig_jump.suptitle("Jumps", fontsize=20)
+
+    n_it = model.chain_log["chain.jump_acceptance"].shape[0]
+    for i in range(ntemps):
+        if i == 0:
+            ax_jump.plot(range(n_it), model.chain_log["chain.jump_acceptance"][:, i], color=cm_sb[i])
+
+    plt.show()
+
+def plot_logl_plot(model: Model):
+    ntemps = model.chain_log["chain.x"].shape[1]
+    nwalkers = model.chain_log["chain.x"].shape[2]
+
+    cm_sb = sns.diverging_palette(210, 0, s=50, l=50, n=ntemps, center="dark")
+
+    fig_logl, ax_logl = plt.subplots(layout='compressed')
+    fig_logl.set_size_inches((17 / 4, 12 / 4))
+    fig_logl.suptitle("Log-likelihood", fontsize=20)
+    logl = model.chain_log["chain.logl"]
+    logl[np.abs(logl) > 1e+9] = np.nan
+
+    indices = np.where(logl[:, 0, :] == np.nanmax(logl[:, 0, :]))
+    print(logl[:, 0, :].max())
+    s0 = indices[0][0]
+    s1 = indices[1][0]
+    print("logl_max: ", logl[s0, 0, s1])
+
+    n_it = model.chain_log["chain.logl"].shape[0]
+    for i_walker in range(nwalkers):
+        for i in range(ntemps):
+            if i == 0:  #######################################################################
+                ax_logl.plot(range(n_it), logl[:, i, i_walker], color=cm_sb[i])
+
+    plt.show()
+
+def plot_iac_plot(model: Model):
+    colors = sns.color_palette("deep")
+    red = colors[3]
+    plot.load_params()
+
+    result_, fig_trace_beta, axes_trace, flat_attr_list_, ncols, ntemps, cm_mpl_rev, nwalkers, cm_sb = iac_plot_preprocessing(model)
+
+
+    axes_iac = copy.deepcopy(axes_trace)
+    for j, attr in enumerate(flat_attr_list_):
+        row = math.floor(j / ncols)
+        col = int(j - ncols * row)
+        axes_iac[row, col] = axes_trace[row, col].twinx()
+
+    print(result_)
+
+    iac = result_["integratedAutoCorrelatedTime"][:-1]
+    print(iac)
+
+    n_it = iac.shape[0]
+    for i in range(ntemps):
+        for j, attr in enumerate(flat_attr_list_):
+            row = math.floor(j / ncols)
+
+    heuristic_line = np.arange(n_it) / 20
+    for j, attr in enumerate(flat_attr_list_):
+        row = math.floor(j / ncols)
+        col = int(j - ncols * row)
+        axes_iac[row, col].plot(range(n_it), heuristic_line, color="black", linewidth=1, linestyle="dashed",
+                                alpha=1, label=r"$\tau=N/50$")
+        axes_iac[row, col].set_ylim([0 - 0.05 * iac.max(), iac.max() + 0.05 * iac.max()])
+
+    plt.show()
+
+
+def plot_trace_plot(model: Model):
+    vmin = np.min(model.chain_log["chain.betas"])
+    vmax = np.max(model.chain_log["chain.betas"])
+    burnin = 2000
+
+    result_, fig_trace_beta, axes_trace, flat_attr_list_, ncols, ntemps, cm_mpl_rev, nwalkers, cm_sb = iac_plot_preprocessing(model)
+
+    chain_logl = model.chain_log["chain.logl"]
+    bool_ = chain_logl < -5e+9
+    chain_logl[bool_] = np.nan
+    chain_logl[np.isnan(chain_logl)] = np.nanmin(chain_logl)
+
+    for nt in reversed(range(ntemps)):
+        for nw in range(nwalkers):
+            x = model.chain_log["chain.x"][:, nt, nw, :]
+            T = model.chain_log["chain.T"][:, nt]
+            beta = model.chain_log["chain.betas"][:, nt]
+
+            for j, attr in enumerate(flat_attr_list_):
+                row = math.floor(j / ncols)
+                col = int(j - ncols * row)
+                if ntemps > 1:
+
+                    sc = axes_trace[row, col].scatter(range(x[:, j].shape[0]), x[:, j], c=beta, vmin=vmin, vmax=vmax,
+                                                      s=0.3, cmap=cm_mpl_rev, alpha=0.1)
+                else:
+                    sc = axes_trace[row, col].scatter(range(x[:, j].shape[0]), x[:, j], s=0.3, color=cm_sb[0],
+                                                      alpha=0.1)
+
+                axes_trace[row, col].axvline(burnin, color="black", linewidth=1, alpha=0.8)  # , linestyle="--")
+
+
+    x_left = 0.1
+    x_mid_left = 0.515
+    x_right = 0.9
+    x_mid_right = 0.58
+    dx_left = x_mid_left - x_left
+    dx_right = x_right - x_mid_right
+
+    fontsize = 12
+    for j, attr in enumerate(flat_attr_list_):
+        row = math.floor(j / ncols)
+        col = int(j - ncols * row)
+        axes_trace[row, col].axvline(burnin, color="black", linestyle=":", linewidth=1.5, alpha=0.5)
+        y = np.array([-np.inf, np.inf])
+        x1 = -burnin
+        x2 = burnin
+        axes_trace[row, col].fill_betweenx(y, x1, x2=0)
+        axes_trace[row, col].text(x_left + dx_left / 2, 0.44, 'Burn-in', ha='center', va='center',
+                                  rotation='horizontal', fontsize=fontsize, transform=axes_trace[row, col].transAxes)
+
+        axes_trace[row, col].text(x_mid_right + dx_right / 2, 0.44, 'Posterior', ha='center', va='center',
+                                  rotation='horizontal', fontsize=fontsize, transform=axes_trace[row, col].transAxes)
+
+        axes_trace[row, col].set_ylabel(attr, fontsize=20)
+        axes_trace[row, col].ticklabel_format(style='plain', useOffset=False)
+
+    if ntemps > 1:
+        cb = fig_trace_beta.colorbar(sc, ax=axes_trace)
+        cb.set_label(label=r"$T$", size=30)  # , weight='bold')
+        cb.solids.set(alpha=1)
+        # fig_trace_beta.tight_layout()
+        dist = (vmax - vmin) / (ntemps) / 2
+        tick_start = vmin + dist
+        tick_end = vmax - dist
+        tick_locs = np.linspace(tick_start, tick_end, ntemps)[::-1]
+        cb.set_ticks(tick_locs)
+        labels = list(result_["chain.T"][0, :])
+        inf_label = r"$\infty$"
+        labels[-1] = inf_label
+        ticklabels = [str(round(float(label), 1)) if isinstance(label, str) == False else label for label in
+                      labels]  # round(x, 2)
+        cb.set_ticklabels(ticklabels, size=12)
+
+        for tick in cb.ax.get_yticklabels():
+            tick.set_fontsize(12)
+            txt = tick.get_text()
+            if txt == inf_label:
+                tick.set_fontsize(20)
+
+    plt.show()
+
+def plot_swap_plot(model: Model):
+    result_, fig_trace_beta, axes_trace, flat_attr_list_, ncols, ntemps, cm_mpl_rev, nwalkers, cm_sb = iac_plot_preprocessing(
+        model)
+
+    fig_swap, ax_swap = plt.subplots(layout='compressed')
+    fig_swap.set_size_inches((17, 12))
+    fig_swap.suptitle("Swaps", fontsize=20)
+    n = ntemps-1
+    for i in range(n):
+        if i==0: #######################################################################
+            ax_swap.plot(range(result_["chain.swaps_accepted"][:,i].shape[0]), result_["chain.swaps_accepted"][:,i]/result_["chain.swaps_proposed"][:,i], color=cm_sb[i])
+
+    plt.show()
+
+def plot_corner_plot(model: Model):
+
+    plt.rcParams['mathtext.fontset'] = 'cm'
+    colors = sns.color_palette("deep")
+    red = colors[3]
+    plot.load_params()
+
+    burnin = 5149
+    result_, fig_trace_beta, axes_trace, flat_attr_list_, ncols, ntemps, cm_mpl_rev, nwalkers, cm_sb = iac_plot_preprocessing(
+        model, False)
+
+
+    parameter_chain = model.chain_log["chain.x"][burnin:, 0, :, :]
+    parameter_chain = parameter_chain.reshape(parameter_chain.shape[0] * parameter_chain.shape[1],
+                                              parameter_chain.shape[2])
+    fig_corner = corner.corner(parameter_chain, fig=None, labels=flat_attr_list_, labelpad=-0.2, show_titles=False,
+                               color=cm_sb[0], plot_contours=True, bins=15, hist_bin_factor=5, max_n_ticks=3,
+                               quantiles=[0.16, 0.5, 0.84],
+                               title_kwargs={"fontsize": 10, "ha": "left", "position": (0.03, 1.01)})
+    fig_corner.set_size_inches((12, 12))
+    pad = 0.025
+    fig_corner.subplots_adjust(left=pad, bottom=pad, right=1 - pad, top=1 - pad, wspace=0.08, hspace=0.08)
+    axes = fig_corner.get_axes()
+    for ax in axes:
+        ax.set_xticks([], minor=True)
+        ax.set_xticks([])
+        ax.set_yticks([], minor=True)
+        ax.set_yticks([])
+
+        ax.xaxis.set_ticklabels([])
+        ax.yaxis.set_ticklabels([])
+
+    median = np.median(parameter_chain, axis=0)
+    corner.overplot_lines(fig_corner, median, color=red, linewidth=0.5)
+    corner.overplot_points(fig_corner, median.reshape(1, median.shape[0]), marker="s", color=red)
+
+    plt.show()
+
+"""def plot_inference_plot(model: Model):
+    result_, fig_trace_beta, axes_trace, flat_attr_list_, ncols, ntemps, cm_mpl_rev, nwalkers, cm_sb = iac_plot_preprocessing(
+        model)
+    
+    ylims = ([0, 1], [19.5, 28.5], [19.5, 25.5], [20, 23.5], [None, None])
+
+    assert len(
+        flat_attr_list) == ndim, f"Number of parameters in flat_attr_list ({len(flat_attr_list)}) does not match number of parameters in chain.x ({ndim})"
+    # parameter_chain = result["chain.x"][-1:,0,:,:] #[-1:,0,:,:]
+    parameter_chain = parameter_chain.reshape(
+        (parameter_chain.shape[0] * parameter_chain.shape[1], parameter_chain.shape[2]))
+    fig, axes = simulator.run_emcee_inference(model, parameter_chain, targetParameters, targetMeasuringDevices,
+                                              startTime_test, endTime_test, stepSize_test,
+                                              assume_uncorrelated_noise=assume_uncorrelated_noise)
+    ylabels = [r"$u_v [1]$", r"$T_{c,w,in} [^\circ\!C]$", r"$T_{c,w,out} [^\circ\!C]$", r"$T_{c,a,out} [^\circ\!C]$",
+               r"$\dot{P}_f [W]$"]
+    # fig.subplots_adjust(hspace=0.3)
+    # fig.set_size_inches((15,10))
+    for ax, ylabel, ylim in zip(axes, ylabels, ylims):
+        # ax.legend(loc="center left", bbox_to_anchor=(1,0.5), prop={'size': 12})
+        # pos = ax.get_position()
+        # pos.x0 = 0.15       # for example 0.2, choose your value
+        # pos.x1 = 0.99       # for example 0.2, choose your value
+
+        # ax.set_position(pos)
+        ax.tick_params(axis='y', labelsize=10)
+        # ax.locator_params(axis='y', nbins=3)
+        ax.set_ylim(ylim)
+        ax.yaxis.set_major_locator(plt.MaxNLocator(3))
+        ax.text(-0.07, 0.5, ylabel, fontsize=14, rotation="horizontal", ha="right", transform=ax.transAxes)
+        ax.xaxis.label.set_color("black")"""
\ No newline at end of file
Index: .idea/Twin4Build.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/Twin4Build.iml b/.idea/Twin4Build.iml
new file mode 100644
--- /dev/null	(date 1716281320412)
+++ b/.idea/Twin4Build.iml	(date 1716281320412)
@@ -0,0 +1,15 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<module type="PYTHON_MODULE" version="4">
+  <component name="NewModuleRootManager">
+    <content url="file://$MODULE_DIR$">
+      <excludeFolder url="file://$MODULE_DIR$/.venv" />
+      <excludeFolder url="file://$MODULE_DIR$/venv1" />
+    </content>
+    <orderEntry type="jdk" jdkName="Python 3.10 (Twin4Build)" jdkType="Python SDK" />
+    <orderEntry type="sourceFolder" forTests="false" />
+  </component>
+  <component name="PyDocumentationSettings">
+    <option name="format" value="PLAIN" />
+    <option name="myDocStringFormat" value="Plain" />
+  </component>
+</module>
\ No newline at end of file
Index: .gitignore
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Pickle\r\n*.pickle\r\n\r\n# \r\ntwin4build/test/\r\n\r\ngenerated_files/\r\n\r\n#DMI weather files\r\n*.grib\r\n\r\n# Generated outputs e.g. plots and dot files\r\n*.png\r\n*.dot\r\n*.zip\r\n*.npz\r\n*.npy\r\n*.pt\r\n*.csv\r\n*.json\r\n\r\n# FMU\r\n*.exe\r\n*.libs\r\n*.o\r\n*.inc\r\n*.def\r\n\r\n#PyTorch\r\n*.onnx\r\n\r\n#Top folders\r\ncalibrated_folder/\r\n\r\n# Byte-compiled / optimized / DLL files\r\n__pycache__/\r\n*.py[cod]\r\n*$py.class\r\n\r\n# C extensions\r\n*.so\r\n*.c\r\n*.h\r\n*.xml\r\n*.makefile\r\n\r\n# Distribution / packaging\r\n.Python\r\nbuild/\r\ndevelop-eggs/\r\ndist/\r\ndownloads/\r\neggs/\r\n.eggs/\r\nlib/\r\nlib64/\r\nparts/\r\nsdist/\r\nvar/\r\nwheels/\r\n*.egg-info/\r\n.installed.cfg\r\n*.egg\r\nMANIFEST\r\n\r\n# PyInstaller\r\n#  Usually these files are written by a python script from a template\r\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\r\n*.manifest\r\n*.spec\r\n\r\n# Installer logs\r\npip-log.txt\r\npip-delete-this-directory.txt\r\n\r\n# Unit test / coverage reports\r\nhtmlcov/\r\n.tox/\r\n.coverage\r\n.coverage.*\r\n.cache\r\nnosetests.xml\r\ncoverage.xml\r\n*.cover\r\n.hypothesis/\r\n.pytest_cache/\r\n\r\n# Translations\r\n*.mo\r\n*.pot\r\n\r\n# Django stuff:\r\n*.log\r\nlocal_settings.py\r\ndb.sqlite3\r\n\r\n# Flask stuff:\r\ninstance/\r\n.webassets-cache\r\n\r\n# Scrapy stuff:\r\n.scrapy\r\n\r\n# Sphinx documentation\r\ndocs/_build/\r\n\r\n# PyBuilder\r\ntarget/\r\n\r\n# Jupyter Notebook\r\n.ipynb_checkpoints\r\n\r\n# pyenv\r\n.python-version\r\n\r\n# celery beat schedule file\r\ncelerybeat-schedule\r\n\r\n# SageMath parsed files\r\n*.sage.py\r\n\r\n# Environments\r\n.env\r\n.venv\r\nenv/\r\nvenv/\r\nENV/\r\nenv.bak/\r\nvenv.bak/\r\n\r\n# Spyder project settings\r\n.spyderproject\r\n.spyproject\r\n\r\n# Rope project settings\r\n.ropeproject\r\n\r\n# mkdocs documentation\r\n/site\r\n\r\n# mypy\r\n.mypy_cache/\r\n\r\n# secrets\r\nsecrets.ini\r\nconf.ini\r\nconfig.ini\r\n\r\n\r\n# fiware\r\nfiware_test.py\r\ntwin4build/api/codes/weather_forecasting/dmi_api_config.ini\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.gitignore b/.gitignore
--- a/.gitignore	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ b/.gitignore	(date 1716281320381)
@@ -123,7 +123,7 @@
 .env
 .venv
 env/
-venv/
+.venv/
 ENV/
 env.bak/
 venv.bak/
Index: setup.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from setuptools import setup\r\nimport setuptools\r\nsetup(\r\n    name=\"twin4build\",\r\n    python_requires='>3.8',\r\n    version=\"0.0.0\",\r\n    description=\"A library and framework for modeling Digital Twins of buildings.\",\r\n    url=\"https://github.com/JBjoernskov/Twin4Build\",\r\n    keywords=\"Digital Twins, Energy Modeling, Building Performance Simulation\",\r\n    author=\"Jakob Bjrnskov, SDU Center for Energy Informatics; Avneet, NEC India; Grzegorz Wiszniewski, KMD A/S\",\r\n    license=\"BSD\",\r\n    platforms=[\"Windows\", \"Linux\"],\r\n    packages=setuptools.find_packages(),\r\n    include_package_data=True,\r\n    package_data={'': ['*.pickle', '*.xlsx', \"*.pt\", \"*.fmu\", \"*.ini\"]},\r\n    install_requires=[\r\n        \"matplotlib\",\r\n        \"networkx\",\r\n        \"seaborn\",\r\n        \"pandas\",\r\n        \"torch\",\r\n        \"openpyxl\",\r\n        \"pydot\",\r\n        \"tqdm\",\r\n        \"onnx\",\r\n        \"onnxruntime\",\r\n        \"requests\",\r\n        \"pwlf\",\r\n        \"fmpy\",\r\n        \"ptemcee @ git+https://github.com/willvousden/ptemcee.git@c06ffef47eaf9e371a3d629b4d28fb3cecda56b4\",\r\n        \"scipy\",\r\n        \"fastapi\",\r\n        \"numpy\",\r\n        \"george\",\r\n        \"uvicorn\"\r\n    ],\r\n    classifiers=[\"Programming Language :: Python :: 3\"],\r\n)
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/setup.py b/setup.py
--- a/setup.py	(revision 5e9d98597fa20ff51db5017f1c122d049fc13c8b)
+++ b/setup.py	(date 1716281320396)
@@ -1,5 +1,6 @@
 from setuptools import setup
 import setuptools
+
 setup(
     name="twin4build",
     python_requires='>3.8',
diff --git a/twin4build/generated_files/plots/__init__.py b/twin4build/generated_files/plots/__init__.py
deleted file mode 100644
diff --git a/twin4build/generated_files/__init__.py b/twin4build/generated_files/__init__.py
deleted file mode 100644
diff --git a/twin4build/generated_files/.gitignore b/twin4build/generated_files/.gitignore
deleted file mode 100644
diff --git a/twin4build/generated_files/graphs/__init__.py b/twin4build/generated_files/graphs/__init__.py
deleted file mode 100644
diff --git a/twin4build/generated_files/fmu/__init__.py b/twin4build/generated_files/fmu/__init__.py
deleted file mode 100644
diff --git a/twin4build/generated_files/model_parameters/chain_logs/__init__.py b/twin4build/generated_files/model_parameters/chain_logs/__init__.py
deleted file mode 100644
diff --git a/twin4build/generated_files/cached_data/__init__.py b/twin4build/generated_files/cached_data/__init__.py
deleted file mode 100644
diff --git a/twin4build/generated_files/model_parameters/__init__.py b/twin4build/generated_files/model_parameters/__init__.py
deleted file mode 100644
