{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FzeRCkJLDcBW",
        "outputId": "01f55860-17e6-45df-a288-808c8c4995b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Google collab/OU44_zipped/space_model_batches.zip\n",
            "/content\n",
            "Unzipping training directory...\n",
            "Loaded...\n",
            "INPUT\n",
            "8\n",
            "TOTAL NUMBER OF PARAMETERS IN MODEL: 2295\n",
            "----\n",
            "\u001b[K|#---------------------------------------| 1% -- 8 -- 0.03811035305261612 -- 0 -- 0.038110357 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 16 -- 0.03811035305261612 -- 0 -- 0.038110357 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 24 -- 0.022813213989138603 -- 0 -- 0.022813214 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 32 -- 0.022813213989138603 -- 0 -- 0.022813214 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 40 -- 0.02278056927025318 -- 0 -- 0.02278057 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 48 -- 0.02278056927025318 -- 0 -- 0.02278057 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 56 -- 0.022716457024216652 -- 0 -- 0.022716457 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 64 -- 0.022716457024216652 -- 0 -- 0.022716457 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 72 -- 0.022663014009594917 -- 0 -- 0.022663016 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 80 -- 0.022663014009594917 -- 0 -- 0.022663016 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 88 -- 0.022636812180280685 -- 0 -- 0.022636814 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 96 -- 0.022636812180280685 -- 0 -- 0.022636814 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 104 -- 0.022653087973594666 -- 0 -- 0.022636814 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 112 -- 0.022653087973594666 -- 0 -- 0.022636814 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 120 -- 0.022548658773303032 -- 0 -- 0.022548659 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 128 -- 0.022548658773303032 -- 0 -- 0.022548659 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 136 -- 0.022513829171657562 -- 0 -- 0.022513827 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 144 -- 0.022513829171657562 -- 0 -- 0.022513827 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 152 -- 0.022513791918754578 -- 0 -- 0.022513792 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 160 -- 0.022513791918754578 -- 0 -- 0.022513792 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 168 -- 0.022459769621491432 -- 0 -- 0.022459773 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 176 -- 0.022459769621491432 -- 0 -- 0.022459773 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 184 -- 0.022455232217907906 -- 0 -- 0.022455232 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 192 -- 0.022455232217907906 -- 0 -- 0.022455232 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 200 -- 0.02244132198393345 -- 0 -- 0.02244132 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 208 -- 0.02244132198393345 -- 0 -- 0.02244132 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 216 -- 0.02242099866271019 -- 0 -- 0.022420997 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 224 -- 0.02242099866271019 -- 0 -- 0.022420997 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 232 -- 0.022457242012023926 -- 0 -- 0.022420997 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 240 -- 0.022457242012023926 -- 0 -- 0.022420997 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 248 -- 0.022458670660853386 -- 0 -- 0.022420997 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 256 -- 0.022458670660853386 -- 0 -- 0.022420997 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 264 -- 0.022393859922885895 -- 0 -- 0.02239386 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 272 -- 0.022393859922885895 -- 0 -- 0.02239386 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 280 -- 0.022422488778829575 -- 0 -- 0.02239386 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 288 -- 0.022422488778829575 -- 0 -- 0.02239386 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 296 -- 0.022360561415553093 -- 0 -- 0.022360561 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 304 -- 0.022360561415553093 -- 0 -- 0.022360561 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 312 -- 0.02247484028339386 -- 0 -- 0.022360561 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 320 -- 0.02247484028339386 -- 0 -- 0.022360561 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 328 -- 0.022370386868715286 -- 0 -- 0.022360561 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 336 -- 0.022370386868715286 -- 0 -- 0.022360561 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 344 -- 0.022371722385287285 -- 0 -- 0.022360561 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 352 -- 0.022371722385287285 -- 0 -- 0.022360561 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 360 -- 0.022341690957546234 -- 0 -- 0.022341691 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 368 -- 0.022341690957546234 -- 0 -- 0.022341691 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 376 -- 0.02236737124621868 -- 0 -- 0.022341691 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 384 -- 0.02236737124621868 -- 0 -- 0.022341691 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 392 -- 0.022321345284581184 -- 0 -- 0.022321345 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 400 -- 0.022321345284581184 -- 0 -- 0.022321345 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 408 -- 0.02243313007056713 -- 0 -- 0.022321345 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 416 -- 0.02243313007056713 -- 0 -- 0.022321345 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 424 -- 0.02237679250538349 -- 0 -- 0.022321345 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 432 -- 0.02237679250538349 -- 0 -- 0.022321345 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 440 -- 0.02235652320086956 -- 0 -- 0.022321345 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 448 -- 0.02235652320086956 -- 0 -- 0.022321345 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 456 -- 0.02229984477162361 -- 0 -- 0.022299845 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 464 -- 0.02229984477162361 -- 0 -- 0.022299845 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 472 -- 0.02229771763086319 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 480 -- 0.02229771763086319 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 488 -- 0.022314010187983513 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 496 -- 0.022314010187983513 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 504 -- 0.02246537245810032 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 512 -- 0.02246537245810032 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 520 -- 0.02241179719567299 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 528 -- 0.02241179719567299 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 536 -- 0.022501232102513313 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 544 -- 0.022501232102513313 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 552 -- 0.02234603464603424 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 560 -- 0.02234603464603424 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 568 -- 0.022439250722527504 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 576 -- 0.022439250722527504 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 584 -- 0.02235046774148941 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 592 -- 0.02235046774148941 -- 0 -- 0.022297718 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 600 -- 0.022289616987109184 -- 0 -- 0.022289617 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 608 -- 0.022289616987109184 -- 0 -- 0.022289617 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 616 -- 0.022265082225203514 -- 0 -- 0.02226508 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 624 -- 0.022265082225203514 -- 0 -- 0.02226508 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 632 -- 0.022257866337895393 -- 0 -- 0.022257866 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 640 -- 0.022257866337895393 -- 0 -- 0.022257866 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 648 -- 0.02230600081384182 -- 0 -- 0.022257866 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 656 -- 0.02230600081384182 -- 0 -- 0.022257866 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 664 -- 0.022324038669466972 -- 0 -- 0.022257866 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 672 -- 0.022324038669466972 -- 0 -- 0.022257866 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 680 -- 0.02222958579659462 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 688 -- 0.02222958579659462 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 696 -- 0.02227194793522358 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 704 -- 0.02227194793522358 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 712 -- 0.022513456642627716 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 720 -- 0.022513456642627716 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 728 -- 0.02236871048808098 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 736 -- 0.02236871048808098 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 744 -- 0.02238422818481922 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 752 -- 0.02238422818481922 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 760 -- 0.022407490760087967 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 768 -- 0.022407490760087967 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 776 -- 0.022374026477336884 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 784 -- 0.022374026477336884 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 792 -- 0.022313939407467842 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 800 -- 0.022313939407467842 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 808 -- 0.022328175604343414 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 816 -- 0.022328175604343414 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 824 -- 0.022296175360679626 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 832 -- 0.022296175360679626 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 840 -- 0.022363483905792236 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 848 -- 0.022363483905792236 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 856 -- 0.02225254476070404 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 864 -- 0.02225254476070404 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 872 -- 0.022240182384848595 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 880 -- 0.022240182384848595 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 888 -- 0.022243307903409004 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 896 -- 0.022243307903409004 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 904 -- 0.02224935032427311 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 912 -- 0.02224935032427311 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 920 -- 0.022235214710235596 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 928 -- 0.022235214710235596 -- 0 -- 0.022229588 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 936 -- 0.022139133885502815 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 944 -- 0.022139133885502815 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 952 -- 0.02225779928267002 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 960 -- 0.02225779928267002 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 968 -- 0.02233213186264038 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 976 -- 0.02233213186264038 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 984 -- 0.022236492484807968 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 992 -- 0.022236492484807968 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1000 -- 0.022349493578076363 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1008 -- 0.022349493578076363 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1016 -- 0.02222481556236744 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1024 -- 0.02222481556236744 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1032 -- 0.022272545844316483 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1040 -- 0.022272545844316483 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1048 -- 0.022273119539022446 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1056 -- 0.022273119539022446 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1064 -- 0.022191356867551804 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1072 -- 0.022191356867551804 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1080 -- 0.022331194952130318 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1088 -- 0.022331194952130318 -- 0 -- 0.022139138 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1096 -- 0.022136010229587555 -- 0 -- 0.022136008 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1104 -- 0.022136010229587555 -- 0 -- 0.022136008 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1112 -- 0.022117532789707184 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1120 -- 0.022117532789707184 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1128 -- 0.02225804515182972 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1136 -- 0.02225804515182972 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1144 -- 0.022314921021461487 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1152 -- 0.022314921021461487 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1160 -- 0.02218092978000641 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1168 -- 0.02218092978000641 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1176 -- 0.022278273478150368 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1184 -- 0.022278273478150368 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1192 -- 0.02230880782008171 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1200 -- 0.02230880782008171 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1208 -- 0.02219597063958645 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1216 -- 0.02219597063958645 -- 0 -- 0.022117533 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1224 -- 0.022114070132374763 -- 0 -- 0.02211407 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1232 -- 0.022114070132374763 -- 0 -- 0.02211407 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1240 -- 0.022175896912813187 -- 0 -- 0.02211407 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1248 -- 0.022175896912813187 -- 0 -- 0.02211407 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1256 -- 0.022231601178646088 -- 0 -- 0.02211407 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1264 -- 0.022231601178646088 -- 0 -- 0.02211407 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1272 -- 0.022099031135439873 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1280 -- 0.022099031135439873 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1288 -- 0.0221044160425663 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1296 -- 0.0221044160425663 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1304 -- 0.022131485864520073 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1312 -- 0.022131485864520073 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1320 -- 0.02219340018928051 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1328 -- 0.02219340018928051 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1336 -- 0.02225177362561226 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1344 -- 0.02225177362561226 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1352 -- 0.022402502596378326 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1360 -- 0.022402502596378326 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1368 -- 0.022230733186006546 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1376 -- 0.022230733186006546 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1384 -- 0.022263778373599052 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1392 -- 0.022263778373599052 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1400 -- 0.02218073606491089 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1408 -- 0.02218073606491089 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1416 -- 0.02221485786139965 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1424 -- 0.02221485786139965 -- 0 -- 0.022099031 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1432 -- 0.022073976695537567 -- 0 -- 0.022073973 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1440 -- 0.022073976695537567 -- 0 -- 0.022073973 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1448 -- 0.02226930484175682 -- 0 -- 0.022073973 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1456 -- 0.02226930484175682 -- 0 -- 0.022073973 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1464 -- 0.02203967794775963 -- 0 -- 0.022039678 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1472 -- 0.02203967794775963 -- 0 -- 0.022039678 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1480 -- 0.022051505744457245 -- 0 -- 0.022039678 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1488 -- 0.022051505744457245 -- 0 -- 0.022039678 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1496 -- 0.022035079076886177 -- 0 -- 0.02203508 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1504 -- 0.022035079076886177 -- 0 -- 0.02203508 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1512 -- 0.022151391953229904 -- 0 -- 0.02203508 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1520 -- 0.022151391953229904 -- 0 -- 0.02203508 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1528 -- 0.0219833105802536 -- 0 -- 0.021983312 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1536 -- 0.0219833105802536 -- 0 -- 0.021983312 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1544 -- 0.022353358566761017 -- 0 -- 0.021983312 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1552 -- 0.022353358566761017 -- 0 -- 0.021983312 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1560 -- 0.021955834701657295 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1568 -- 0.021955834701657295 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1576 -- 0.022056158632040024 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1584 -- 0.022056158632040024 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1592 -- 0.022085504606366158 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1600 -- 0.022085504606366158 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1608 -- 0.02232452481985092 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1616 -- 0.02232452481985092 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1624 -- 0.02229023166000843 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1632 -- 0.02229023166000843 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1640 -- 0.021977916359901428 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1648 -- 0.021977916359901428 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1656 -- 0.02221408113837242 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1664 -- 0.02221408113837242 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1672 -- 0.022409677505493164 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1680 -- 0.022409677505493164 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1688 -- 0.022099005058407784 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1696 -- 0.022099005058407784 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1704 -- 0.0221481304615736 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1712 -- 0.0221481304615736 -- 0 -- 0.021955837 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1720 -- 0.021950891241431236 -- 0 -- 0.02195089 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1728 -- 0.021950891241431236 -- 0 -- 0.02195089 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1736 -- 0.02214011363685131 -- 0 -- 0.02195089 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1744 -- 0.02214011363685131 -- 0 -- 0.02195089 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1752 -- 0.022015321999788284 -- 0 -- 0.02195089 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1760 -- 0.022015321999788284 -- 0 -- 0.02195089 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1768 -- 0.02203306369483471 -- 0 -- 0.02195089 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1776 -- 0.02203306369483471 -- 0 -- 0.02195089 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1784 -- 0.02189384214580059 -- 0 -- 0.021893842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1792 -- 0.02189384214580059 -- 0 -- 0.021893842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1800 -- 0.022011591121554375 -- 0 -- 0.021893842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1808 -- 0.022011591121554375 -- 0 -- 0.021893842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1816 -- 0.02180405706167221 -- 0 -- 0.021804057 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1824 -- 0.02180405706167221 -- 0 -- 0.021804057 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1832 -- 0.021777568385004997 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1840 -- 0.021777568385004997 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1848 -- 0.022006310522556305 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1856 -- 0.022006310522556305 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1864 -- 0.022207053378224373 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1872 -- 0.022207053378224373 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1880 -- 0.022161567583680153 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1888 -- 0.022161567583680153 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1896 -- 0.02201513573527336 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1904 -- 0.02201513573527336 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1912 -- 0.021790875121951103 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1920 -- 0.021790875121951103 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1928 -- 0.021923715248703957 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1936 -- 0.021923715248703957 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1944 -- 0.022063402459025383 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1952 -- 0.022063402459025383 -- 0 -- 0.021777568 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1960 -- 0.02177398093044758 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1968 -- 0.02177398093044758 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1976 -- 0.021811900660395622 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1984 -- 0.021811900660395622 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 1992 -- 0.02189488895237446 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2000 -- 0.02189488895237446 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2008 -- 0.021789101883769035 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2016 -- 0.021789101883769035 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2024 -- 0.021817373111844063 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2032 -- 0.021817373111844063 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2040 -- 0.02220899611711502 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2048 -- 0.02220899611711502 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2056 -- 0.022194428369402885 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2064 -- 0.022194428369402885 -- 0 -- 0.02177398 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2072 -- 0.021754557266831398 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2080 -- 0.021754557266831398 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2088 -- 0.021996106952428818 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2096 -- 0.021996106952428818 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2104 -- 0.0221438966691494 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2112 -- 0.0221438966691494 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2120 -- 0.022108769044280052 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2128 -- 0.022108769044280052 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2136 -- 0.022031139582395554 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2144 -- 0.022031139582395554 -- 0 -- 0.021754555 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2152 -- 0.021734891459345818 -- 0 -- 0.021734893 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2160 -- 0.021734891459345818 -- 0 -- 0.021734893 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2168 -- 0.02161678485572338 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2176 -- 0.02161678485572338 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2184 -- 0.021763522177934647 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2192 -- 0.021763522177934647 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2200 -- 0.02184821292757988 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2208 -- 0.02184821292757988 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2216 -- 0.021956579759716988 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2224 -- 0.021956579759716988 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2232 -- 0.022053176537156105 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2240 -- 0.022053176537156105 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2248 -- 0.021903205662965775 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2256 -- 0.021903205662965775 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2264 -- 0.021953044459223747 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2272 -- 0.021953044459223747 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2280 -- 0.021830184385180473 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2288 -- 0.021830184385180473 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2296 -- 0.021831126883625984 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2304 -- 0.021831126883625984 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2312 -- 0.021796736866235733 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2320 -- 0.021796736866235733 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2328 -- 0.021726790815591812 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2336 -- 0.021726790815591812 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2344 -- 0.02227691560983658 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2352 -- 0.02227691560983658 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2360 -- 0.021727729588747025 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2368 -- 0.021727729588747025 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2376 -- 0.02178305760025978 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2384 -- 0.02178305760025978 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2392 -- 0.02201373316347599 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2400 -- 0.02201373316347599 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2408 -- 0.02185717225074768 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2416 -- 0.02185717225074768 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2424 -- 0.021744495257735252 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2432 -- 0.021744495257735252 -- 0 -- 0.021616787 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2440 -- 0.021528219804167747 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2448 -- 0.021528219804167747 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2456 -- 0.021595938131213188 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2464 -- 0.021595938131213188 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2472 -- 0.021726176142692566 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2480 -- 0.021726176142692566 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2488 -- 0.02181394211947918 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2496 -- 0.02181394211947918 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2504 -- 0.02171458676457405 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2512 -- 0.02171458676457405 -- 0 -- 0.021528222 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2520 -- 0.021516649052500725 -- 0 -- 0.021516649 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2528 -- 0.021516649052500725 -- 0 -- 0.021516649 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2536 -- 0.02163599245250225 -- 0 -- 0.021516649 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2544 -- 0.02163599245250225 -- 0 -- 0.021516649 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2552 -- 0.021496431902050972 -- 0 -- 0.021496432 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2560 -- 0.021496431902050972 -- 0 -- 0.021496432 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2568 -- 0.021373005583882332 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2576 -- 0.021373005583882332 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2584 -- 0.021683624014258385 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2592 -- 0.021683624014258385 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2600 -- 0.021593794226646423 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2608 -- 0.021593794226646423 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2616 -- 0.022105444222688675 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2624 -- 0.022105444222688675 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2632 -- 0.021564798429608345 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2640 -- 0.021564798429608345 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2648 -- 0.021539844572544098 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2656 -- 0.021539844572544098 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2664 -- 0.02161368541419506 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2672 -- 0.02161368541419506 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2680 -- 0.021530549973249435 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2688 -- 0.021530549973249435 -- 0 -- 0.021373006 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2696 -- 0.021310381591320038 -- 0 -- 0.02131038 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2704 -- 0.021310381591320038 -- 0 -- 0.02131038 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2712 -- 0.021280841901898384 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2720 -- 0.021280841901898384 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2728 -- 0.02151065319776535 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2736 -- 0.02151065319776535 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2744 -- 0.021437447518110275 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2752 -- 0.021437447518110275 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2760 -- 0.021389015018939972 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2768 -- 0.021389015018939972 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2776 -- 0.0214573722332716 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2784 -- 0.0214573722332716 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2792 -- 0.02149171754717827 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2800 -- 0.02149171754717827 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2808 -- 0.02139306627213955 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2816 -- 0.02139306627213955 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2824 -- 0.021423764526844025 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2832 -- 0.021423764526844025 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2840 -- 0.021498756483197212 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2848 -- 0.021498756483197212 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2856 -- 0.02134946919977665 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2864 -- 0.02134946919977665 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2872 -- 0.021351469680666924 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2880 -- 0.021351469680666924 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2888 -- 0.021576764062047005 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2896 -- 0.021576764062047005 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2904 -- 0.02184196002781391 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2912 -- 0.02184196002781391 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2920 -- 0.02149571292102337 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2928 -- 0.02149571292102337 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2936 -- 0.02154959924519062 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2944 -- 0.02154959924519062 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2952 -- 0.021409841254353523 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2960 -- 0.021409841254353523 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2968 -- 0.021399788558483124 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2976 -- 0.021399788558483124 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2984 -- 0.021533427760004997 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 2992 -- 0.021533427760004997 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3000 -- 0.02139158360660076 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3008 -- 0.02139158360660076 -- 0 -- 0.021280842 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3016 -- 0.021126896142959595 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3024 -- 0.021126896142959595 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3032 -- 0.021151376888155937 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3040 -- 0.021151376888155937 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3048 -- 0.021903369575738907 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3056 -- 0.021903369575738907 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3064 -- 0.021168414503335953 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3072 -- 0.021168414503335953 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3080 -- 0.02120538428425789 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3088 -- 0.02120538428425789 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3096 -- 0.021522479131817818 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3104 -- 0.021522479131817818 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3112 -- 0.021350296214222908 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3120 -- 0.021350296214222908 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3128 -- 0.021139221265912056 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3136 -- 0.021139221265912056 -- 0 -- 0.021126896 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3144 -- 0.021063970401883125 -- 0 -- 0.021063969 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3152 -- 0.021063970401883125 -- 0 -- 0.021063969 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3160 -- 0.021060949191451073 -- 0 -- 0.02106095 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3168 -- 0.021060949191451073 -- 0 -- 0.02106095 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3176 -- 0.021247785538434982 -- 0 -- 0.02106095 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3184 -- 0.021247785538434982 -- 0 -- 0.02106095 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3192 -- 0.021011702716350555 -- 0 -- 0.021011703 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3200 -- 0.021011702716350555 -- 0 -- 0.021011703 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3208 -- 0.021116485819220543 -- 0 -- 0.021011703 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3216 -- 0.021116485819220543 -- 0 -- 0.021011703 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3224 -- 0.0209013894200325 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3232 -- 0.0209013894200325 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3240 -- 0.021157177165150642 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3248 -- 0.021157177165150642 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3256 -- 0.020986855030059814 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3264 -- 0.020986855030059814 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3272 -- 0.021264098584651947 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3280 -- 0.021264098584651947 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3288 -- 0.021537212654948235 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3296 -- 0.021537212654948235 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3304 -- 0.021075161173939705 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3312 -- 0.021075161173939705 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3320 -- 0.02160526253283024 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3328 -- 0.02160526253283024 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3336 -- 0.021524010226130486 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3344 -- 0.021524010226130486 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3352 -- 0.02129811979830265 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3360 -- 0.02129811979830265 -- 0 -- 0.020901391 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3368 -- 0.020831920206546783 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3376 -- 0.020831920206546783 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3384 -- 0.021520640701055527 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3392 -- 0.021520640701055527 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3400 -- 0.021419692784547806 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3408 -- 0.021419692784547806 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3416 -- 0.021554376929998398 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3424 -- 0.021554376929998398 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3432 -- 0.021056847646832466 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3440 -- 0.021056847646832466 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3448 -- 0.02126706764101982 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3456 -- 0.02126706764101982 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3464 -- 0.02124154567718506 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3472 -- 0.02124154567718506 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3480 -- 0.02085801027715206 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3488 -- 0.02085801027715206 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3496 -- 0.021258264780044556 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3504 -- 0.021258264780044556 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3512 -- 0.020892005413770676 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3520 -- 0.020892005413770676 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3528 -- 0.02107943966984749 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3536 -- 0.02107943966984749 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3544 -- 0.020993195474147797 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3552 -- 0.020993195474147797 -- 0 -- 0.02083192 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3560 -- 0.02061416581273079 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3568 -- 0.02061416581273079 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3576 -- 0.021058954298496246 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3584 -- 0.021058954298496246 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3592 -- 0.02110661379992962 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3600 -- 0.02110661379992962 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3608 -- 0.02085515297949314 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3616 -- 0.02085515297949314 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3624 -- 0.02086787298321724 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3632 -- 0.02086787298321724 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3640 -- 0.020923545584082603 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3648 -- 0.020923545584082603 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3656 -- 0.021276675164699554 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3664 -- 0.021276675164699554 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3672 -- 0.02128445915877819 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3680 -- 0.02128445915877819 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3688 -- 0.020970214158296585 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3696 -- 0.020970214158296585 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3704 -- 0.020717967301607132 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3712 -- 0.020717967301607132 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3720 -- 0.020854420959949493 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3728 -- 0.020854420959949493 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3736 -- 0.02078022062778473 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3744 -- 0.02078022062778473 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3752 -- 0.020757438614964485 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3760 -- 0.020757438614964485 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3768 -- 0.020647220313549042 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3776 -- 0.020647220313549042 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3784 -- 0.021017057821154594 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3792 -- 0.021017057821154594 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3800 -- 0.02122143656015396 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3808 -- 0.02122143656015396 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3816 -- 0.020955398678779602 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3824 -- 0.020955398678779602 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3832 -- 0.020728446543216705 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3840 -- 0.020728446543216705 -- 0 -- 0.020614168 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3848 -- 0.020605595782399178 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3856 -- 0.020605595782399178 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3864 -- 0.020937757566571236 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3872 -- 0.020937757566571236 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3880 -- 0.02086728624999523 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3888 -- 0.02086728624999523 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3896 -- 0.021052291616797447 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3904 -- 0.021052291616797447 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3912 -- 0.021109363064169884 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3920 -- 0.021109363064169884 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3928 -- 0.020930824801325798 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3936 -- 0.020930824801325798 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3944 -- 0.021029900759458542 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3952 -- 0.021029900759458542 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3960 -- 0.021095357835292816 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3968 -- 0.021095357835292816 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3976 -- 0.020927859470248222 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3984 -- 0.020927859470248222 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 3992 -- 0.021010739728808403 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4000 -- 0.021010739728808403 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4008 -- 0.021505022421479225 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4016 -- 0.021505022421479225 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4024 -- 0.02082785777747631 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4032 -- 0.02082785777747631 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4040 -- 0.02085600234568119 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4048 -- 0.02085600234568119 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4056 -- 0.02078678086400032 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4064 -- 0.02078678086400032 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4072 -- 0.02098284289240837 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4080 -- 0.02098284289240837 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4088 -- 0.020817993208765984 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4096 -- 0.020817993208765984 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4104 -- 0.021193353459239006 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4112 -- 0.021193353459239006 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4120 -- 0.020816294476389885 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4128 -- 0.020816294476389885 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4136 -- 0.020765773952007294 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4144 -- 0.020765773952007294 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4152 -- 0.020857233554124832 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4160 -- 0.020857233554124832 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4168 -- 0.020860059186816216 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4176 -- 0.020860059186816216 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4184 -- 0.02091308869421482 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4192 -- 0.02091308869421482 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4200 -- 0.021336065605282784 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4208 -- 0.021336065605282784 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4216 -- 0.02117554098367691 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4224 -- 0.02117554098367691 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4232 -- 0.021318838000297546 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4240 -- 0.021318838000297546 -- 0 -- 0.020605596 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4248 -- 0.020556548610329628 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4256 -- 0.020556548610329628 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4264 -- 0.020816422998905182 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4272 -- 0.020816422998905182 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4280 -- 0.02089003100991249 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4288 -- 0.02089003100991249 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4296 -- 0.020842351019382477 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4304 -- 0.020842351019382477 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4312 -- 0.020885316655039787 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4320 -- 0.020885316655039787 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4328 -- 0.020559735596179962 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4336 -- 0.020559735596179962 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4344 -- 0.02084599994122982 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4352 -- 0.02084599994122982 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4360 -- 0.020742591470479965 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4368 -- 0.020742591470479965 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4376 -- 0.020674744620919228 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4384 -- 0.020674744620919228 -- 0 -- 0.020556547 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4392 -- 0.020472602918744087 -- 0 -- 0.020472603 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4400 -- 0.020472602918744087 -- 0 -- 0.020472603 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4408 -- 0.02047317661345005 -- 0 -- 0.020472603 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4416 -- 0.02047317661345005 -- 0 -- 0.020472603 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4424 -- 0.020260710269212723 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4432 -- 0.020260710269212723 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4440 -- 0.02076995186507702 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4448 -- 0.02076995186507702 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4456 -- 0.020534582436084747 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4464 -- 0.020534582436084747 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4472 -- 0.02061227709054947 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4480 -- 0.02061227709054947 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4488 -- 0.02040131576359272 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4496 -- 0.02040131576359272 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4504 -- 0.02074146457016468 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4512 -- 0.02074146457016468 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4520 -- 0.020326046273112297 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4528 -- 0.020326046273112297 -- 0 -- 0.020260708 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4536 -- 0.02021358720958233 -- 0 -- 0.020213585 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4544 -- 0.02021358720958233 -- 0 -- 0.020213585 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4552 -- 0.020538227632641792 -- 0 -- 0.020213585 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4560 -- 0.020538227632641792 -- 0 -- 0.020213585 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4568 -- 0.020506342872977257 -- 0 -- 0.020213585 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4576 -- 0.020506342872977257 -- 0 -- 0.020213585 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4584 -- 0.020585859194397926 -- 0 -- 0.020213585 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4592 -- 0.020585859194397926 -- 0 -- 0.020213585 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4600 -- 0.020176520571112633 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4608 -- 0.020176520571112633 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4616 -- 0.020808173343539238 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4624 -- 0.020808173343539238 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4632 -- 0.020889027044177055 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4640 -- 0.020889027044177055 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4648 -- 0.020772181451320648 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4656 -- 0.020772181451320648 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4664 -- 0.020731618627905846 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4672 -- 0.020731618627905846 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4680 -- 0.020464522764086723 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4688 -- 0.020464522764086723 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4696 -- 0.020442159846425056 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4704 -- 0.020442159846425056 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4712 -- 0.020611805841326714 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4720 -- 0.020611805841326714 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4728 -- 0.02075508050620556 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4736 -- 0.02075508050620556 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4744 -- 0.0206940695643425 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4752 -- 0.0206940695643425 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4760 -- 0.020838532596826553 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4768 -- 0.020838532596826553 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4776 -- 0.020557545125484467 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4784 -- 0.020557545125484467 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4792 -- 0.02060411497950554 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4800 -- 0.02060411497950554 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4808 -- 0.020601248368620872 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4816 -- 0.020601248368620872 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4824 -- 0.02044558897614479 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4832 -- 0.02044558897614479 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4840 -- 0.02030082233250141 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4848 -- 0.02030082233250141 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4856 -- 0.020231734961271286 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4864 -- 0.020231734961271286 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4872 -- 0.020648809149861336 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4880 -- 0.020648809149861336 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4888 -- 0.02083490416407585 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4896 -- 0.02083490416407585 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4904 -- 0.020546799525618553 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4912 -- 0.020546799525618553 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4920 -- 0.02042361907660961 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4928 -- 0.02042361907660961 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4936 -- 0.020980821922421455 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4944 -- 0.020980821922421455 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4952 -- 0.020672133192420006 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4960 -- 0.020672133192420006 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4968 -- 0.02061769925057888 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4976 -- 0.02061769925057888 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4984 -- 0.02043524570763111 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 4992 -- 0.02043524570763111 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5000 -- 0.02018113248050213 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5008 -- 0.02018113248050213 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5016 -- 0.020444409921765327 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5024 -- 0.020444409921765327 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5032 -- 0.02051733061671257 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5040 -- 0.02051733061671257 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5048 -- 0.020178992301225662 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5056 -- 0.020178992301225662 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5064 -- 0.020875917747616768 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5072 -- 0.020875917747616768 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5080 -- 0.020565973594784737 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5088 -- 0.020565973594784737 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5096 -- 0.020475896075367928 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5104 -- 0.020475896075367928 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5112 -- 0.020314285531640053 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5120 -- 0.020314285531640053 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5128 -- 0.02032536454498768 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5136 -- 0.02032536454498768 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5144 -- 0.020408127456903458 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5152 -- 0.020408127456903458 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5160 -- 0.020522341132164 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5168 -- 0.020522341132164 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5176 -- 0.02087724395096302 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5184 -- 0.02087724395096302 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5192 -- 0.02095385640859604 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5200 -- 0.02095385640859604 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5208 -- 0.021173156797885895 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5216 -- 0.021173156797885895 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5224 -- 0.020489564165472984 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5232 -- 0.020489564165472984 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5240 -- 0.02045760303735733 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5248 -- 0.02045760303735733 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5256 -- 0.02114930748939514 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5264 -- 0.02114930748939514 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5272 -- 0.021235279738903046 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5280 -- 0.021235279738903046 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5288 -- 0.020907456055283546 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5296 -- 0.020907456055283546 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5304 -- 0.02027863822877407 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5312 -- 0.02027863822877407 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5320 -- 0.020310059189796448 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5328 -- 0.020310059189796448 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5336 -- 0.020562825724482536 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5344 -- 0.020562825724482536 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5352 -- 0.020253358408808708 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5360 -- 0.020253358408808708 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5368 -- 0.020182494074106216 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5376 -- 0.020182494074106216 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5384 -- 0.020652899518609047 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5392 -- 0.020652899518609047 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5400 -- 0.020790603011846542 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5408 -- 0.020790603011846542 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5416 -- 0.020478440448641777 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5424 -- 0.020478440448641777 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5432 -- 0.020844517275691032 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5440 -- 0.020844517275691032 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5448 -- 0.020910760387778282 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5456 -- 0.020910760387778282 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5464 -- 0.02079964242875576 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5472 -- 0.02079964242875576 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5480 -- 0.020640728995203972 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5488 -- 0.020640728995203972 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5496 -- 0.02054445631802082 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5504 -- 0.02054445631802082 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5512 -- 0.020478229969739914 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5520 -- 0.020478229969739914 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5528 -- 0.02030370943248272 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5536 -- 0.02030370943248272 -- 0 -- 0.02017652 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5544 -- 0.020172102376818657 -- 0 -- 0.020172102 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5552 -- 0.020172102376818657 -- 0 -- 0.020172102 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5560 -- 0.0204934049397707 -- 0 -- 0.020172102 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5568 -- 0.0204934049397707 -- 0 -- 0.020172102 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5576 -- 0.020411962643265724 -- 0 -- 0.020172102 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5584 -- 0.020411962643265724 -- 0 -- 0.020172102 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5592 -- 0.020152529701590538 -- 0 -- 0.02015253 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5600 -- 0.020152529701590538 -- 0 -- 0.02015253 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5608 -- 0.020590713247656822 -- 0 -- 0.02015253 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5616 -- 0.020590713247656822 -- 0 -- 0.02015253 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5624 -- 0.020320020616054535 -- 0 -- 0.02015253 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5632 -- 0.020320020616054535 -- 0 -- 0.02015253 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5640 -- 0.020302392542362213 -- 0 -- 0.02015253 ----\n",
            "\u001b[K|#---------------------------------------| 1% -- 5648 -- 0.020302392542362213 -- 0 -- 0.02015253 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bb68dd560194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-bb68dd560194>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;31m# self.batch_idx_test += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-bb68dd560194>\u001b[0m in \u001b[0;36mtest_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_it_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_batch_into_GPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_idx_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-bb68dd560194>\u001b[0m in \u001b[0;36mtest_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;31m################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mloss_dT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dT_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0;31m# loss = loss_T + loss_dT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_dT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-bb68dd560194>\u001b[0m in \u001b[0;36mloss_penalized\u001b[0;34m(output, target, x, input)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# loss_SPACEHEATER[bool_arr_constant] = torch.relu(x_SPACEHEATER_output[bool_arr_constant])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     grad_SPACEHEATER = torch.autograd.grad(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mx_SPACEHEATER_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_SPACEHEATER_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_SPACEHEATER_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# %%file main.py\n",
        "\"\"\"\n",
        "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!pip install torchvision\n",
        "!pip install torch==1.4.0\n",
        "!pip install torchaudio==0.4.0\n",
        "%matplotlib inline\n",
        "!python pytorch-xla-env-setup.py --version $VERSION\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# !pip install torch_intermediate_layer_getter\n",
        "# from torch_intermediate_layer_getter import IntermediateLayerGetter as MidGetter\n",
        "\n",
        "\n",
        "# !pip install line_profiler\n",
        "# %load_ext line_profiler\n",
        "\n",
        "#standard\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import math\n",
        "import sys\n",
        "\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "\n",
        "\n",
        "#torch\n",
        "import torch\n",
        "import torch.jit as jit\n",
        "from torch import Tensor\n",
        "import torchvision\n",
        "\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import pickle\n",
        "\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "\n",
        "# !pip install py-heat-magic\n",
        "# %load_ext heat\n",
        "\n",
        "\n",
        "\n",
        "# !pip install memory_profiler\n",
        "# %load_ext memory_profiler\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "\n",
        "\n",
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def loss_penalized(output, target, x, input):\n",
        "    (x_OUTDOORTEMPERATURE_input,\n",
        "        x_RADIATION_input,\n",
        "        x_SPACEHEATER_input,\n",
        "        x_VENTILATION_input) = input\n",
        "\n",
        "    \n",
        "\n",
        "    (x_OUTDOORTEMPERATURE_output, x_RADIATION_output, x_SPACEHEATER_output, x_VENTILATION_output) = x\n",
        "\n",
        "\n",
        "    tol = 1e-8\n",
        "\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_output = torch.zeros(x_OUTDOORTEMPERATURE_output.shape).cuda()\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_output[:,1:] = x_OUTDOORTEMPERATURE_output[:,1:]-x_OUTDOORTEMPERATURE_output[:,:-1]\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_input_0 = torch.zeros(x_OUTDOORTEMPERATURE_output.shape).cuda()\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_input_0[:,1:,0] = x_OUTDOORTEMPERATURE_input[:,1:,0]-x_OUTDOORTEMPERATURE_input[:,:-1,0]\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_input_1 = torch.zeros(x_OUTDOORTEMPERATURE_output.shape).cuda()\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_input_1[:,1:,0] = x_OUTDOORTEMPERATURE_input[:,1:,1]-x_OUTDOORTEMPERATURE_input[:,:-1,1]\n",
        "    # bool_arr_grad_neg = torch.logical_and(DELTA_x_OUTDOORTEMPERATURE_input_0 > -tol, DELTA_x_OUTDOORTEMPERATURE_input_1 < tol)\n",
        "    # bool_arr_grad_pos = torch.logical_and(DELTA_x_OUTDOORTEMPERATURE_input_0 < tol, DELTA_x_OUTDOORTEMPERATURE_input_1 > -tol)\n",
        "    # loss_OUTDOORTEMPERATURE = torch.zeros(x_OUTDOORTEMPERATURE_output.shape).cuda()\n",
        "    # loss_OUTDOORTEMPERATURE[bool_arr_grad_neg] = torch.relu(DELTA_x_OUTDOORTEMPERATURE_output[bool_arr_grad_neg])\n",
        "    # loss_OUTDOORTEMPERATURE[bool_arr_grad_pos] = torch.relu(-DELTA_x_OUTDOORTEMPERATURE_output[bool_arr_grad_pos])\n",
        "\n",
        "\n",
        "    grad_OUTDOORTEMPERATURE = torch.autograd.grad(\n",
        "            x_OUTDOORTEMPERATURE_output, x_OUTDOORTEMPERATURE_input,\n",
        "            grad_outputs=torch.ones_like(x_OUTDOORTEMPERATURE_output),\n",
        "            retain_graph=True,\n",
        "            create_graph=True\n",
        "        )[0]\n",
        "    loss_OUTDOORTEMPERATURE_0 = torch.relu(grad_OUTDOORTEMPERATURE[:,:,0].unsqueeze(2))\n",
        "    loss_OUTDOORTEMPERATURE_1 = torch.relu(-grad_OUTDOORTEMPERATURE[:,:,1].unsqueeze(2))\n",
        "\n",
        "\n",
        "    # loss_RADIATION = torch.zeros(x_RADIATION_output.shape).to(DEVICE)\n",
        "    # bool_arr = x_RADIATION_input[:,:,0] < tol\n",
        "    # loss_RADIATION[bool_arr] = torch.abs(x_RADIATION_output[bool_arr])\n",
        "    # grad_RADIATION = torch.autograd.grad(\n",
        "    #         x_RADIATION_output, x_RADIATION_input,\n",
        "    #         grad_outputs=torch.ones_like(x_RADIATION_output),\n",
        "    #         retain_graph=True,\n",
        "    #         create_graph=True\n",
        "    #     )[0]\n",
        "    # loss_RADIATION_0 = torch.relu(grad_RADIATION[:,:,0].unsqueeze(2))\n",
        "\n",
        "    DELTA_x_SPACEHEATER_output = torch.zeros(x_SPACEHEATER_output.shape).to(DEVICE)\n",
        "    DELTA_x_SPACEHEATER_output[:,1:] = x_SPACEHEATER_output[:,1:]-x_SPACEHEATER_output[:,:-1]\n",
        "    bool_arr_grad = torch.logical_and(x_SPACEHEATER_input[:,:,1] < tol, x_SPACEHEATER_output[:,:,0] > tol)\n",
        "    # bool_arr_constant = torch.logical_and(torch.abs(DELTA_x_SPACEHEATER_output[:,:,0]) < tol, x_SPACEHEATER_input[:,:,1] < tol)\n",
        "    loss_SPACEHEATER = torch.zeros(x_SPACEHEATER_output.shape).to(DEVICE)\n",
        "    loss_SPACEHEATER[bool_arr_grad] = torch.relu(DELTA_x_SPACEHEATER_output[bool_arr_grad])\n",
        "    # loss_SPACEHEATER[bool_arr_constant] = torch.relu(x_SPACEHEATER_output[bool_arr_constant])\n",
        "\n",
        "    grad_SPACEHEATER = torch.autograd.grad(\n",
        "            x_SPACEHEATER_output, x_SPACEHEATER_input,\n",
        "            grad_outputs=torch.ones_like(x_SPACEHEATER_output),\n",
        "            retain_graph=True,\n",
        "            create_graph=True\n",
        "        )[0]\n",
        "    loss_SPACEHEATER_0 = torch.relu(grad_SPACEHEATER[:,:,0].unsqueeze(2))\n",
        "    loss_SPACEHEATER_1 = torch.relu(-grad_SPACEHEATER[:,:,1].unsqueeze(2))\n",
        "    loss_SPACEHEATER_2 = torch.relu(-grad_SPACEHEATER[:,:,2].unsqueeze(2))\n",
        "\n",
        "\n",
        "\n",
        "    loss_VENTILATION = torch.zeros(x_VENTILATION_output.shape).to(DEVICE)\n",
        "    bool_arr = x_VENTILATION_input[:,:,1] < tol\n",
        "    loss_VENTILATION[bool_arr] = torch.abs(x_VENTILATION_output[bool_arr])\n",
        "\n",
        "    grad_VENTILATION = torch.autograd.grad(\n",
        "            x_VENTILATION_output, x_VENTILATION_input,\n",
        "            grad_outputs=torch.ones_like(x_VENTILATION_output),\n",
        "            retain_graph=True,\n",
        "            create_graph=True\n",
        "        )[0]\n",
        "    loss_VENTILATION_0 = torch.relu(grad_VENTILATION[:,:,0].unsqueeze(2))\n",
        "    loss_VENTILATION_1 = torch.relu(-grad_VENTILATION[:,:,1].unsqueeze(2))\n",
        "    loss_VENTILATION_2 = torch.relu(-grad_VENTILATION[:,:,2].unsqueeze(2))\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    K = 1\n",
        "    loss = torch.mean(\n",
        "        (output - target)**2 + \n",
        "        K*torch.relu(-x_SPACEHEATER_output) + \n",
        "        K*torch.relu(-x_RADIATION_output) + \n",
        "        # K*loss_OUTDOORTEMPERATURE + \n",
        "        K*loss_OUTDOORTEMPERATURE_0 + \n",
        "        K*loss_OUTDOORTEMPERATURE_1 + \n",
        "        # K*loss_RADIATION + \n",
        "        # K*loss_RADIATION_0 + \n",
        "        K*loss_SPACEHEATER + \n",
        "        K*loss_SPACEHEATER_0 + \n",
        "        K*loss_SPACEHEATER_1 +\n",
        "        K*loss_SPACEHEATER_2 +\n",
        "        # K*loss_VENTILATION +\n",
        "        K*loss_VENTILATION_0 + \n",
        "        K*loss_VENTILATION_1 +\n",
        "        K*loss_VENTILATION_2)\n",
        "        \n",
        "    return loss\n",
        "\n",
        "# class LSTM(jit.ScriptModule):\n",
        "class LSTM(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 n_input=None, \n",
        "                 n_lstm_hidden=None, \n",
        "                 n_lstm_layers=None, \n",
        "                 n_output=None, \n",
        "                 dropout=None,\n",
        "                 scaling_value_dict=None):\n",
        "\n",
        "        self.kwargs = {\"n_input\": n_input,\n",
        "                        \"n_lstm_hidden\": n_lstm_hidden,\n",
        "                        \"n_lstm_layers\": n_lstm_layers,\n",
        "                        \"n_output\": n_output,\n",
        "                        \"dropout\": dropout,\n",
        "                        \"scaling_value_dict\": scaling_value_dict}\n",
        "        \n",
        "        self.n_input = n_input\n",
        "    \n",
        "        (self.n_lstm_hidden_OUTDOORTEMPERATURE,\n",
        "        self.n_lstm_hidden_RADIATION,\n",
        "        self.n_lstm_hidden_SPACEHEATER,\n",
        "        self.n_lstm_hidden_VENTILATION) = n_lstm_hidden\n",
        "        \n",
        "\n",
        "        (self.n_lstm_layers_OUTDOORTEMPERATURE,\n",
        "        self.n_lstm_layers_RADIATION,\n",
        "        self.n_lstm_layers_SPACEHEATER,\n",
        "        self.n_lstm_layers_VENTILATION) = n_lstm_layers\n",
        "\n",
        "        self.n_output = n_output\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        # self.lstm_hidden1_OUTDOORTEMPERATURE = torch.nn.LSTM(self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_layers_OUTDOORTEMPERATURE, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        # self.lstm_hidden2_OUTDOORTEMPERATURE = torch.nn.LSTM(self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_layers_OUTDOORTEMPERATURE, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        # self.lstm_hidden3_OUTDOORTEMPERATURE = torch.nn.LSTM(self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_layers_OUTDOORTEMPERATURE, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_input_OUTDOORTEMPERATURE = torch.nn.LSTM(2, self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_layers_OUTDOORTEMPERATURE, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_output_OUTDOORTEMPERATURE = torch.nn.LSTM(self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_output, 1, batch_first=True, bias=False)\n",
        "\n",
        "\n",
        "        # self.T_w_in__cp = torch.nn.Parameter(torch.randn(1))\n",
        "        # self.m_w_max = torch.nn.Parameter(torch.randn(1))\n",
        "        # self.UA = torch.nn.Parameter(torch.randn(1))\n",
        "\n",
        "        # self.lstm_hidden1_RADIATION = torch.nn.LSTM(self.n_lstm_hidden_RADIATION, self.n_lstm_hidden_RADIATION, self.n_lstm_layers_RADIATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        # self.lstm_hidden2_RADIATION = torch.nn.LSTM(self.n_lstm_hidden_RADIATION, self.n_lstm_hidden_RADIATION, self.n_lstm_layers_RADIATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        # self.lstm_hidden3_RADIATION = torch.nn.LSTM(self.n_lstm_hidden_RADIATION, self.n_lstm_hidden_RADIATION, self.n_lstm_layers_RADIATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_input_RADIATION = torch.nn.LSTM(1, self.n_lstm_hidden_RADIATION, self.n_lstm_layers_RADIATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_output_RADIATION = torch.nn.LSTM(self.n_lstm_hidden_RADIATION, self.n_output, 1, batch_first=True, bias=False)\n",
        "\n",
        "        self.lstm_input_SPACEHEATER = torch.nn.LSTM(3, self.n_lstm_hidden_SPACEHEATER, self.n_lstm_layers_SPACEHEATER, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_output_SPACEHEATER = torch.nn.LSTM(self.n_lstm_hidden_SPACEHEATER, self.n_output, 1, batch_first=True, bias=False)\n",
        "\n",
        "        self.lstm_input_VENTILATION = torch.nn.LSTM(3, self.n_lstm_hidden_VENTILATION, self.n_lstm_layers_VENTILATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_output_VENTILATION = torch.nn.LSTM(self.n_lstm_hidden_VENTILATION, self.n_output, 1, batch_first=True, bias=False)\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(p=self.dropout, inplace=False)\n",
        "\n",
        "\n",
        "        # self.linear_OUTDOORTEMPERATURE = torch.nn.Linear(self.n_lstm_hidden_OUTDOORTEMPERATURE,1)\n",
        "        # self.linear_RADIATION = torch.nn.Linear(self.n_lstm_hidden_RADIATION,1)\n",
        "        # self.linear_SPACEHEATER = torch.nn.Linear(self.n_lstm_hidden_SPACEHEATER,1)\n",
        "        # self.linear_VENTILATION = torch.nn.Linear(self.n_lstm_hidden_VENTILATION,1)\n",
        "\n",
        "        self.linear_u = torch.nn.Linear(1,1, bias=False)\n",
        "        self.linear_T_o_hid = torch.nn.Linear(1,self.n_lstm_hidden_VENTILATION)\n",
        "        self.linear_T_o_out = torch.nn.Linear(self.n_lstm_hidden_VENTILATION,1)\n",
        "        self.linear_T_z = torch.nn.Linear(1,1)\n",
        "\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "    # @jit.script_method\n",
        "    def forward(self, \n",
        "                input: Tuple[Tensor, Tensor, Tensor, Tensor], \n",
        "                hidden_state: Tuple[Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor],\n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor]]):\n",
        "\n",
        "\n",
        "        (x_OUTDOORTEMPERATURE,\n",
        "        x_RADIATION,\n",
        "        x_SPACEHEATER,\n",
        "        x_VENTILATION) = input\n",
        "\n",
        "        \n",
        "\n",
        "        (hidden_state_input_OUTDOORTEMPERATURE,\n",
        "        hidden_state_output_OUTDOORTEMPERATURE,\n",
        "        hidden_state_input_RADIATION,\n",
        "        hidden_state_output_RADIATION,\n",
        "        hidden_state_input_SPACEHEATER,\n",
        "        hidden_state_output_SPACEHEATER,\n",
        "        hidden_state_input_VENTILATION,\n",
        "        hidden_state_output_VENTILATION) = hidden_state\n",
        "\n",
        "        # h_0_hidden1_OUTDOORTEMPERATURE = torch.zeros(hidden_state_input_OUTDOORTEMPERATURE[0].shape).cuda()\n",
        "        # c_0_hidden1_layer_OUTDOORTEMPERATURE = torch.zeros(hidden_state_input_OUTDOORTEMPERATURE[1].shape).cuda()\n",
        "        # hidden_state_hidden1_OUTDOORTEMPERATURE = (h_0_hidden1_OUTDOORTEMPERATURE,c_0_hidden1_layer_OUTDOORTEMPERATURE)\n",
        "        # h_0_hidden2_OUTDOORTEMPERATURE = torch.zeros(hidden_state_input_OUTDOORTEMPERATURE[0].shape).cuda()\n",
        "        # c_0_hidden2_layer_OUTDOORTEMPERATURE = torch.zeros(hidden_state_input_OUTDOORTEMPERATURE[1].shape).cuda()\n",
        "        # hidden_state_hidden2_OUTDOORTEMPERATURE = (h_0_hidden2_OUTDOORTEMPERATURE,c_0_hidden2_layer_OUTDOORTEMPERATURE)\n",
        "\n",
        "        # h_0_hidden1_RADIATION = torch.zeros(hidden_state_input_RADIATION[0].shape).cuda()\n",
        "        # c_0_hidden1_layer_RADIATION = torch.zeros(hidden_state_input_RADIATION[1].shape).cuda()\n",
        "        # hidden_state_hidden1_RADIATION = (h_0_hidden1_RADIATION,c_0_hidden1_layer_RADIATION)\n",
        "        # h_0_hidden2_RADIATION = torch.zeros(hidden_state_input_RADIATION[0].shape).cuda()\n",
        "        # c_0_hidden2_layer_RADIATION = torch.zeros(hidden_state_input_RADIATION[1].shape).cuda()\n",
        "        # hidden_state_hidden2_RADIATION = (h_0_hidden2_RADIATION,c_0_hidden2_layer_RADIATION)\n",
        "\n",
        "\n",
        "        x_OUTDOORTEMPERATURE,hidden_state_input_OUTDOORTEMPERATURE = self.lstm_input_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_input_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = x_OUTDOORTEMPERATURE + x_OUTDOORTEMPERATURE_temp\n",
        "        # x_OUTDOORTEMPERATURE_temp,hidden_state_input_OUTDOORTEMPERATURE = self.lstm_hidden1_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_hidden1_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = x_OUTDOORTEMPERATURE + x_OUTDOORTEMPERATURE_temp\n",
        "        # x_OUTDOORTEMPERATURE_temp,hidden_state_input_OUTDOORTEMPERATURE = self.lstm_hidden2_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_hidden2_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = x_OUTDOORTEMPERATURE + x_OUTDOORTEMPERATURE_temp\n",
        "        # x_OUTDOORTEMPERATURE,hidden_state_input_OUTDOORTEMPERATURE = self.lstm_input_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_input_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = self.dropout(x_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = x_OUTDOORTEMPERATURE + x_OUTDOORTEMPERATURE_\n",
        "        x_OUTDOORTEMPERATURE,hidden_state_output_OUTDOORTEMPERATURE = self.lstm_output_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_output_OUTDOORTEMPERATURE)\n",
        "\n",
        "        x_RADIATION,hidden_state_input_RADIATION = self.lstm_input_RADIATION(x_RADIATION,hidden_state_input_RADIATION)\n",
        "        # x_RADIATION = x_RADIATION + x_RADIATION_temp\n",
        "        # x_RADIATION_temp,hidden_state_input_RADIATION = self.lstm_hidden1_RADIATION(x_RADIATION,hidden_state_hidden1_RADIATION)\n",
        "        # x_RADIATION = x_RADIATION + x_RADIATION_temp\n",
        "        # x_RADIATION_temp,hidden_state_input_RADIATION = self.lstm_hidden2_RADIATION(x_RADIATION,hidden_state_hidden2_RADIATION)\n",
        "        # x_RADIATION = x_RADIATION + x_RADIATION_temp\n",
        "        x_RADIATION,hidden_state_output_RADIATION = self.lstm_output_RADIATION(x_RADIATION,hidden_state_output_RADIATION)\n",
        "\n",
        "        x_SPACEHEATER,hidden_state_input_SPACEHEATER = self.lstm_input_SPACEHEATER(x_SPACEHEATER,hidden_state_input_SPACEHEATER)\n",
        "        # x_SPACEHEATER = self.dropout(x_SPACEHEATER)\n",
        "        # x_SPACEHEATER = x_SPACEHEATER + x_SPACEHEATER_\n",
        "        x_SPACEHEATER,hidden_state_output_SPACEHEATER = self.lstm_output_SPACEHEATER(x_SPACEHEATER,hidden_state_output_SPACEHEATER)\n",
        "\n",
        "        # x_damper = torch.unsqueeze(x_VENTILATION[:,:,1],2)\n",
        "        x_VENTILATION,hidden_state_input_VENTILATION = self.lstm_input_VENTILATION(x_VENTILATION,hidden_state_input_VENTILATION)\n",
        "        # # x_VENTILATION = self.dropout(x_VENTILATION)\n",
        "        # # x_VENTILATION = x_VENTILATION + x_VENTILATION_\n",
        "        x_VENTILATION,hidden_state_output_VENTILATION = self.lstm_output_VENTILATION(x_VENTILATION,hidden_state_output_VENTILATION)\n",
        "        # x_VENTILATION = x_VENTILATION*x_damper\n",
        "\n",
        "\n",
        "        # d1,d2,d3 = x_VENTILATION.size()\n",
        "        # x_VENTILATION = x_VENTILATION.reshape(d1*d2,d3)\n",
        "        # x_indoor = torch.unsqueeze(x_VENTILATION[:,0],1)\n",
        "        # x_damper = torch.unsqueeze(x_VENTILATION[:,1],1)\n",
        "        # x_supply_air_temperature = torch.unsqueeze(x_VENTILATION[:,2],1)\n",
        "\n",
        "        # x_VENTILATION = (x_supply_air_temperature-self.linear_T_z(x_indoor))*self.linear_u(x_damper)\n",
        "        # x_VENTILATION = x_VENTILATION.reshape(d1,d2,1)\n",
        "\n",
        "        x = (x_OUTDOORTEMPERATURE, x_RADIATION, x_SPACEHEATER, x_VENTILATION)\n",
        "        y = x_OUTDOORTEMPERATURE + x_RADIATION + x_SPACEHEATER + x_VENTILATION\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        hidden_state = (hidden_state_input_OUTDOORTEMPERATURE,\n",
        "                        hidden_state_output_OUTDOORTEMPERATURE,\n",
        "                        hidden_state_input_RADIATION,\n",
        "                        hidden_state_output_RADIATION,\n",
        "                        hidden_state_input_SPACEHEATER,\n",
        "                        hidden_state_output_SPACEHEATER,\n",
        "                        hidden_state_input_VENTILATION,\n",
        "                        hidden_state_output_VENTILATION)\n",
        "\n",
        "        return y,hidden_state,x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def min_max_norm(y,y_min,y_max,low,high):\n",
        "    y = (y-y_min)/(y_max-y_min)*(high-low) + low\n",
        "    return y\n",
        "\n",
        "def rescale(y,y_min,y_max,low,high):\n",
        "    y = (y-low)/(high-low)*(y_max-y_min) + y_min\n",
        "    return y\n",
        "\n",
        "def sigmoid_inverse(x):\n",
        "    out = np.log(x/(1-x))\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, space_name, data_paths, load=True, plot=False):\n",
        "\n",
        "        self.space_name = space_name\n",
        "\n",
        "        (self.training_data_folder_name,\n",
        "        self.drive_zipped_training_data_path,\n",
        "        self.drive_unzipped_training_data_path,\n",
        "        self.vm_drive_unzip_data_path,\n",
        "        self.vm_drive_training_data_path) = data_paths\n",
        "\n",
        "\n",
        "        np.random.seed(0)\n",
        "\n",
        "        self.saved_serialized_networks_path = \"/content/drive/My Drive/Google collab/b3d_serialized_networks_new/\"\n",
        "        self.saved_networks_path = \"/content/drive/My Drive/Google collab/b3d_saved_networks_new/\"\n",
        "\n",
        "        os.chdir(self.saved_networks_path)\n",
        "\n",
        "        # self.T_min = -7.91\n",
        "        # self.T_max = 39.29999923706055\n",
        "        \n",
        "        self.dT_min = -1\n",
        "        self.dT_max = -self.dT_min\n",
        "        \n",
        "        self.best_loss_diff_max = 5000\n",
        "        self.max_it_stop = 1000000\n",
        "        momentum = 0.9 \n",
        "        LR = '1e-2' #1e-1\n",
        "        LR_s = '1e-2' #1e-1\n",
        "        self.update_factor = 1e-1\n",
        "        self.n_step_diff = 10000000000 #768000 #30 Epochs\n",
        "        self.n_step_update = self.n_step_diff\n",
        "        self.n_step_max = int(self.n_step_diff+self.n_step_diff/4+self.n_step_diff/16)\n",
        "        self.learning_rate = float(LR_s)\n",
        "        self.n_batch = 2**6\n",
        "        self.n_batch_s = 2**6\n",
        "        # self.file_batch = 64\n",
        "        self.file_batch = 2**9 #2048\n",
        "        self.n_output = 1\n",
        "        self.n_input = self.get_input_size() ################################################\n",
        "        self.n_lstm_hidden = (5,5,5,5) #20 #(2,2,1,3) good\n",
        "        self.n_lstm_layers = (3,3,3,3)\n",
        "        self.dropout = 0.\n",
        "\n",
        "\n",
        "        self.load_min_max_scale_values()\n",
        "        self.model = LSTM(self.n_input, self.n_lstm_hidden, self.n_lstm_layers, self.n_output, self.dropout, self.scaling_value_dict).to(DEVICE)\n",
        "        self.model.train()\n",
        "\n",
        "        \n",
        "\n",
        "        # self.optimizer = torch.optim.NAdam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        # self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate,momentum=momentum)\n",
        "        self.loss_fn = loss_penalized#torch.nn.MSELoss()\n",
        "\n",
        "        # model_type_load = \"b3d_B%d_LR%s\" % (self.n_batch,LR)\n",
        "        # model_type_save = \"b3d_B%d_LR%s\" % (self.n_batch,LR_s)\n",
        "        # model_type_load = \"T_diff_b3d_B%d_LR%s\" % (self.n_batch,LR)\n",
        "        # model_type_save = \"T_diff_b3d_B%d_LR%s\" % (self.n_batch,LR_s)\n",
        "        # model_type_load = \"T_diff_LSTM_b3d_B%d_LR%s\" % (self.n_batch,LR)\n",
        "        # model_type_save = \"T_diff_LSTM_b3d_B%d_LR%s\" % (self.n_batch_s,LR_s)\n",
        "        model_type_load = self.space_name + \"_T_diff_LSTM_b3d_B%d_LR%s\" % (self.n_batch,LR)\n",
        "        model_type_save = self.space_name + \"_T_diff_LSTM_b3d_B%d_LR%s\" % (self.n_batch_s,LR_s)\n",
        "\n",
        "        self.network_filename_load = self.space_name + \"_Network\"\n",
        "        self.optimizer_filename_load = self.space_name + \"_Optimizer\"\n",
        "\n",
        "        self.network_filename_save = self.space_name + \"_Network\"\n",
        "        self.optimizer_filename_save = self.space_name + \"_Optimizer\"\n",
        "\n",
        "        self.step_train_filename_load = self.space_name + \"_step_train\"\n",
        "        self.prec_train_filename_load = self.space_name + \"_prec_train\"\n",
        "\n",
        "        self.step_train_filename_save = self.space_name + \"_step_train\"\n",
        "        self.prec_train_filename_save = self.space_name + \"_prec_train\"\n",
        "\n",
        "        self.step_test_filename_load = self.space_name + \"_step_test\"\n",
        "        self.prec_test_filename_load = self.space_name + \"_prec_test\"\n",
        "\n",
        "        self.step_test_filename_save = self.space_name + \"_step_test\"\n",
        "        self.prec_test_filename_save = self.space_name + \"_prec_test\"\n",
        "\n",
        "        self.running_validation_loss_filename_load = self.space_name + \"_running_validation_loss\"\n",
        "        self.running_validation_loss_filename_save = self.space_name + \"_running_validation_loss\"\n",
        "\n",
        "        self.running_validation_loss_model_name_filename_load = self.space_name + \"_running_validation_loss_model_name\"\n",
        "        self.running_validation_loss_model_name_filename_save = self.space_name + \"_running_validation_loss_model_name\"\n",
        "\n",
        "        if load==True:\n",
        "            os.chdir(self.saved_networks_path)\n",
        "            self.model.load_state_dict(torch.load(self.network_filename_load,map_location=torch.device(DEVICE)))\n",
        "            self.optimizer.load_state_dict(torch.load(self.optimizer_filename_load,map_location=torch.device(DEVICE)))\n",
        "\n",
        "            self.step_train = np.load(self.step_train_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "            self.prec_train = np.load(self.prec_train_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "\n",
        "            self.step_test = np.load(self.step_test_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "            self.prec_test = np.load(self.prec_test_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "\n",
        "            os.chdir(self.saved_serialized_networks_path)\n",
        "\n",
        "            self.running_validation_loss = np.load(self.running_validation_loss_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "            self.running_validation_loss_model_name = np.load(self.running_validation_loss_model_name_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "\n",
        "            os.chdir(self.saved_networks_path)\n",
        "\n",
        "            self.n_step = self.step_train[-1]\n",
        "        else:\n",
        "            load_pretrained_model = False   \n",
        "            if load_pretrained_model:\n",
        "                print(os.getcwd())\n",
        "                print(os.listdir())\n",
        "                self.model.load_state_dict(torch.load(self.network_filename_load + \".pt\",map_location=torch.device(DEVICE)))\n",
        "            \n",
        "            self.step_train = []\n",
        "            self.prec_train = [] \n",
        "            self.step_test = []\n",
        "            self.prec_test = [] \n",
        "            self.running_validation_loss = []\n",
        "            self.running_validation_loss_model_name = []\n",
        "            self.n_step = 0\n",
        "        pytorch_total_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        print(\"TOTAL NUMBER OF PARAMETERS IN MODEL: \" + str(pytorch_total_params))\n",
        "\n",
        "        self.n_step_start = self.n_step\n",
        "\n",
        "\n",
        "\n",
        "        self.batch_idx_train = 0\n",
        "        self.batch_idx_test = 0\n",
        "        self.batch_train_counter = 0\n",
        "\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = self.learning_rate\n",
        "\n",
        "        self.do_test = True\n",
        "        self.extract_model = True\n",
        "\n",
        "        self.n_test = 2**4\n",
        "        self.plot = plot\n",
        "        \n",
        "\n",
        "        self.n_save_traced_module = self.n_test\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        h_0_input_layer_OUTDOORTEMPERATURE = torch.zeros((self.n_lstm_layers[0],self.n_batch_s,self.n_lstm_hidden[0])).to(DEVICE)\n",
        "        c_0_input_layer_OUTDOORTEMPERATURE = torch.zeros((self.n_lstm_layers[0],self.n_batch_s,self.n_lstm_hidden[0])).to(DEVICE)\n",
        "        h_0_output_layer_OUTDOORTEMPERATURE = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        c_0_output_layer_OUTDOORTEMPERATURE = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        hidden_state_input_OUTDOORTEMPERATURE = (h_0_input_layer_OUTDOORTEMPERATURE,c_0_input_layer_OUTDOORTEMPERATURE)\n",
        "        hidden_state_output_OUTDOORTEMPERATURE = (h_0_output_layer_OUTDOORTEMPERATURE,c_0_output_layer_OUTDOORTEMPERATURE)\n",
        "\n",
        "        h_0_input_layer_RADIATION = torch.zeros((self.n_lstm_layers[1],self.n_batch_s,self.n_lstm_hidden[1])).to(DEVICE)\n",
        "        c_0_input_layer_RADIATION = torch.zeros((self.n_lstm_layers[1],self.n_batch_s,self.n_lstm_hidden[1])).to(DEVICE)\n",
        "        h_0_output_layer_RADIATION = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        c_0_output_layer_RADIATION = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        hidden_state_input_RADIATION = (h_0_input_layer_RADIATION,c_0_input_layer_RADIATION)\n",
        "        hidden_state_output_RADIATION = (h_0_output_layer_RADIATION,c_0_output_layer_RADIATION)\n",
        "\n",
        "        h_0_input_layer_SPACEHEATER = torch.zeros((self.n_lstm_layers[2],self.n_batch_s,self.n_lstm_hidden[2])).to(DEVICE)\n",
        "        c_0_input_layer_SPACEHEATER = torch.zeros((self.n_lstm_layers[2],self.n_batch_s,self.n_lstm_hidden[2])).to(DEVICE)\n",
        "        h_0_output_layer_SPACEHEATER = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        c_0_output_layer_SPACEHEATER = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        hidden_state_input_SPACEHEATER = (h_0_input_layer_SPACEHEATER,c_0_input_layer_SPACEHEATER)\n",
        "        hidden_state_output_SPACEHEATER = (h_0_output_layer_SPACEHEATER,c_0_output_layer_SPACEHEATER)\n",
        "\n",
        "        h_0_input_layer_VENTILATION = torch.zeros((self.n_lstm_layers[3],self.n_batch_s,self.n_lstm_hidden[3])).to(DEVICE)\n",
        "        c_0_input_layer_VENTILATION = torch.zeros((self.n_lstm_layers[3],self.n_batch_s,self.n_lstm_hidden[3])).to(DEVICE)\n",
        "        h_0_output_layer_VENTILATION = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        c_0_output_layer_VENTILATION = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        hidden_state_input_VENTILATION = (h_0_input_layer_VENTILATION,c_0_input_layer_VENTILATION)\n",
        "        hidden_state_output_VENTILATION = (h_0_output_layer_VENTILATION,c_0_output_layer_VENTILATION)\n",
        "\n",
        "\n",
        "\n",
        "        self.hidden_state = (hidden_state_input_OUTDOORTEMPERATURE,\n",
        "                            hidden_state_output_OUTDOORTEMPERATURE,\n",
        "                            hidden_state_input_RADIATION,\n",
        "                            hidden_state_output_RADIATION,\n",
        "                            hidden_state_input_SPACEHEATER,\n",
        "                            hidden_state_output_SPACEHEATER,\n",
        "                            hidden_state_input_VENTILATION,\n",
        "                            hidden_state_output_VENTILATION)\n",
        "    \n",
        "\n",
        "\n",
        "    def load_dataset_into_RAM(self):\n",
        "        drive.mount('/content/drive')\n",
        "        os.chdir(self.training_data_path) \n",
        "        self.cnn_input_list = []\n",
        "        self.flat_input_list = []\n",
        "        self.h_0_input_list = []\n",
        "        self.output_list = []\n",
        "\n",
        "\n",
        "        self.it_list = [0,1] #########################################\n",
        "        for i in self.it_list:\n",
        "            print(i)\n",
        "            name_idx_rand = self.file_batch*i + self.file_batch\n",
        "            filename = 'Batch_%d.npz' % (name_idx_rand)\n",
        "\n",
        "        \n",
        "            loaded = np.load(filename)\n",
        "            cnn_input = torch.Tensor(loaded[loaded.files[0]])\n",
        "            flat_input = torch.Tensor(loaded[loaded.files[1]])\n",
        "            h_0_input = torch.Tensor(loaded[loaded.files[2]])\n",
        "            output = torch.Tensor(loaded[loaded.files[3]])\n",
        "            del loaded.f\n",
        "            loaded.close()\n",
        "\n",
        "            print(\"----\")\n",
        "            print(cnn_input.element_size())\n",
        "            print(cnn_input.nelement())\n",
        "            print(cnn_input.element_size() * cnn_input.nelement())\n",
        "\n",
        "            flat_input_temp = torch.zeros((flat_input.shape[0],flat_input.shape[1],flat_input.shape[2]-1))\n",
        "            flat_input_temp[:,:,0:2] = flat_input[:,:,0:2]\n",
        "            flat_input_temp[:,:,2:] = flat_input[:,:,3:]\n",
        "\n",
        "            flat_input = flat_input_temp\n",
        "\n",
        "            self.cnn_input_list.append(cnn_input)\n",
        "            self.flat_input_list.append(flat_input)\n",
        "            self.h_0_input_list.append(h_0_input)\n",
        "            self.output_list.append(output)\n",
        "\n",
        "            \n",
        "    def get_input_size(self):\n",
        "        os.chdir(self.vm_drive_training_data_path)\n",
        "        filename = self.space_name + \"_training_batch_%d.npz\" % (self.file_batch)\n",
        "        loaded = np.load(filename)\n",
        "        flat_input = torch.Tensor(loaded[loaded.files[0]])\n",
        "        os.chdir(self.saved_networks_path)\n",
        "        n_input = flat_input.shape[2]\n",
        "        \n",
        "        print(\"INPUT\")\n",
        "        print(n_input)\n",
        "\n",
        "        return n_input\n",
        "\n",
        "\n",
        "\n",
        "    def load_batch_into_GPU(self):\n",
        "        os.chdir(self.vm_drive_training_data_path)\n",
        "        # os.chdir(self.drive_unzipped_training_data_path)\n",
        "        \n",
        "        \n",
        "        if self.batch_idx_train == self.max_it_train:\n",
        "            np.random.shuffle(self.it_list_train)\n",
        "            self.batch_idx_train = 0\n",
        "        \n",
        "        if self.batch_idx_test==self.max_it_test:\n",
        "            np.random.shuffle(self.it_list_test)\n",
        "            self.batch_idx_test = 0\n",
        "\n",
        "\n",
        "        # if self.batch_train_counter % self.test_it == 0:\n",
        "        #     self.do_test = True\n",
        "        #     self.first_test = False\n",
        "\n",
        "\n",
        "        if self.do_test==False:\n",
        "            i = self.it_list_train[self.batch_idx_train]\n",
        "            self.data_type = \"training\"\n",
        "            \n",
        "        else:\n",
        "            i = self.it_list_test[self.batch_idx_test]\n",
        "            self.data_type = \"validation\"\n",
        "        \n",
        "        name_idx_rand = self.file_batch*i + self.file_batch\n",
        "        filename = self.space_name + \"_\" + self.data_type + \"_batch_%d.npz\" % (name_idx_rand)\n",
        "\n",
        "        loaded = np.load(filename)\n",
        "\n",
        "\n",
        "        flat_input = torch.Tensor(loaded[loaded.files[0]])\n",
        "        output = torch.Tensor(loaded[loaded.files[1]])  \n",
        "\n",
        "        self.flat_input = flat_input.to(DEVICE)\n",
        "        self.output = output.to(DEVICE)\n",
        "\n",
        "        temp = self.flat_input\n",
        "        # self.flat_input = self.flat_input[:,1:]\n",
        "        # self.flat_input[:,:,0] = temp[:,:-1,0] #Indoor temperature\n",
        "\n",
        "        self.flat_input = self.flat_input[:,:-1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # self.h_0_input = self.h_0_input[:,:-1]\n",
        "        self.output_dT = self.output[:,1:]-self.output[:,:-1]\n",
        "        # self.output = self.output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # self.output_dT = min_max_norm(self.output_dT,self.dT_min,self.dT_max,-1,1)\n",
        "\n",
        "\n",
        "\n",
        "    def load_min_max_scale_values(self):\n",
        "        os.chdir(self.vm_drive_training_data_path)\n",
        "        filename = self.space_name + \"_scaling_value_dict\" + \".pickle\"\n",
        "        filehandler = open(filename, 'rb')\n",
        "        self.scaling_value_dict = pickle.load(filehandler)\n",
        "\n",
        "    def scan_directory(self):\n",
        "        os.chdir(self.vm_drive_training_data_path)\n",
        "        directory = os.fsencode(self.vm_drive_training_data_path)\n",
        "        file_counter_training = 0\n",
        "        file_counter_validation = 0\n",
        "        for file in os.listdir(directory):\n",
        "            filename = os.fsdecode(file)\n",
        "            if filename.find(self.space_name + \"_training\") != -1:\n",
        "                file_counter_training += 1\n",
        "            elif filename.find(self.space_name + \"_validation\") != -1:\n",
        "                file_counter_validation += 1\n",
        "        self.max_it_train = file_counter_training\n",
        "        self.max_it_test = file_counter_validation\n",
        "        self.n_running_avg = self.max_it_test\n",
        "\n",
        "        self.it_list_train = np.arange(0,self.max_it_train)\n",
        "        self.it_list_test = np.arange(0,self.max_it_test)\n",
        "\n",
        "    def get_input(self, flat_input):\n",
        "\n",
        "        x_OUTDOORTEMPERATURE = torch.zeros((flat_input.shape[0], flat_input.shape[1], 2)).to(DEVICE)\n",
        "        x_RADIATION = torch.zeros((flat_input.shape[0], flat_input.shape[1], 1)).to(DEVICE)\n",
        "        x_SPACEHEATER = torch.zeros((flat_input.shape[0], flat_input.shape[1], 3)).to(DEVICE)\n",
        "        x_VENTILATION = torch.zeros((flat_input.shape[0], flat_input.shape[1], 3)).to(DEVICE)\n",
        "        \n",
        "        x_OUTDOORTEMPERATURE[:,:,0] = flat_input[:,:,0] #indoor\n",
        "        x_OUTDOORTEMPERATURE[:,:,1] = flat_input[:,:,6] #outdoor\n",
        "        x_RADIATION[:,:,0] = flat_input[:,:,7] #radiation\n",
        "        x_SPACEHEATER[:,:,0] = flat_input[:,:,0] #indoor\n",
        "        x_SPACEHEATER[:,:,1] = flat_input[:,:,2] #valve\n",
        "        x_SPACEHEATER[:,:,2] = flat_input[:,:,3] #supply water temperature\n",
        "        # x_SPACEHEATER[:,:,3] = flat_input[:,:,2]*flat_input[:,:,3] #energy\n",
        "        x_VENTILATION[:,:,0] = flat_input[:,:,0] #indoor\n",
        "        x_VENTILATION[:,:,1] = flat_input[:,:,4] #damper\n",
        "        x_VENTILATION[:,:,2] = flat_input[:,:,5] #supply air temperature\n",
        "        # x_VENTILATION[:,:,3] = flat_input[:,:,4]*flat_input[:,:,5] #energy in \n",
        "        # x_VENTILATION[:,:,4] = flat_input[:,:,4]*flat_input[:,:,0] #energy out\n",
        "\n",
        "        x_OUTDOORTEMPERATURE.requires_grad = True\n",
        "        x_RADIATION.requires_grad = True\n",
        "        x_SPACEHEATER.requires_grad = True\n",
        "        x_VENTILATION.requires_grad = True\n",
        "\n",
        "\n",
        "        input = (x_OUTDOORTEMPERATURE,\n",
        "                x_RADIATION,\n",
        "                x_SPACEHEATER,\n",
        "                x_VENTILATION)\n",
        "\n",
        "        return input\n",
        "\n",
        "    def train_batch(self):\n",
        "        self.model.train()\n",
        "        #Shuffle data\n",
        "        idx = np.arange(self.flat_input.shape[0])\n",
        "        np.random.shuffle(idx)\n",
        "\n",
        "        self.flat_input = self.flat_input[idx]\n",
        "        self.output_dT = self.output_dT[idx]\n",
        "\n",
        "\n",
        "        abs_err_train = 0\n",
        "        size = self.flat_input.shape[0]\n",
        "        n_it_sub_batch = int(np.ceil(size/self.n_batch_s))\n",
        "        t_start = time.time()\n",
        "        loss_vec = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        loss_vec_T = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        loss_vec_dT = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        update = False\n",
        "        print(\"----\")\n",
        "        for idx in range(n_it_sub_batch):\n",
        "            if idx+1!=n_it_sub_batch or int(np.remainder(size,self.n_batch_s))==0:\n",
        "                n = self.n_batch_s\n",
        "            else:\n",
        "                break\n",
        "                #n = int(np.remainder(size,n_batch))\n",
        "\n",
        "\n",
        "            flat_input_batch = self.flat_input[idx*self.n_batch_s:idx*self.n_batch_s+n]\n",
        "            output_dT_batch = self.output_dT[idx*self.n_batch_s:idx*self.n_batch_s+n]\n",
        "\n",
        "            input = self.get_input(flat_input_batch)\n",
        "\n",
        "            # time_start = time.time()\n",
        "            with torch.backends.cudnn.flags(enabled=False): ####################################################\n",
        "                output_batch_pred,hidden_state,x = self.model(input, self.hidden_state)\n",
        "            \n",
        "            ##### Add temperature MSE to loos function #####\n",
        "            # dT = rescale(output_batch_pred, self.dT_min, self.dT_max, -1, 1)\n",
        "            # # T_0 = rescale(output_batch[:,0], self.T_min, self.T_max, -1, 1)\n",
        "            # T_0 = output_batch[:,0]\n",
        "            # T_0 = torch.reshape(T_0,(T_0.shape[0],1,T_0.shape[1]))\n",
        "            # dT_cumsum = torch.cumsum(dT,dim=1)\n",
        "            # T = T_0 + dT_cumsum\n",
        "            # T = min_max_norm(T, self.T_min, self.T_max, -1, 1)\n",
        "            # T_target = min_max_norm(output_batch[:,1:], self.T_min, self.T_max, -1, 1)\n",
        "            # loss_T = 0*self.loss_fn(T_target,T)\n",
        "            ################################################\n",
        "\n",
        "\n",
        "            loss_dT = self.loss_fn(output_batch_pred,output_dT_batch,x,input)\n",
        "            # loss = loss_T + loss_dT\n",
        "            loss = loss_dT\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "            loss_vec[idx] = loss.detach()\n",
        "            # loss_vec_T[idx] = loss_T.detach()\n",
        "            # loss_vec_dT[idx] = loss_dT.detach()\n",
        "\n",
        "\n",
        "\n",
        "            # loss_list.append(loss.item())\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # for name, W in self.model.named_parameters():\n",
        "            #     print(\"### Parameter ###\")\n",
        "            #     print(name)\n",
        "            #     avg = torch.mean(torch.abs(W.grad))\n",
        "            #     var = torch.var(W.grad)\n",
        "            #     print(avg)\n",
        "            #     print(var)\n",
        "\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.n_step += 1\n",
        "            # print(idx, time.time()-time_start)\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "            if self.n_step == self.n_step_update and self.n_step <= self.n_step_max:\n",
        "                update = True\n",
        "         \n",
        "                \n",
        "        if update == True:\n",
        "            self.learning_rate = self.learning_rate*self.update_factor\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group['lr'] = self.learning_rate\n",
        "            # self.n_batch_s = int(self.n_batch_s*self.update_factor)\n",
        "            # self.n_step_diff = int(self.n_step_diff/self.update_factor)\n",
        "            self.n_step_update = self.n_step_update + self.n_step_diff\n",
        "\n",
        "\n",
        "        # avg_loss = np.mean(np.array(loss_list))\n",
        "        \n",
        "        avg_loss = torch.mean(loss_vec).cpu()\n",
        "        # avg_loss_T = torch.mean(loss_vec_T).cpu()\n",
        "        # avg_loss_dT = torch.mean(loss_vec_dT).cpu()\n",
        "\n",
        "        self.step_train.append(self.n_step)\n",
        "        self.prec_train.append(avg_loss)\n",
        "      \n",
        "        if self.verbose:\n",
        "            print('Batch number: %d' % (self.batch_idx_train))\n",
        "            print('Gradient steps: %d' % (self.n_step))\n",
        "            print('Learning rate: %s' % \"{:.10f}\".format(self.learning_rate))\n",
        "\n",
        "\n",
        "            print('Update factor: %d' % (self.update_factor))\n",
        "            print('Next update: %d' % (self.n_step_update))\n",
        "            print('Update difference: %d' % (self.n_step_diff))\n",
        "            print('Max update: %d' % (self.n_step_max))\n",
        "            print('Batch size: %d' % (self.n_batch_s))\n",
        "\n",
        "            print('Avg loss: %s' % \"{:.10f}\".format(avg_loss))\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def test_batch(self):\n",
        "\n",
        "        # with torch.no_grad():\n",
        "        # self.model.eval()\n",
        "\n",
        "        os.chdir(self.saved_networks_path)\n",
        "\n",
        "        rescaled_y_list = []\n",
        "        rescaled_y_pred_list = []\n",
        "        r_valve_list = []\n",
        "        abs_err_test = 0\n",
        "        size = self.flat_input.shape[0]\n",
        "\n",
        "        # n_it_sub_batch = int(np.ceil(size/self.n_batch_s))\n",
        "        n_it_sub_batch = int(np.ceil(size/self.file_batch))\n",
        "        # loss_list = []\n",
        "        loss_vec = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        for idx in range(n_it_sub_batch):\n",
        "            if idx+1!=n_it_sub_batch or int(np.remainder(size,self.n_batch_s))==0:\n",
        "                n = self.n_batch_s\n",
        "            else:\n",
        "                break\n",
        "\n",
        "\n",
        "            flat_input_batch = self.flat_input[idx*self.n_batch_s:idx*self.n_batch_s+n]\n",
        "            output_dT_batch = self.output_dT[idx*self.n_batch_s:idx*self.n_batch_s+n]\n",
        "\n",
        "\n",
        "            input = self.get_input(flat_input_batch)\n",
        "            output_batch_pred,hidden_state,x = self.model(input, self.hidden_state)\n",
        "\n",
        "\n",
        "            ##### Add temperature MSE to loos function #####\n",
        "            # dT = rescale(output_batch_pred, self.dT_min, self.dT_max, -1, 1)\n",
        "            # # T_0 = rescale(output_batch[:,0], self.T_min, self.T_max, -1, 1)\n",
        "            # T_0 = output_batch[:,0]\n",
        "            # T_0 = torch.reshape(T_0,(T_0.shape[0],1,T_0.shape[1]))\n",
        "            # dT_cumsum = torch.cumsum(dT,dim=1)\n",
        "            # T = T_0 + dT_cumsum\n",
        "            # T = min_max_norm(T, self.T_min, self.T_max, -1, 1)\n",
        "            # T_target = min_max_norm(output_batch[:,1:], self.T_min, self.T_max, -1, 1)\n",
        "            # loss_T = 0*self.loss_fn(T_target,T)\n",
        "            ################################################\n",
        "\n",
        "            loss_dT = self.loss_fn(output_batch_pred,output_dT_batch,x,input)\n",
        "            # loss = loss_T + loss_dT\n",
        "            loss = loss_dT\n",
        "\n",
        "\n",
        "            # loss = self.loss_fn(output_batch_pred,output_batch)\n",
        "            loss_vec[idx] = loss.detach()\n",
        "            # loss_list.append(loss.item())\n",
        "\n",
        "            rescaled_y = rescale(output_dT_batch.cpu(),self.dT_min,self.dT_max,-1,1)\n",
        "            rescaled_y_pred = rescale(output_batch_pred.cpu(),self.dT_min,self.dT_max,-1,1)\n",
        "\n",
        "            rescaled_y_list.extend(np.array(rescaled_y))\n",
        "            rescaled_y_pred_list.extend(np.array(rescaled_y_pred.detach()))\n",
        "            r_valve_list.extend(np.array(flat_input_batch[:,:,1].detach().cpu()))\n",
        "\n",
        "        # avg_loss = np.mean(np.array(loss_list))\n",
        "        avg_loss = torch.mean(loss_vec).cpu()\n",
        "\n",
        "        if self.verbose:\n",
        "            # print('Running average: %s' % \"{:.10f}\".format(running_test_avg))\n",
        "            print('Avg loss: %s' % \"{:.10f}\".format(avg_loss))\n",
        "        \n",
        "\n",
        "        self.rescaled_y_list = np.array(rescaled_y_list)\n",
        "        self.rescaled_y_pred_list = np.array(rescaled_y_pred_list)\n",
        "        self.r_valve_list = np.array(r_valve_list)\n",
        "\n",
        "        self.step_test.append(self.n_step)\n",
        "        self.prec_test.append(avg_loss)\n",
        "\n",
        "\n",
        "        #Saving\n",
        "        np.save(self.step_train_filename_save + \".npy\",np.array(self.step_train))\n",
        "        np.save(self.prec_train_filename_save + \".npy\",np.array(self.prec_train))\n",
        "\n",
        "        np.save(self.step_test_filename_save + \".npy\",np.array(self.step_test))\n",
        "        np.save(self.prec_test_filename_save + \".npy\",np.array(self.prec_test))\n",
        "\n",
        "        torch.save(self.model.state_dict(),self.network_filename_save)\n",
        "        torch.save(self.optimizer.state_dict(),self.optimizer_filename_save)\n",
        "\n",
        "        \n",
        "\n",
        "            \n",
        "\n",
        "    def test_all(self):\n",
        "        for i in range(self.max_it_test):\n",
        "            self.load_batch_into_GPU()\n",
        "            self.test_batch()\n",
        "            self.batch_idx_test += 1\n",
        "        self.model.eval()\n",
        "\n",
        "        if self.plot:\n",
        "            # running_test_avg = np.mean(np.array(self.prec_test[-self.n_running_avg:]))\n",
        "            running_test_avg = torch.mean(torch.Tensor(self.prec_test[-self.n_running_avg:]))\n",
        "            np_step_test = np.array(self.step_test, dtype=np.int)\n",
        "            np_prec_test = np.array(self.prec_test)\n",
        "            unique_step_test = np.unique(self.step_test)\n",
        "            unique_prec_test = [np.mean(np_prec_test[idx==np_step_test]) for idx in unique_step_test]\n",
        "            try:\n",
        "                self.const_line.remove()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "           \n",
        "            if self.plot:\n",
        "                # Plotting\n",
        "                self.ax_loss.plot(self.step_train,self.prec_train, color=\"blue\")\n",
        "                self.ax_loss.plot(unique_step_test,unique_prec_test, color=\"black\")\n",
        "                self.const_line = self.ax_loss.axhline(y=running_test_avg, color='r', linestyle='-')\n",
        "                self.ax_loss.set_yscale('log')\n",
        "                # display.display(plt.gcf())\n",
        "\n",
        "                # fig_profile.clear(True) \n",
        "\n",
        "\n",
        "                self.ax[0].clear()\n",
        "                var_vec = np.var(self.rescaled_y_list[:,:,0], axis=1)\n",
        "                max_var_idx = np.random.randint(self.rescaled_y_list[:,:,0].shape[0])#np.argmax(var_vec)\n",
        "                \n",
        "                self.ax[0].plot(self.rescaled_y_list[max_var_idx,:,0], color=\"blue\",label=\"Truth\")\n",
        "                self.ax[0].plot(self.rescaled_y_pred_list[max_var_idx,:,0], color=\"green\",label=\"Prediction\")\n",
        "                self.ax[0].plot(self.r_valve_list[max_var_idx,:], color=\"red\",label=\"valve\")\n",
        "                # ax_i.set_ylim([15, 28])\n",
        "                self.ax[0].legend()\n",
        "\n",
        "\n",
        "                self.ax[1].clear()\n",
        "                self.ax[1].plot(self.output.cpu().detach().numpy()[max_var_idx,:-1,0]) #\n",
        "                # self.ax[1].set_ylim([15, 28])\n",
        "\n",
        "                display.display(plt.gcf())\n",
        "                # display.clear_output(wait=True)\n",
        "                time.sleep(0.1)\n",
        "\n",
        "    def serialize_model(self):\n",
        "        do_break = False\n",
        "        # os.chdir(S_path)\n",
        "\n",
        "        self.model.cpu()\n",
        "\n",
        "\n",
        "        os.chdir(self.saved_serialized_networks_path)\n",
        "        filename = self.network_filename_save + \"_step\" + str(self.n_step) + \".pt\"\n",
        "        torch.save((self.model.kwargs, self.model.state_dict()), filename)\n",
        "\n",
        "        \n",
        "        self.running_validation_loss.append(np.mean(np.array(self.prec_test[-self.n_running_avg:])))\n",
        "        np.save(self.running_validation_loss_filename_save + \".npy\",np.array(self.running_validation_loss))\n",
        "\n",
        "        self.running_validation_loss_model_name.append(self.network_filename_save + \"_step\" + str(self.n_step) + \".pt\")\n",
        "        np.save(self.running_validation_loss_model_name_filename_save + \".npy\",np.array(self.running_validation_loss_model_name))\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"Saved serialized module\")\n",
        "        \n",
        "        best_loss_diff = (len(self.running_validation_loss)-np.nanargmin(np.array(self.running_validation_loss))-1)*self.n_save_traced_module\n",
        "        if best_loss_diff>=self.best_loss_diff_max:\n",
        "            print(\"No improvement for the last \" + str(self.best_loss_diff_max) + \" iterations: Stopping...\")\n",
        "            do_break = True\n",
        "\n",
        "        self.extract_model = False\n",
        "\n",
        "        self.model.train()\n",
        "        self.model.to(DEVICE)\n",
        "\n",
        "        self.sort_directory()\n",
        "\n",
        "        return do_break\n",
        "\n",
        "    def train(self, verbose=False):\n",
        "\n",
        "        self.verbose = verbose\n",
        "        \n",
        "        if self.plot:\n",
        "            rows = 3\n",
        "            fig = plt.figure(figsize=(40,10))\n",
        "            grid = plt.GridSpec(rows, 1, hspace=0.2, wspace=0.2)\n",
        "            self.ax_loss = fig.add_subplot(grid[0, 0:1]) #0:2\n",
        "\n",
        "\n",
        "            self.ax = []\n",
        "            for i in range(1,rows,1):\n",
        "                for j in range(1):\n",
        "                    self.ax.append(fig.add_subplot(grid[i, j]))#, xticklabels=[])#, sharey=main_ax)\n",
        "\n",
        "            for ax_i in self.ax:\n",
        "                ax_i.set_ylim([20, 23])\n",
        "        self.first_test = True\n",
        "\n",
        "        \n",
        "        while True:   \n",
        "\n",
        "            \n",
        "\n",
        "            if self.verbose:\n",
        "                print('--------------------------') \n",
        "\n",
        "\n",
        "            self.load_batch_into_GPU()\n",
        "\n",
        "            if self.do_test == True:\n",
        "                self.test_all()\n",
        "                # self.batch_idx_test += 1\n",
        "                self.do_test = False\n",
        "\n",
        "            self.train_batch()\n",
        "            self.batch_idx_train += 1\n",
        "\n",
        "            if self.extract_model==True:\n",
        "                do_break = self.serialize_model()\n",
        "                if do_break:\n",
        "                    break\n",
        "\n",
        "            if self.n_step % self.n_test == 0:\n",
        "                self.do_test = True\n",
        "\n",
        "            if self.n_step % self.n_save_traced_module == 0:\n",
        "                self.extract_model = True\n",
        "\n",
        "            \n",
        "            best_loss_diff = (len(self.running_validation_loss)-np.nanargmin(np.array(self.running_validation_loss))-1)*self.n_save_traced_module\n",
        "            running_test_avg = torch.mean(torch.Tensor(self.prec_test[-self.n_running_avg:]))\n",
        "            add_args = [self.n_step, running_test_avg.item(), best_loss_diff, np.nanmin(np.array(self.running_validation_loss))]\n",
        "            progressbar(self.n_step,self.n_step_start,self.max_it_stop, add_args = add_args)\n",
        "                \n",
        "\n",
        "            \n",
        "            self.batch_train_counter += 1\n",
        "        #    \n",
        "            # print('--------------------------')\n",
        "            if self.n_step >= self.max_it_stop:\n",
        "                break\n",
        "\n",
        "            if time.time()-start_time>time_limit:\n",
        "                break\n",
        "\n",
        "    def display(self,str_input):\n",
        "\n",
        "        fill_str = \"#\"\n",
        "        n = 100\n",
        "        n_str_input = len(str_input)\n",
        "        n_fill_left = math.ceil((n-n_str_input)/2) - 1\n",
        "        n_fill_right = n-n_fill_left-n_str_input - 2\n",
        "        n_rows = 3\n",
        "        i_row = 1 #Index of row placement of input string\n",
        "\n",
        "        str_output = \"\"\n",
        "        for row in range(n_rows):\n",
        "            if row == i_row:\n",
        "                for j in range(n_fill_left):\n",
        "                    str_output += fill_str\n",
        "                str_output += \" \"\n",
        "                str_output += str_input\n",
        "                str_output += \" \"\n",
        "                for j in range(n_fill_right):\n",
        "                    str_output += fill_str\n",
        "                str_output += \"\\n\"\n",
        "            else:\n",
        "                for j in range(n):\n",
        "                    str_output += fill_str\n",
        "                str_output += \"\\n\"\n",
        "\n",
        "        print(str_output)\n",
        "\n",
        "\n",
        "\n",
        "    def sort_directory(self):\n",
        "        os.chdir(self.saved_serialized_networks_path)\n",
        "\n",
        "        running_validation_loss = np.array(self.running_validation_loss)\n",
        "        idx = np.argmin(running_validation_loss)\n",
        "        running_validation_loss_model_name_sorted = self.running_validation_loss_model_name[:]\n",
        "        running_validation_loss_model_name_sorted.pop(idx)\n",
        "\n",
        "        for filename in running_validation_loss_model_name_sorted:\n",
        "            try:\n",
        "                os.remove(filename)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        self.running_validation_loss = [self.running_validation_loss[idx]]\n",
        "        self.running_validation_loss_model_name = [self.running_validation_loss_model_name[idx]]\n",
        "        \n",
        "        np.save(self.running_validation_loss_filename_save + \".npy\",np.array(self.running_validation_loss))\n",
        "        np.save(self.running_validation_loss_model_name_filename_save + \".npy\",np.array(self.running_validation_loss_model_name))\n",
        "\n",
        "    def one_time_delete(self):\n",
        "        os.chdir(self.saved_serialized_networks_path)\n",
        "\n",
        "        running_validation_loss = np.array(self.running_validation_loss)\n",
        "        idx = np.argmin(running_validation_loss)\n",
        "\n",
        "        print(\"----\")\n",
        "        print(self.running_validation_loss_model_name)\n",
        "        print(self.running_validation_loss)\n",
        "\n",
        "        if running_validation_loss.size!=1:\n",
        "            \n",
        "\n",
        "            self.running_validation_loss = [self.running_validation_loss[idx]]\n",
        "            self.running_validation_loss_model_name = [self.running_validation_loss_model_name[idx]]\n",
        "\n",
        "            np.save(self.running_validation_loss_filename_save + \".npy\",np.array(self.running_validation_loss))\n",
        "            np.save(self.running_validation_loss_model_name_filename_save + \".npy\",np.array(self.running_validation_loss_model_name))\n",
        "\n",
        "        print(\"----\")\n",
        "        print(self.running_validation_loss_model_name)\n",
        "        print(self.running_validation_loss)\n",
        "\n",
        "def load_dataset_into_disk(data_paths):\n",
        "    file_batch = 2**9\n",
        "    (training_data_folder_name,\n",
        "    drive_zipped_training_data_path,\n",
        "    drive_unzipped_training_data_path,\n",
        "    vm_drive_unzip_data_path,\n",
        "    vm_drive_training_data_path) = data_paths\n",
        "    \n",
        "    print(drive_zipped_training_data_path)\n",
        "    print(vm_drive_unzip_data_path)\n",
        "    \n",
        "    if os.path.isdir(training_data_folder_name):\n",
        "        print(\"VM training directory already exists: Proceeding...\")\n",
        "    else:\n",
        "        print(\"Unzipping training directory...\")\n",
        "        command_str = \"unzip \\\"%s\\\" -d \\\"%s\\\" \" % (drive_zipped_training_data_path, vm_drive_unzip_data_path)\n",
        "        os.system(command_str)\n",
        "    \n",
        "    # os.chdir(vm_drive_training_data_path)\n",
        "    # filename =  \"saved_space_list\" + \".npz\"\n",
        "    # loaded = np.load(filename)\n",
        "    # saved_space_list = loaded[loaded.files[0]]\n",
        "    \n",
        "    \n",
        "    print(\"Loaded...\")\n",
        "    # new_saved_space_list = []\n",
        "\n",
        "    # print(\"Validating dataset...\")\n",
        "\n",
        "    # os.chdir(vm_drive_training_data_path)\n",
        "    # for i,space_name in enumerate(saved_space_list):\n",
        "        \n",
        "    #     filename1 = space_name + \"_validation_batch_%d.npz\" % file_batch\n",
        "    #     filename2 = space_name + \"_test_batch_%d.npz\" % file_batch\n",
        "    #     if os.path.isfile(filename1) and os.path.isfile(filename2):\n",
        "    #         load = True\n",
        "    #     else:\n",
        "    #         print(\"Can't load \\\"\" + space_name + \"\\\"\")\n",
        "    #         load = False\n",
        "\n",
        "    #     if load == False:\n",
        "    #         i = 0\n",
        "    #         while True:\n",
        "    #             name_idx = file_batch*i + file_batch\n",
        "    #             filename = space_name + \"_\" + \"training\" + \"_batch_%d.npz\" % (name_idx)\n",
        "    #             try:\n",
        "    #                 os.remove(filename)\n",
        "    #             except Exception as inst:\n",
        "    #                 break\n",
        "    #             i += 1\n",
        "\n",
        "    #     else:\n",
        "    #         new_saved_space_list.append(space_name)\n",
        "\n",
        "    # os.chdir(vm_drive_unzip_data_path)\n",
        "    # filename =  \"saved_space_list\" + \".npz\"\n",
        "    # np.savez_compressed(filename, np.array(new_saved_space_list))\n",
        "\n",
        "    # return new_saved_space_list\n",
        "\n",
        "\n",
        "def progressbar(current,start,stop, add_args=None):\n",
        "\n",
        "    \n",
        "\n",
        "    total_time = stop-start\n",
        "    relative_time = current-start\n",
        "\n",
        "    n_ticks_total = 40\n",
        "    n_ticks_current = math.ceil(relative_time/total_time*n_ticks_total)\n",
        "    percent_done = math.ceil(relative_time/total_time*100)\n",
        "\n",
        "    progress_str = '|'\n",
        "    for i in range(n_ticks_total):\n",
        "        if n_ticks_current > i:\n",
        "            progress_str += '#'\n",
        "        else:\n",
        "            progress_str += '-'\n",
        "    \n",
        "    if add_args:\n",
        "        progress_str += '| ' + str(percent_done) + '% '\n",
        "        for arg in add_args:\n",
        "            progress_str += \"-- \" + str(arg) + \" \"\n",
        "    else:\n",
        "        progress_str += '| ' + str(percent_done) + '% '\n",
        "\n",
        "\n",
        "    sys.stdout.write('\\r\\x1b[K' + progress_str)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "# !nvidia-smi\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "start_time = time.time()\n",
        "time_limit = 1e+10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "training_data_folder_name = \"space_model_batches\"\n",
        "drive_zipped_training_data_path = \"/content/drive/My Drive/Google collab/OU44_zipped\" + \"/\" + training_data_folder_name + \".zip\"\n",
        "drive_unzipped_training_data_path = \"/content/drive/My Drive/Google collab/OU44_LSTM_data_2048batch_-11norm_10min_144seq_filtered_test_relu/\"\n",
        "vm_drive_unzip_data_path = \"/content\"\n",
        "vm_drive_training_data_path = vm_drive_unzip_data_path + \"/\" + training_data_folder_name\n",
        "\n",
        "data_paths = (training_data_folder_name,\n",
        "            drive_zipped_training_data_path,\n",
        "            drive_unzipped_training_data_path,\n",
        "            vm_drive_unzip_data_path,\n",
        "            vm_drive_training_data_path)\n",
        "\n",
        "saved_space_list = load_dataset_into_disk(data_paths)\n",
        "\n",
        "# trainer.load_dataset_into_disk()\n",
        "# trainer.load_batch_into_GPU()\n",
        "# trainer.visualize_outputs()\n",
        "\n",
        "\n",
        "# trainer.load_batch_into_GPU()\n",
        "# trainer.get_input_gradients()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################################################\n",
        "# for i,space_name in enumerate(saved_space_list):\n",
        "#     # clear_output(wait=True)\n",
        "#     train = False\n",
        "#     try:\n",
        "#         trainer = Trainer(space_name, data_paths, load=True)\n",
        "#         running_validation_loss = np.array(trainer.running_validation_loss)\n",
        "\n",
        "#         if running_validation_loss.size==1:\n",
        "#             print(\"Space \\\"\" + space_name + \"\\\" exists and has size 1\")\n",
        "#             # print(trainer.running_validation_loss_model_name)\n",
        "\n",
        "#             best_idx = int(trainer.running_validation_loss_model_name[0].split(\"_step\")[1].split(\".pt\")[0])\n",
        "\n",
        "            \n",
        "#             best_loss_diff = trainer.n_step-best_idx\n",
        "#             if best_loss_diff>=trainer.best_loss_diff_max:\n",
        "#                 print(\"No improvement for the last \" + str(trainer.best_loss_diff_max) + \" iterations: Skipping...\")\n",
        "#             else:\n",
        "#                 train = True\n",
        "\n",
        "#         else:\n",
        "#             print(\"Space \\\"\" + space_name + \"\\\" exists but has size \" + str(running_validation_loss.size))\n",
        "#             trainer = Trainer(space_name, data_paths, load=True)\n",
        "#             train = True\n",
        "\n",
        "#     except Exception as inst:\n",
        "#         # print(inst)\n",
        "#         print(\"Can't load \\\"\" + space_name + \"\\\"\")\n",
        "#         trainer = Trainer(space_name, data_paths, load=False)\n",
        "#         train = True\n",
        "\n",
        "#     if train == True:\n",
        "#         print(\"Space number \" + str(i))\n",
        "#         trainer.load_min_max_scale_values()\n",
        "#         trainer.scan_directory()\n",
        "#         trainer.train(verbose=False)\n",
        "#         trainer.sort_directory()\n",
        "##################################################################\n",
        "# 20-601b-2\n",
        "# 22-511-2\n",
        "space_name = \"OE20-601b-2\"\n",
        "# space_name = \"OE22-511-2\"\n",
        "trainer = Trainer(space_name, data_paths, load=False, plot=False)\n",
        "trainer.scan_directory()\n",
        "trainer.train()\n",
        "trainer.sort_directory()\n",
        "\n",
        "\n",
        "\n",
        "# %mprun -f trainer.load_dataset_into_RAM trainer.load_dataset_into_RAM()\n",
        "# %lprun -f trainer.train_batch -f trainer.test_batch -f trainer.train -f trainer.load_batch_into_GPU trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yJ5dekd7bbI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X2FGJ3pKphH",
        "outputId": "77b939ba-c168-4253-d96a-fd050a9e015c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K|########################################| 100% "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import math\n",
        "\n",
        "def progressbar(current,start,stop, add_args=None):\n",
        "\n",
        "    \n",
        "\n",
        "    total_time = stop-start\n",
        "    relative_time = current-start\n",
        "\n",
        "    n_ticks_total = 40\n",
        "    n_ticks_current = math.ceil(relative_time/total_time*n_ticks_total)\n",
        "    percent_done = math.ceil(relative_time/total_time*100)\n",
        "\n",
        "    progress_str = '|'\n",
        "    for i in range(n_ticks_total):\n",
        "        if n_ticks_current > i:\n",
        "            progress_str += '#'\n",
        "        else:\n",
        "            progress_str += '-'\n",
        "    \n",
        "    if add_args:\n",
        "        progress_str += '| ' + str(percent_done) + '% '\n",
        "        for arg in add_args:\n",
        "            progress_str += \"-- \" + str(arg)\n",
        "    else:\n",
        "        progress_str += '| ' + str(percent_done) + '% '\n",
        "\n",
        "\n",
        "    sys.stdout.write('\\r\\x1b[K' + progress_str)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "for i in range(10000):\n",
        "    progressbar(i,0,10000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEJ-qclujS6y",
        "outputId": "24da54ac-ea8a-4f38-bac6-006c0895e6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31285 sha256=8beee7403bc291796459a59f64a8832243f92548bd659677491ff3f7f4322478\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.60.0\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/memory_profiler.py\", line 845, in enable\n",
            "    sys.settrace(self.trace_memory_usage)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOTAL NUMBER OF PARAMETERS IN MODEL: 2643209\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "0\n",
            "----\n",
            "4\n",
            "905969664\n",
            "3623878656\n",
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/memory_profiler.py\", line 848, in disable\n",
            "    sys.settrace(self._original_trace_function)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----\n",
            "4\n",
            "905969664\n",
            "3623878656\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from main import Trainer\n",
        "import psutil\n",
        "\n",
        "!pip install memory_profiler\n",
        "# !pip install psutil\n",
        "%load_ext memory_profiler\n",
        "\n",
        "trainer = Trainer()\n",
        "%mprun -f trainer.load_dataset_into_RAM trainer.load_dataset_into_RAM()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsKy5oYHU47i",
        "outputId": "61f29e4a-e3db-4431-da06-7fd45d7f6f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}