{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzeRCkJLDcBW",
        "outputId": "54a2a19e-c7c2-45e7-e89d-21045cc70ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Google collab/OU44_zipped/space_model_batches.zip\n",
            "/content\n",
            "Unzipping training directory...\n",
            "Loaded...\n",
            "INPUT\n",
            "9\n",
            "TOTAL NUMBER OF PARAMETERS IN MODEL: 593\n",
            "--------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0239804182\n",
            "Avg MSE: 2.6743078232\n",
            "Avg MAE: 1.3046566248\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0216435529\n",
            "Avg MSE: 2.6545255184\n",
            "Avg MAE: 1.3084338903\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0250313543\n",
            "Avg MSE: 2.5836865902\n",
            "Avg MAE: 1.2772541046\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0233843103\n",
            "Avg MSE: 2.4700951576\n",
            "Avg MAE: 1.2610926628\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0237174071\n",
            "Avg MSE: 2.7025716305\n",
            "Avg MAE: 1.3025844097\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223503858\n",
            "Avg MSE: 2.6724662781\n",
            "Avg MAE: 1.3051202297\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0230381526\n",
            "Avg MSE: 2.7215960026\n",
            "Avg MAE: 1.3059551716\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0234450139\n",
            "Avg MSE: 2.6115252972\n",
            "Avg MAE: 1.2857429981\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0233485959\n",
            "Avg MSE: 2.6403398514\n",
            "Avg MAE: 1.2990754843\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0235904232\n",
            "Avg MSE: 2.6735177040\n",
            "Avg MAE: 1.3089121580\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226888228\n",
            "Avg MSE: 2.5343880653\n",
            "Avg MAE: 1.2700774670\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_15872.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0347807035\n",
            "\u001b[K|#---------------------------------------| 1% -- 16 -- 0.023292584344744682 -- 16 -- 0.023292588 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_18944.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0189798791\n",
            "\u001b[K|#---------------------------------------| 1% -- 32 -- 0.023292584344744682 -- 32 -- 0.023292588 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_14336.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0172949769\n",
            "\u001b[K|#---------------------------------------| 1% -- 48 -- 0.023292584344744682 -- 48 -- 0.023292588 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_2560.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0186175145\n",
            "\u001b[K|#---------------------------------------| 1% -- 64 -- 0.023292584344744682 -- 64 -- 0.023292588 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0229280479\n",
            "Avg MSE: 0.7686450481\n",
            "Avg MAE: 0.5874602795\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0206346214\n",
            "Avg MSE: 0.6627728939\n",
            "Avg MAE: 0.5546098948\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0239181742\n",
            "Avg MSE: 0.6981338859\n",
            "Avg MAE: 0.5713331699\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223126970\n",
            "Avg MSE: 0.7405647635\n",
            "Avg MAE: 0.5738891363\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226911549\n",
            "Avg MSE: 0.8318683505\n",
            "Avg MAE: 0.6055086255\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0213509109\n",
            "Avg MSE: 0.8240259886\n",
            "Avg MAE: 0.5912235975\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220320653\n",
            "Avg MSE: 0.7885723710\n",
            "Avg MAE: 0.5747941136\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0224698409\n",
            "Avg MSE: 0.7677373290\n",
            "Avg MAE: 0.5931117535\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223643910\n",
            "Avg MSE: 0.6581322551\n",
            "Avg MAE: 0.5470632911\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0225584097\n",
            "Avg MSE: 0.7182804346\n",
            "Avg MAE: 0.5736130476\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0217113029\n",
            "Avg MSE: 0.7271433473\n",
            "Avg MAE: 0.5764700770\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_5632.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0173325539\n",
            "\u001b[K|#---------------------------------------| 1% -- 80 -- 0.022270148620009422 -- 16 -- 0.022270147 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_13312.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0179529358\n",
            "\u001b[K|#---------------------------------------| 1% -- 96 -- 0.022270148620009422 -- 32 -- 0.022270147 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_14848.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0188339129\n",
            "\u001b[K|#---------------------------------------| 1% -- 112 -- 0.022270148620009422 -- 48 -- 0.022270147 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_6144.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0190337766\n",
            "\u001b[K|#---------------------------------------| 1% -- 128 -- 0.022270148620009422 -- 64 -- 0.022270147 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0228317194\n",
            "Avg MSE: 1.1510467529\n",
            "Avg MAE: 0.7720957398\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0205416866\n",
            "Avg MSE: 1.0559432507\n",
            "Avg MAE: 0.7497002482\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0238102544\n",
            "Avg MSE: 1.1079481840\n",
            "Avg MAE: 0.7685505152\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222154465\n",
            "Avg MSE: 1.1543797255\n",
            "Avg MAE: 0.7657252550\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0225888565\n",
            "Avg MSE: 1.2547624111\n",
            "Avg MAE: 0.8139722347\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0212591421\n",
            "Avg MSE: 1.2667820454\n",
            "Avg MAE: 0.7963151336\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0219466742\n",
            "Avg MSE: 1.1501103640\n",
            "Avg MAE: 0.7620363832\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223888326\n",
            "Avg MSE: 1.2442009449\n",
            "Avg MAE: 0.8163115978\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222552326\n",
            "Avg MSE: 0.9643439054\n",
            "Avg MAE: 0.7162660360\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0224681012\n",
            "Avg MSE: 1.0941776037\n",
            "Avg MAE: 0.7666928768\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0216146410\n",
            "Avg MSE: 1.1531784534\n",
            "Avg MAE: 0.7811383009\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_19456.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0187295694\n",
            "\u001b[K|#---------------------------------------| 1% -- 144 -- 0.022174596786499023 -- 16 -- 0.022174599 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_16384.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0196185242\n",
            "\u001b[K|#---------------------------------------| 1% -- 160 -- 0.022174596786499023 -- 32 -- 0.022174599 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_15360.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0192043614\n",
            "\u001b[K|#---------------------------------------| 1% -- 176 -- 0.022174596786499023 -- 48 -- 0.022174599 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_10752.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0188290887\n",
            "\u001b[K|#---------------------------------------| 1% -- 192 -- 0.022174596786499023 -- 64 -- 0.022174599 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226954743\n",
            "Avg MSE: 1.0711743832\n",
            "Avg MAE: 0.7313947678\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0204121582\n",
            "Avg MSE: 0.9428009391\n",
            "Avg MAE: 0.7011513114\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0236677453\n",
            "Avg MSE: 1.0037114620\n",
            "Avg MAE: 0.7190816402\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220750086\n",
            "Avg MSE: 1.0371338129\n",
            "Avg MAE: 0.7120704055\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0224570073\n",
            "Avg MSE: 1.1978936195\n",
            "Avg MAE: 0.7759873867\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0211449768\n",
            "Avg MSE: 1.1812632084\n",
            "Avg MAE: 0.7464245558\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0218277723\n",
            "Avg MSE: 1.0789765120\n",
            "Avg MAE: 0.7230166197\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222603790\n",
            "Avg MSE: 1.1195696592\n",
            "Avg MAE: 0.7587040663\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0221184064\n",
            "Avg MSE: 0.8756270409\n",
            "Avg MAE: 0.6716890335\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223345086\n",
            "Avg MSE: 1.0001696348\n",
            "Avg MAE: 0.7203772664\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214832667\n",
            "Avg MSE: 1.0648390055\n",
            "Avg MAE: 0.7310145497\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_20480.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0186351892\n",
            "\u001b[K|#---------------------------------------| 1% -- 208 -- 0.022043336182832718 -- 16 -- 0.022043336 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_1536.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0173228979\n",
            "\u001b[K|#---------------------------------------| 1% -- 224 -- 0.022043336182832718 -- 32 -- 0.022043336 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_21504.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0184788425\n",
            "\u001b[K|#---------------------------------------| 1% -- 240 -- 0.022043336182832718 -- 48 -- 0.022043336 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_9728.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0183363557\n",
            "\u001b[K|#---------------------------------------| 1% -- 256 -- 0.022043336182832718 -- 64 -- 0.022043336 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0227116570\n",
            "Avg MSE: 2.0929112434\n",
            "Avg MAE: 0.9591844678\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0204396471\n",
            "Avg MSE: 1.9944696426\n",
            "Avg MAE: 0.9247917533\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0236895289\n",
            "Avg MSE: 2.0487923622\n",
            "Avg MAE: 0.9454446435\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220831484\n",
            "Avg MSE: 1.8951144218\n",
            "Avg MAE: 0.9120659232\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0224704929\n",
            "Avg MSE: 2.3505764008\n",
            "Avg MAE: 1.0058231354\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0211353805\n",
            "Avg MSE: 2.0790016651\n",
            "Avg MAE: 0.9443119168\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0218335427\n",
            "Avg MSE: 1.7444006205\n",
            "Avg MAE: 0.8668563366\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222599469\n",
            "Avg MSE: 2.0298600197\n",
            "Avg MAE: 0.9604945183\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0221230499\n",
            "Avg MSE: 1.8535600901\n",
            "Avg MAE: 0.8959403038\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223479178\n",
            "Avg MSE: 1.9716608524\n",
            "Avg MAE: 0.9342043996\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214855988\n",
            "Avg MSE: 2.0631330013\n",
            "Avg MAE: 0.9335460663\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_8192.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0182624403\n",
            "\u001b[K|#---------------------------------------| 1% -- 272 -- 0.022052718326449394 -- 80 -- 0.022043336 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_11776.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0184317045\n",
            "\u001b[K|#---------------------------------------| 1% -- 288 -- 0.022052718326449394 -- 96 -- 0.022043336 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_8704.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0168001745\n",
            "\u001b[K|#---------------------------------------| 1% -- 304 -- 0.022052718326449394 -- 112 -- 0.022043336 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_19968.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0186204556\n",
            "\u001b[K|#---------------------------------------| 1% -- 320 -- 0.022052718326449394 -- 128 -- 0.022043336 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226263925\n",
            "Avg MSE: 1.3630375862\n",
            "Avg MAE: 0.8005630374\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0203540474\n",
            "Avg MSE: 1.2611312866\n",
            "Avg MAE: 0.7766306996\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0235921424\n",
            "Avg MSE: 1.3283047676\n",
            "Avg MAE: 0.7981505394\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220011082\n",
            "Avg MSE: 1.2699812651\n",
            "Avg MAE: 0.7722239494\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223893672\n",
            "Avg MSE: 1.5569646358\n",
            "Avg MAE: 0.8518329859\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0210897811\n",
            "Avg MSE: 1.4805190563\n",
            "Avg MAE: 0.8188434839\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0217705928\n",
            "Avg MSE: 1.2923141718\n",
            "Avg MAE: 0.7790855765\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0221902542\n",
            "Avg MSE: 1.3765795231\n",
            "Avg MAE: 0.8184458017\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220526587\n",
            "Avg MSE: 1.1429796219\n",
            "Avg MAE: 0.7414757609\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222659148\n",
            "Avg MSE: 1.2866402864\n",
            "Avg MAE: 0.7904609442\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214179065\n",
            "Avg MSE: 1.4015412331\n",
            "Avg MAE: 0.7983188629\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_4608.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0187062826\n",
            "\u001b[K|#---------------------------------------| 1% -- 336 -- 0.021977288648486137 -- 16 -- 0.021977289 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_7168.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0184441581\n",
            "\u001b[K|#---------------------------------------| 1% -- 352 -- 0.021977288648486137 -- 32 -- 0.021977289 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_3072.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0181220025\n",
            "\u001b[K|#---------------------------------------| 1% -- 368 -- 0.021977288648486137 -- 48 -- 0.021977289 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_9216.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0180255044\n",
            "\u001b[K|#---------------------------------------| 1% -- 384 -- 0.021977288648486137 -- 64 -- 0.021977289 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226104278\n",
            "Avg MSE: 1.1158567667\n",
            "Avg MAE: 0.7252393961\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0203355253\n",
            "Avg MSE: 0.9918299317\n",
            "Avg MAE: 0.6928067803\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0235791802\n",
            "Avg MSE: 1.0650228262\n",
            "Avg MAE: 0.7183244228\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0219894201\n",
            "Avg MSE: 1.0446325541\n",
            "Avg MAE: 0.6965569258\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223733895\n",
            "Avg MSE: 1.2751606703\n",
            "Avg MAE: 0.7732505798\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0210734047\n",
            "Avg MSE: 1.2169188261\n",
            "Avg MAE: 0.7398344874\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0217563529\n",
            "Avg MSE: 1.0941410065\n",
            "Avg MAE: 0.7159566879\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0221789200\n",
            "Avg MSE: 1.1322693825\n",
            "Avg MAE: 0.7426806092\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220375191\n",
            "Avg MSE: 0.9139642715\n",
            "Avg MAE: 0.6684502959\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222474076\n",
            "Avg MSE: 1.0420829058\n",
            "Avg MAE: 0.7142719626\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214046165\n",
            "Avg MSE: 1.1345157623\n",
            "Avg MAE: 0.7240502238\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_16896.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0180463567\n",
            "\u001b[K|#---------------------------------------| 1% -- 400 -- 0.021962376311421394 -- 16 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_7680.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0193006285\n",
            "\u001b[K|#---------------------------------------| 1% -- 416 -- 0.021962376311421394 -- 32 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_18432.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0176091548\n",
            "\u001b[K|#---------------------------------------| 1% -- 432 -- 0.021962376311421394 -- 48 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_4096.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0197354630\n",
            "\u001b[K|#---------------------------------------| 1% -- 448 -- 0.021962376311421394 -- 64 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226683989\n",
            "Avg MSE: 2.0241281986\n",
            "Avg MAE: 0.9114549160\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0203949288\n",
            "Avg MSE: 1.9356112480\n",
            "Avg MAE: 0.8795225024\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0236251336\n",
            "Avg MSE: 1.9566733837\n",
            "Avg MAE: 0.8986499906\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220297351\n",
            "Avg MSE: 1.7989896536\n",
            "Avg MAE: 0.8656168580\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0224313289\n",
            "Avg MSE: 2.3365826607\n",
            "Avg MAE: 0.9767110944\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0211038161\n",
            "Avg MSE: 2.0741569996\n",
            "Avg MAE: 0.9111368656\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0217891876\n",
            "Avg MSE: 1.7207906246\n",
            "Avg MAE: 0.8447209597\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222085007\n",
            "Avg MSE: 1.9434468746\n",
            "Avg MAE: 0.9148350954\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220751110\n",
            "Avg MSE: 1.7829134464\n",
            "Avg MAE: 0.8521199822\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222877022\n",
            "Avg MSE: 1.9155893326\n",
            "Avg MAE: 0.8906158209\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214446653\n",
            "Avg MSE: 2.0539927483\n",
            "Avg MAE: 0.8921456337\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_17920.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0186739191\n",
            "\u001b[K|#---------------------------------------| 1% -- 464 -- 0.022005317732691765 -- 80 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_1024.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0189805180\n",
            "\u001b[K|#---------------------------------------| 1% -- 480 -- 0.022005317732691765 -- 96 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_13824.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0183006842\n",
            "\u001b[K|#---------------------------------------| 1% -- 496 -- 0.022005317732691765 -- 112 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_6656.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0189606175\n",
            "\u001b[K|#---------------------------------------| 1% -- 512 -- 0.022005317732691765 -- 128 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226236451\n",
            "Avg MSE: 1.4568848610\n",
            "Avg MAE: 0.8096285462\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0203448460\n",
            "Avg MSE: 1.3048059940\n",
            "Avg MAE: 0.7676537633\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0235706009\n",
            "Avg MSE: 1.3697067499\n",
            "Avg MAE: 0.7964212298\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0219890028\n",
            "Avg MSE: 1.3532129526\n",
            "Avg MAE: 0.7773443460\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223926157\n",
            "Avg MSE: 1.6683014631\n",
            "Avg MAE: 0.8663353324\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0210836343\n",
            "Avg MSE: 1.5786511898\n",
            "Avg MAE: 0.8232522011\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0217667427\n",
            "Avg MSE: 1.3887643814\n",
            "Avg MAE: 0.7888119817\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0221809112\n",
            "Avg MSE: 1.4310376644\n",
            "Avg MAE: 0.8205357790\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220408440\n",
            "Avg MSE: 1.2327767611\n",
            "Avg MAE: 0.7525858283\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222432427\n",
            "Avg MSE: 1.3713103533\n",
            "Avg MAE: 0.7964920998\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214108303\n",
            "Avg MSE: 1.4893163443\n",
            "Avg MAE: 0.8018504977\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_17408.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0192424953\n",
            "\u001b[K|#---------------------------------------| 1% -- 528 -- 0.021967900916934013 -- 144 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_12800.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0185900740\n",
            "\u001b[K|#---------------------------------------| 1% -- 544 -- 0.021967900916934013 -- 160 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_3584.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0175578557\n",
            "\u001b[K|#---------------------------------------| 1% -- 560 -- 0.021967900916934013 -- 176 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_12288.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0180712268\n",
            "\u001b[K|#---------------------------------------| 1% -- 576 -- 0.021967900916934013 -- 192 -- 0.021962376 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226081870\n",
            "Avg MSE: 1.1473424435\n",
            "Avg MAE: 0.7173658609\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0203345418\n",
            "Avg MSE: 1.0027854443\n",
            "Avg MAE: 0.6761988401\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0235685203\n",
            "Avg MSE: 1.0763529539\n",
            "Avg MAE: 0.7050163746\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0219821949\n",
            "Avg MSE: 1.0639418364\n",
            "Avg MAE: 0.6858343482\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223768353\n",
            "Avg MSE: 1.3041342497\n",
            "Avg MAE: 0.7632439733\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0210679770\n",
            "Avg MSE: 1.2349731922\n",
            "Avg MAE: 0.7242413759\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0217574760\n",
            "Avg MSE: 1.1104135513\n",
            "Avg MAE: 0.7015993595\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0221701618\n",
            "Avg MSE: 1.1414552927\n",
            "Avg MAE: 0.7293968797\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220387354\n",
            "Avg MSE: 0.9500156641\n",
            "Avg MAE: 0.6618553400\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222361479\n",
            "Avg MSE: 1.0690141916\n",
            "Avg MAE: 0.7033599615\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214025695\n",
            "Avg MSE: 1.1598019600\n",
            "Avg MAE: 0.7095675468\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_11264.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0182393920\n",
            "\u001b[K|#---------------------------------------| 1% -- 592 -- 0.0219584871083498 -- 16 -- 0.021958485 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_10240.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0179550219\n",
            "\u001b[K|#---------------------------------------| 1% -- 608 -- 0.0219584871083498 -- 32 -- 0.021958485 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_5120.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0192126650\n",
            "\u001b[K|#---------------------------------------| 1% -- 624 -- 0.0219584871083498 -- 48 -- 0.021958485 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_20992.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0181394033\n",
            "\u001b[K|#---------------------------------------| 1% -- 640 -- 0.0219584871083498 -- 64 -- 0.021958485 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226167683\n",
            "Avg MSE: 0.9716108441\n",
            "Avg MAE: 0.6606175900\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0203473791\n",
            "Avg MSE: 0.8523876071\n",
            "Avg MAE: 0.6265018582\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0235897098\n",
            "Avg MSE: 0.9139061570\n",
            "Avg MAE: 0.6494395137\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0219944939\n",
            "Avg MSE: 0.9006983042\n",
            "Avg MAE: 0.6321773529\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0223823190\n",
            "Avg MSE: 1.0997272730\n",
            "Avg MAE: 0.7008243799\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0210699327\n",
            "Avg MSE: 1.0410199165\n",
            "Avg MAE: 0.6626273990\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0217605699\n",
            "Avg MSE: 0.9411047697\n",
            "Avg MAE: 0.6434550285\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0221814625\n",
            "Avg MSE: 0.9958922863\n",
            "Avg MAE: 0.6781835556\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220485311\n",
            "Avg MSE: 0.7919932604\n",
            "Avg MAE: 0.6047669649\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222504660\n",
            "Avg MSE: 0.8983104825\n",
            "Avg MAE: 0.6453579664\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214123577\n",
            "Avg MSE: 0.9677567482\n",
            "Avg MAE: 0.6533985734\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_2048.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0180548970\n",
            "\u001b[K|#---------------------------------------| 1% -- 656 -- 0.021968545392155647 -- 80 -- 0.021958485 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_512.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0167067759\n",
            "\u001b[K|#---------------------------------------| 1% -- 672 -- 0.021968545392155647 -- 96 -- 0.021958485 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_5120.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0192124248\n",
            "\u001b[K|#---------------------------------------| 1% -- 688 -- 0.021968545392155647 -- 112 -- 0.021958485 --------------------------\n",
            "LOADED: OE20-601b-2_training_batch_7168.npz\n",
            "---Training batch results---\n",
            "Avg loss: 0.0184152406\n",
            "\u001b[K|#---------------------------------------| 1% -- 704 -- 0.021968545392155647 -- 128 -- 0.021958485 --------------------------\n",
            "LOADED: OE20-601b-2_validation_batch_512.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0226471554\n",
            "Avg MSE: 1.9114372730\n",
            "Avg MAE: 0.8682761788\n",
            "LOADED: OE20-601b-2_validation_batch_1024.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0203846637\n",
            "Avg MSE: 1.8142184019\n",
            "Avg MAE: 0.8366524577\n",
            "LOADED: OE20-601b-2_validation_batch_1536.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0236163009\n",
            "Avg MSE: 1.8367905617\n",
            "Avg MAE: 0.8538696766\n",
            "LOADED: OE20-601b-2_validation_batch_2048.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220118631\n",
            "Avg MSE: 1.6830923557\n",
            "Avg MAE: 0.8194320798\n",
            "LOADED: OE20-601b-2_validation_batch_2560.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0224181674\n",
            "Avg MSE: 2.1950993538\n",
            "Avg MAE: 0.9324777126\n",
            "LOADED: OE20-601b-2_validation_batch_3072.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0210847426\n",
            "Avg MSE: 1.9208682775\n",
            "Avg MAE: 0.8576776385\n",
            "LOADED: OE20-601b-2_validation_batch_3584.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0217850674\n",
            "Avg MSE: 1.6164901257\n",
            "Avg MAE: 0.8006522655\n",
            "LOADED: OE20-601b-2_validation_batch_4096.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0221914649\n",
            "Avg MSE: 1.8495490551\n",
            "Avg MAE: 0.8718863130\n",
            "LOADED: OE20-601b-2_validation_batch_4608.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0220582299\n",
            "Avg MSE: 1.6877864599\n",
            "Avg MAE: 0.8164413571\n",
            "LOADED: OE20-601b-2_validation_batch_5120.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0222601928\n",
            "Avg MSE: 1.7986680269\n",
            "Avg MAE: 0.8483865857\n",
            "LOADED: OE20-601b-2_validation_batch_5632.npz\n",
            "32\n",
            "---Testing batch results---\n",
            "Avg loss: 0.0214271583\n",
            "Avg MSE: 1.8963901997\n",
            "Avg MAE: 0.8431659341\n",
            "Saved serialized module\n",
            "LOADED: OE20-601b-2_training_batch_1536.npz\n"
          ]
        }
      ],
      "source": [
        "# %%file main.py\n",
        "\"\"\"\n",
        "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!pip install torchvision\n",
        "!pip install torch==1.4.0\n",
        "!pip install torchaudio==0.4.0\n",
        "%matplotlib inline\n",
        "!python pytorch-xla-env-setup.py --version $VERSION\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# !pip install torch_intermediate_layer_getter\n",
        "# from torch_intermediate_layer_getter import IntermediateLayerGetter as MidGetter\n",
        "\n",
        "\n",
        "# !pip install line_profiler\n",
        "# %load_ext line_profiler\n",
        "\n",
        "#standard\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import math\n",
        "import sys\n",
        "\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "\n",
        "\n",
        "#torch\n",
        "import torch\n",
        "import torch.jit as jit\n",
        "from torch import Tensor\n",
        "import torchvision\n",
        "\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import pickle\n",
        "\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "\n",
        "# !pip install py-heat-magic\n",
        "# %load_ext heat\n",
        "\n",
        "\n",
        "\n",
        "# !pip install memory_profiler\n",
        "# %load_ext memory_profiler\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "\n",
        "\n",
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def loss_penalized(output, target, x, input):\n",
        "    (x_OUTDOORTEMPERATURE_input,\n",
        "        x_RADIATION_input,\n",
        "        x_SPACEHEATER_input,\n",
        "        x_VENTILATION_input) = input\n",
        "\n",
        "    \n",
        "\n",
        "    (x_OUTDOORTEMPERATURE_output, x_RADIATION_output, x_SPACEHEATER_output, x_VENTILATION_output) = x\n",
        "\n",
        "\n",
        "    tol = 1e-8\n",
        "\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_output = torch.zeros(x_OUTDOORTEMPERATURE_output.shape).cuda()\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_output[:,1:] = x_OUTDOORTEMPERATURE_output[:,1:]-x_OUTDOORTEMPERATURE_output[:,:-1]\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_input_0 = torch.zeros(x_OUTDOORTEMPERATURE_output.shape).cuda()\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_input_0[:,1:,0] = x_OUTDOORTEMPERATURE_input[:,1:,0]-x_OUTDOORTEMPERATURE_input[:,:-1,0]\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_input_1 = torch.zeros(x_OUTDOORTEMPERATURE_output.shape).cuda()\n",
        "    # DELTA_x_OUTDOORTEMPERATURE_input_1[:,1:,0] = x_OUTDOORTEMPERATURE_input[:,1:,1]-x_OUTDOORTEMPERATURE_input[:,:-1,1]\n",
        "    # bool_arr_grad_neg = torch.logical_and(DELTA_x_OUTDOORTEMPERATURE_input_0 > -tol, DELTA_x_OUTDOORTEMPERATURE_input_1 < tol)\n",
        "    # bool_arr_grad_pos = torch.logical_and(DELTA_x_OUTDOORTEMPERATURE_input_0 < tol, DELTA_x_OUTDOORTEMPERATURE_input_1 > -tol)\n",
        "    # loss_OUTDOORTEMPERATURE = torch.zeros(x_OUTDOORTEMPERATURE_output.shape).cuda()\n",
        "    # loss_OUTDOORTEMPERATURE[bool_arr_grad_neg] = torch.relu(DELTA_x_OUTDOORTEMPERATURE_output[bool_arr_grad_neg])\n",
        "    # loss_OUTDOORTEMPERATURE[bool_arr_grad_pos] = torch.relu(-DELTA_x_OUTDOORTEMPERATURE_output[bool_arr_grad_pos])\n",
        "\n",
        "\n",
        "    grad_OUTDOORTEMPERATURE = torch.autograd.grad(\n",
        "            x_OUTDOORTEMPERATURE_output, x_OUTDOORTEMPERATURE_input,\n",
        "            grad_outputs=torch.ones_like(x_OUTDOORTEMPERATURE_output),\n",
        "            retain_graph=True,\n",
        "            create_graph=True\n",
        "        )[0]\n",
        "    loss_OUTDOORTEMPERATURE_0 = torch.relu(grad_OUTDOORTEMPERATURE[:,:,0].unsqueeze(2))\n",
        "    loss_OUTDOORTEMPERATURE_1 = torch.relu(-grad_OUTDOORTEMPERATURE[:,:,1].unsqueeze(2))\n",
        "    # loss_OUTDOORTEMPERATURE_2 = torch.relu(-grad_OUTDOORTEMPERATURE[:,:,2].unsqueeze(2))\n",
        "    # loss_OUTDOORTEMPERATURE_3 = torch.relu(-grad_OUTDOORTEMPERATURE[:,:,3].unsqueeze(2))\n",
        "    # loss_OUTDOORTEMPERATURE_4 = torch.relu(-grad_OUTDOORTEMPERATURE[:,:,4].unsqueeze(2))\n",
        "\n",
        "\n",
        "    # loss_RADIATION = torch.zeros(x_RADIATION_output.shape).to(DEVICE)\n",
        "    # bool_arr = x_RADIATION_input[:,:,0] < tol\n",
        "    # loss_RADIATION[bool_arr] = torch.abs(x_RADIATION_output[bool_arr])\n",
        "    grad_RADIATION = torch.autograd.grad(\n",
        "            x_RADIATION_output, x_RADIATION_input,\n",
        "            grad_outputs=torch.ones_like(x_RADIATION_output),\n",
        "            retain_graph=True,\n",
        "            create_graph=True\n",
        "        )[0]\n",
        "    loss_RADIATION_0 = torch.relu(-grad_RADIATION[:,:,0].unsqueeze(2))\n",
        "\n",
        "    DELTA_x_SPACEHEATER_output = torch.zeros(x_SPACEHEATER_output.shape).to(DEVICE)\n",
        "    DELTA_x_SPACEHEATER_output[:,1:] = x_SPACEHEATER_output[:,1:]-x_SPACEHEATER_output[:,:-1]\n",
        "    bool_arr_grad = torch.logical_and(x_SPACEHEATER_input[:,:,1] < tol, x_SPACEHEATER_output[:,:,0] > tol)\n",
        "    # bool_arr_constant = torch.logical_and(torch.abs(DELTA_x_SPACEHEATER_output[:,:,0]) < tol, x_SPACEHEATER_input[:,:,1] < tol)\n",
        "    loss_SPACEHEATER = torch.zeros(x_SPACEHEATER_output.shape).to(DEVICE)\n",
        "    loss_SPACEHEATER[bool_arr_grad] = torch.relu(DELTA_x_SPACEHEATER_output[bool_arr_grad])\n",
        "    # loss_SPACEHEATER[bool_arr_constant] = torch.relu(x_SPACEHEATER_output[bool_arr_constant])\n",
        "\n",
        "    grad_SPACEHEATER = torch.autograd.grad(\n",
        "            x_SPACEHEATER_output, x_SPACEHEATER_input,\n",
        "            grad_outputs=torch.ones_like(x_SPACEHEATER_output),\n",
        "            retain_graph=True,\n",
        "            create_graph=True\n",
        "        )[0]\n",
        "    loss_SPACEHEATER_0 = torch.relu(grad_SPACEHEATER[:,:,0].unsqueeze(2))\n",
        "    loss_SPACEHEATER_1 = torch.relu(-grad_SPACEHEATER[:,:,1].unsqueeze(2))\n",
        "    # loss_SPACEHEATER_2 = torch.relu(-grad_SPACEHEATER[:,:,2].unsqueeze(2))\n",
        "\n",
        "\n",
        "\n",
        "    loss_VENTILATION = torch.zeros(x_VENTILATION_output.shape).to(DEVICE)\n",
        "    bool_arr = x_VENTILATION_input[:,:,1] < tol\n",
        "    loss_VENTILATION[bool_arr] = torch.abs(x_VENTILATION_output[bool_arr])\n",
        "\n",
        "    grad_VENTILATION = torch.autograd.grad(\n",
        "            x_VENTILATION_output, x_VENTILATION_input,\n",
        "            grad_outputs=torch.ones_like(x_VENTILATION_output),\n",
        "            retain_graph=True,\n",
        "            create_graph=True\n",
        "        )[0]\n",
        "    loss_VENTILATION_0 = torch.relu(-grad_VENTILATION[:,:,0].unsqueeze(2))\n",
        "    loss_VENTILATION_1 = torch.relu(grad_VENTILATION[:,:,1].unsqueeze(2))\n",
        "    # loss_VENTILATION_2 = torch.relu(-grad_VENTILATION[:,:,2].unsqueeze(2))\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    K = 1\n",
        "    loss = torch.mean(\n",
        "        (output - target)**2 + \n",
        "        K*torch.relu(-x_SPACEHEATER_output) + \n",
        "        K*torch.relu(-x_RADIATION_output) + \n",
        "        # K*loss_OUTDOORTEMPERATURE + \n",
        "        K*loss_OUTDOORTEMPERATURE_0 + \n",
        "        K*loss_OUTDOORTEMPERATURE_1 + \n",
        "        # K*loss_OUTDOORTEMPERATURE_2 + \n",
        "        # K*loss_OUTDOORTEMPERATURE_3 + \n",
        "        # K*loss_OUTDOORTEMPERATURE_4 + \n",
        "        # K*loss_RADIATION + \n",
        "        K*loss_RADIATION_0 + \n",
        "        K*loss_SPACEHEATER + \n",
        "        K*loss_SPACEHEATER_0 + \n",
        "        K*loss_SPACEHEATER_1 +\n",
        "        # K*loss_SPACEHEATER_2 +\n",
        "        # K*loss_VENTILATION +\n",
        "        K*loss_VENTILATION_0 + \n",
        "        K*loss_VENTILATION_1)\n",
        "        \n",
        "    return loss\n",
        "\n",
        "# class LSTM(jit.ScriptModule):\n",
        "class LSTM(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 n_input=None, \n",
        "                 n_lstm_hidden=None, \n",
        "                 n_lstm_layers=None, \n",
        "                 n_output=None, \n",
        "                 dropout=None,\n",
        "                 scaling_value_dict=None):\n",
        "\n",
        "        self.kwargs = {\"n_input\": n_input,\n",
        "                        \"n_lstm_hidden\": n_lstm_hidden,\n",
        "                        \"n_lstm_layers\": n_lstm_layers,\n",
        "                        \"n_output\": n_output,\n",
        "                        \"dropout\": dropout,\n",
        "                        \"scaling_value_dict\": scaling_value_dict}\n",
        "        \n",
        "        self.n_input = n_input\n",
        "    \n",
        "        (self.n_lstm_hidden_OUTDOORTEMPERATURE,\n",
        "        self.n_lstm_hidden_RADIATION,\n",
        "        self.n_lstm_hidden_SPACEHEATER,\n",
        "        self.n_lstm_hidden_VENTILATION) = n_lstm_hidden\n",
        "        \n",
        "\n",
        "        (self.n_lstm_layers_OUTDOORTEMPERATURE,\n",
        "        self.n_lstm_layers_RADIATION,\n",
        "        self.n_lstm_layers_SPACEHEATER,\n",
        "        self.n_lstm_layers_VENTILATION) = n_lstm_layers\n",
        "\n",
        "        self.n_output = n_output\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        # self.lstm_hidden1_OUTDOORTEMPERATURE = torch.nn.LSTM(self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_layers_OUTDOORTEMPERATURE, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        # self.lstm_hidden2_OUTDOORTEMPERATURE = torch.nn.LSTM(self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_layers_OUTDOORTEMPERATURE, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        # self.lstm_hidden3_OUTDOORTEMPERATURE = torch.nn.LSTM(self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_layers_OUTDOORTEMPERATURE, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_input_OUTDOORTEMPERATURE = torch.nn.LSTM(2, self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_lstm_layers_OUTDOORTEMPERATURE, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_output_OUTDOORTEMPERATURE = torch.nn.LSTM(self.n_lstm_hidden_OUTDOORTEMPERATURE, self.n_output, 1, batch_first=True, bias=False)\n",
        "\n",
        "\n",
        "        # self.T_w_in__cp = torch.nn.Parameter(torch.randn(1))\n",
        "        # self.m_w_max = torch.nn.Parameter(torch.randn(1))\n",
        "        # self.UA = torch.nn.Parameter(torch.randn(1))\n",
        "\n",
        "        # self.lstm_hidden1_RADIATION = torch.nn.LSTM(self.n_lstm_hidden_RADIATION, self.n_lstm_hidden_RADIATION, self.n_lstm_layers_RADIATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        # self.lstm_hidden2_RADIATION = torch.nn.LSTM(self.n_lstm_hidden_RADIATION, self.n_lstm_hidden_RADIATION, self.n_lstm_layers_RADIATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        # self.lstm_hidden3_RADIATION = torch.nn.LSTM(self.n_lstm_hidden_RADIATION, self.n_lstm_hidden_RADIATION, self.n_lstm_layers_RADIATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_input_RADIATION = torch.nn.LSTM(1, self.n_lstm_hidden_RADIATION, self.n_lstm_layers_RADIATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_output_RADIATION = torch.nn.LSTM(self.n_lstm_hidden_RADIATION, self.n_output, 1, batch_first=True, bias=False)\n",
        "\n",
        "        self.lstm_input_SPACEHEATER = torch.nn.LSTM(2, self.n_lstm_hidden_SPACEHEATER, self.n_lstm_layers_SPACEHEATER, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_output_SPACEHEATER = torch.nn.LSTM(self.n_lstm_hidden_SPACEHEATER, self.n_output, 1, batch_first=True, bias=False)\n",
        "\n",
        "        self.lstm_input_VENTILATION = torch.nn.LSTM(2, self.n_lstm_hidden_VENTILATION, self.n_lstm_layers_VENTILATION, batch_first=True, dropout=self.dropout, bias=False)\n",
        "        self.lstm_output_VENTILATION = torch.nn.LSTM(self.n_lstm_hidden_VENTILATION, self.n_output, 1, batch_first=True, bias=False)\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(p=self.dropout, inplace=False)\n",
        "\n",
        "\n",
        "        # self.linear_OUTDOORTEMPERATURE = torch.nn.Linear(self.n_lstm_hidden_OUTDOORTEMPERATURE,1)\n",
        "        # self.linear_RADIATION = torch.nn.Linear(self.n_lstm_hidden_RADIATION,1)\n",
        "        # self.linear_SPACEHEATER = torch.nn.Linear(self.n_lstm_hidden_SPACEHEATER,1)\n",
        "        # self.linear_VENTILATION = torch.nn.Linear(self.n_lstm_hidden_VENTILATION,1)\n",
        "\n",
        "        self.linear_u = torch.nn.Linear(1,1, bias=False)\n",
        "        self.linear_T_o_hid = torch.nn.Linear(1,self.n_lstm_hidden_VENTILATION)\n",
        "        self.linear_T_o_out = torch.nn.Linear(self.n_lstm_hidden_VENTILATION,1)\n",
        "        self.linear_T_z = torch.nn.Linear(1,1)\n",
        "\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "    # @jit.script_method\n",
        "    def forward(self, \n",
        "                input: Tuple[Tensor, Tensor, Tensor, Tensor], \n",
        "                hidden_state: Tuple[Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor],\n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor], \n",
        "                                    Tuple[Tensor, Tensor]]):\n",
        "\n",
        "\n",
        "        (x_OUTDOORTEMPERATURE,\n",
        "        x_RADIATION,\n",
        "        x_SPACEHEATER,\n",
        "        x_VENTILATION) = input\n",
        "\n",
        "        \n",
        "\n",
        "        (hidden_state_input_OUTDOORTEMPERATURE,\n",
        "        hidden_state_output_OUTDOORTEMPERATURE,\n",
        "        hidden_state_input_RADIATION,\n",
        "        hidden_state_output_RADIATION,\n",
        "        hidden_state_input_SPACEHEATER,\n",
        "        hidden_state_output_SPACEHEATER,\n",
        "        hidden_state_input_VENTILATION,\n",
        "        hidden_state_output_VENTILATION) = hidden_state\n",
        "\n",
        "        # h_0_hidden1_OUTDOORTEMPERATURE = torch.zeros(hidden_state_input_OUTDOORTEMPERATURE[0].shape).cuda()\n",
        "        # c_0_hidden1_layer_OUTDOORTEMPERATURE = torch.zeros(hidden_state_input_OUTDOORTEMPERATURE[1].shape).cuda()\n",
        "        # hidden_state_hidden1_OUTDOORTEMPERATURE = (h_0_hidden1_OUTDOORTEMPERATURE,c_0_hidden1_layer_OUTDOORTEMPERATURE)\n",
        "        # h_0_hidden2_OUTDOORTEMPERATURE = torch.zeros(hidden_state_input_OUTDOORTEMPERATURE[0].shape).cuda()\n",
        "        # c_0_hidden2_layer_OUTDOORTEMPERATURE = torch.zeros(hidden_state_input_OUTDOORTEMPERATURE[1].shape).cuda()\n",
        "        # hidden_state_hidden2_OUTDOORTEMPERATURE = (h_0_hidden2_OUTDOORTEMPERATURE,c_0_hidden2_layer_OUTDOORTEMPERATURE)\n",
        "\n",
        "        # h_0_hidden1_RADIATION = torch.zeros(hidden_state_input_RADIATION[0].shape).cuda()\n",
        "        # c_0_hidden1_layer_RADIATION = torch.zeros(hidden_state_input_RADIATION[1].shape).cuda()\n",
        "        # hidden_state_hidden1_RADIATION = (h_0_hidden1_RADIATION,c_0_hidden1_layer_RADIATION)\n",
        "        # h_0_hidden2_RADIATION = torch.zeros(hidden_state_input_RADIATION[0].shape).cuda()\n",
        "        # c_0_hidden2_layer_RADIATION = torch.zeros(hidden_state_input_RADIATION[1].shape).cuda()\n",
        "        # hidden_state_hidden2_RADIATION = (h_0_hidden2_RADIATION,c_0_hidden2_layer_RADIATION)\n",
        "\n",
        "\n",
        "        x_OUTDOORTEMPERATURE,hidden_state_input_OUTDOORTEMPERATURE = self.lstm_input_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_input_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = x_OUTDOORTEMPERATURE + x_OUTDOORTEMPERATURE_temp\n",
        "        # x_OUTDOORTEMPERATURE_temp,hidden_state_input_OUTDOORTEMPERATURE = self.lstm_hidden1_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_hidden1_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = x_OUTDOORTEMPERATURE + x_OUTDOORTEMPERATURE_temp\n",
        "        # x_OUTDOORTEMPERATURE_temp,hidden_state_input_OUTDOORTEMPERATURE = self.lstm_hidden2_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_hidden2_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = x_OUTDOORTEMPERATURE + x_OUTDOORTEMPERATURE_temp\n",
        "        # x_OUTDOORTEMPERATURE,hidden_state_input_OUTDOORTEMPERATURE = self.lstm_input_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_input_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = self.dropout(x_OUTDOORTEMPERATURE)\n",
        "        # x_OUTDOORTEMPERATURE = x_OUTDOORTEMPERATURE + x_OUTDOORTEMPERATURE_\n",
        "        x_OUTDOORTEMPERATURE,hidden_state_output_OUTDOORTEMPERATURE = self.lstm_output_OUTDOORTEMPERATURE(x_OUTDOORTEMPERATURE,hidden_state_output_OUTDOORTEMPERATURE)\n",
        "\n",
        "        x_RADIATION,hidden_state_input_RADIATION = self.lstm_input_RADIATION(x_RADIATION,hidden_state_input_RADIATION)\n",
        "        # x_RADIATION = x_RADIATION + x_RADIATION_temp\n",
        "        # x_RADIATION_temp,hidden_state_input_RADIATION = self.lstm_hidden1_RADIATION(x_RADIATION,hidden_state_hidden1_RADIATION)\n",
        "        # x_RADIATION = x_RADIATION + x_RADIATION_temp\n",
        "        # x_RADIATION_temp,hidden_state_input_RADIATION = self.lstm_hidden2_RADIATION(x_RADIATION,hidden_state_hidden2_RADIATION)\n",
        "        # x_RADIATION = x_RADIATION + x_RADIATION_temp\n",
        "        x_RADIATION,hidden_state_output_RADIATION = self.lstm_output_RADIATION(x_RADIATION,hidden_state_output_RADIATION)\n",
        "\n",
        "        x_SPACEHEATER,hidden_state_input_SPACEHEATER = self.lstm_input_SPACEHEATER(x_SPACEHEATER,hidden_state_input_SPACEHEATER)\n",
        "        # x_SPACEHEATER = self.dropout(x_SPACEHEATER)\n",
        "        # x_SPACEHEATER = x_SPACEHEATER + x_SPACEHEATER_\n",
        "        x_SPACEHEATER,hidden_state_output_SPACEHEATER = self.lstm_output_SPACEHEATER(x_SPACEHEATER,hidden_state_output_SPACEHEATER)\n",
        "\n",
        "        # x_damper = torch.unsqueeze(x_VENTILATION[:,:,1],2)\n",
        "        x_VENTILATION,hidden_state_input_VENTILATION = self.lstm_input_VENTILATION(x_VENTILATION,hidden_state_input_VENTILATION)\n",
        "        # # x_VENTILATION = self.dropout(x_VENTILATION)\n",
        "        # # x_VENTILATION = x_VENTILATION + x_VENTILATION_\n",
        "        x_VENTILATION,hidden_state_output_VENTILATION = self.lstm_output_VENTILATION(x_VENTILATION,hidden_state_output_VENTILATION)\n",
        "        # x_VENTILATION = x_VENTILATION*x_damper\n",
        "\n",
        "\n",
        "        # d1,d2,d3 = x_VENTILATION.size()\n",
        "        # x_VENTILATION = x_VENTILATION.reshape(d1*d2,d3)\n",
        "        # x_indoor = torch.unsqueeze(x_VENTILATION[:,0],1)\n",
        "        # x_damper = torch.unsqueeze(x_VENTILATION[:,1],1)\n",
        "        # x_supply_air_temperature = torch.unsqueeze(x_VENTILATION[:,2],1)\n",
        "\n",
        "        # x_VENTILATION = (x_supply_air_temperature-self.linear_T_z(x_indoor))*self.linear_u(x_damper)\n",
        "        # x_VENTILATION = x_VENTILATION.reshape(d1,d2,1)\n",
        "\n",
        "        x = (x_OUTDOORTEMPERATURE, x_RADIATION, x_SPACEHEATER, x_VENTILATION)\n",
        "        y = x_OUTDOORTEMPERATURE + x_RADIATION + x_SPACEHEATER + x_VENTILATION\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        hidden_state = (hidden_state_input_OUTDOORTEMPERATURE,\n",
        "                        hidden_state_output_OUTDOORTEMPERATURE,\n",
        "                        hidden_state_input_RADIATION,\n",
        "                        hidden_state_output_RADIATION,\n",
        "                        hidden_state_input_SPACEHEATER,\n",
        "                        hidden_state_output_SPACEHEATER,\n",
        "                        hidden_state_input_VENTILATION,\n",
        "                        hidden_state_output_VENTILATION)\n",
        "\n",
        "        return y,hidden_state,x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def min_max_norm(y,y_min,y_max,low,high):\n",
        "    y = (y-y_min)/(y_max-y_min)*(high-low) + low\n",
        "    return y\n",
        "\n",
        "def rescale(y,y_min,y_max,low,high):\n",
        "    y = (y-low)/(high-low)*(y_max-y_min) + y_min\n",
        "    return y\n",
        "\n",
        "def sigmoid_inverse(x):\n",
        "    out = np.log(x/(1-x))\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, space_name, data_paths, load=True, plot=False, hyperparameters=None):\n",
        "\n",
        "        self.space_name = space_name\n",
        "\n",
        "        (self.training_data_folder_name,\n",
        "        self.drive_zipped_training_data_path,\n",
        "        self.drive_unzipped_training_data_path,\n",
        "        self.vm_drive_unzip_data_path,\n",
        "        self.vm_drive_training_data_path) = data_paths\n",
        "\n",
        "\n",
        "        np.random.seed(0)\n",
        "\n",
        "        self.saved_serialized_networks_path = \"/content/drive/My Drive/Google collab/b3d_serialized_networks_new/\"\n",
        "        self.saved_networks_path = \"/content/drive/My Drive/Google collab/b3d_saved_networks_new/\"\n",
        "\n",
        "        os.chdir(self.saved_networks_path)\n",
        "\n",
        "        # self.T_min = -7.91\n",
        "        # self.T_max = 39.29999923706055\n",
        "        \n",
        "        self.dT_min = -1\n",
        "        self.dT_max = -self.dT_min\n",
        "        \n",
        "        self.best_loss_diff_max = 200\n",
        "        self.max_it_stop = 10000000\n",
        "        momentum = 0.9 \n",
        "        LR = hyperparameters[\"lr\"]#'1e-2' #1e-1\n",
        "        LR_s = hyperparameters[\"lr\"]#'1e-2' #1e-1\n",
        "        self.update_factor = 1e-1\n",
        "        self.n_step_diff = 10000000000 #768000 #30 Epochs\n",
        "        self.n_step_update = self.n_step_diff\n",
        "        self.n_step_max = int(self.n_step_diff+self.n_step_diff/4+self.n_step_diff/16)\n",
        "        self.learning_rate = float(LR_s)\n",
        "        self.n_batch = hyperparameters[\"batch\"]\n",
        "        self.n_batch_s = hyperparameters[\"batch\"]\n",
        "        # self.file_batch = 64\n",
        "        self.file_batch = 2**9 #2048\n",
        "        self.n_output = 1\n",
        "        self.n_input = self.get_input_size() ################################################\n",
        "        self.n_lstm_hidden = tuple([hyperparameters[\"n_hidden\"]]*4)#(3,3,3,3) #20 #(2,2,1,3) good\n",
        "        self.n_lstm_layers = tuple([hyperparameters[\"n_layer\"]]*4)#(2,2,2,2)\n",
        "        self.dropout = 0.\n",
        "\n",
        "\n",
        "        self.load_min_max_scale_values()\n",
        "        self.model = LSTM(self.n_input, self.n_lstm_hidden, self.n_lstm_layers, self.n_output, self.dropout, self.scaling_value_dict).to(DEVICE)\n",
        "        self.model.train()\n",
        "\n",
        "        \n",
        "\n",
        "        # self.optimizer = torch.optim.NAdam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        # self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate,momentum=momentum)\n",
        "        self.loss_train = loss_penalized\n",
        "        self.loss_test = torch.nn.MSELoss()\n",
        "\n",
        "        # model_type_load = \"b3d_B%d_LR%s\" % (self.n_batch,LR)\n",
        "        # model_type_save = \"b3d_B%d_LR%s\" % (self.n_batch,LR_s)\n",
        "        # model_type_load = \"T_diff_b3d_B%d_LR%s\" % (self.n_batch,LR)\n",
        "        # model_type_save = \"T_diff_b3d_B%d_LR%s\" % (self.n_batch,LR_s)\n",
        "        # model_type_load = \"T_diff_LSTM_b3d_B%d_LR%s\" % (self.n_batch,LR)\n",
        "        # model_type_save = \"T_diff_LSTM_b3d_B%d_LR%s\" % (self.n_batch_s,LR_s)\n",
        "        model_type_load = self.space_name + \"_Network_B%d_LR%s_H%s_L%s\" % (self.n_batch,LR,hyperparameters[\"n_hidden\"],hyperparameters[\"n_layer\"])\n",
        "        model_type_save = self.space_name + \"_Network_B%d_LR%s_H%s_L%s\" % (self.n_batch_s,LR_s,hyperparameters[\"n_hidden\"],hyperparameters[\"n_layer\"])\n",
        "\n",
        "        self.network_filename_load = self.space_name + \"_Network\"\n",
        "        self.optimizer_filename_load = self.space_name + \"_Optimizer\"\n",
        "\n",
        "        self.network_filename_save = model_type_save#self.space_name + \"_Network\"\n",
        "        self.optimizer_filename_save = self.space_name + \"_Optimizer\"\n",
        "\n",
        "        self.step_train_filename_load = self.space_name + \"_step_train\"\n",
        "        self.prec_train_filename_load = self.space_name + \"_prec_train\"\n",
        "\n",
        "        self.step_train_filename_save = self.space_name + \"_step_train\"\n",
        "        self.prec_train_filename_save = self.space_name + \"_prec_train\"\n",
        "\n",
        "        self.step_test_filename_load = self.space_name + \"_step_test\"\n",
        "        self.prec_test_filename_load = self.space_name + \"_prec_test\"\n",
        "\n",
        "        self.step_test_filename_save = self.space_name + \"_step_test\"\n",
        "        self.prec_test_filename_save = self.space_name + \"_prec_test\"\n",
        "\n",
        "        self.running_validation_loss_filename_load = self.space_name + \"_running_validation_loss\"\n",
        "        self.running_validation_loss_filename_save = self.space_name + \"_running_validation_loss\"\n",
        "\n",
        "        self.running_validation_loss_model_name_filename_load = self.space_name + \"_running_validation_loss_model_name\"\n",
        "        self.running_validation_loss_model_name_filename_save = self.space_name + \"_running_validation_loss_model_name\"\n",
        "\n",
        "        if load==True:\n",
        "            os.chdir(self.saved_networks_path)\n",
        "            self.model.load_state_dict(torch.load(self.network_filename_load,map_location=torch.device(DEVICE)))\n",
        "            self.optimizer.load_state_dict(torch.load(self.optimizer_filename_load,map_location=torch.device(DEVICE)))\n",
        "\n",
        "            self.step_train = np.load(self.step_train_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "            self.prec_train = np.load(self.prec_train_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "\n",
        "            self.step_test = np.load(self.step_test_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "            self.prec_test = np.load(self.prec_test_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "\n",
        "            os.chdir(self.saved_serialized_networks_path)\n",
        "\n",
        "            self.running_validation_loss = np.load(self.running_validation_loss_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "            self.running_validation_loss_model_name = np.load(self.running_validation_loss_model_name_filename_load + \".npy\",allow_pickle=True).tolist()\n",
        "\n",
        "            os.chdir(self.saved_networks_path)\n",
        "\n",
        "            self.n_step = self.step_train[-1]\n",
        "        else:\n",
        "            load_pretrained_model = False   \n",
        "            if load_pretrained_model:\n",
        "                print(os.getcwd())\n",
        "                print(os.listdir())\n",
        "                self.model.load_state_dict(torch.load(self.network_filename_load + \".pt\",map_location=torch.device(DEVICE)))\n",
        "            \n",
        "            self.step_train = []\n",
        "            self.prec_train = [] \n",
        "            self.step_test = []\n",
        "            self.prec_test = [] \n",
        "            self.running_validation_loss = []\n",
        "            self.running_validation_loss_model_name = []\n",
        "            self.n_step = 0\n",
        "        pytorch_total_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        print(\"TOTAL NUMBER OF PARAMETERS IN MODEL: \" + str(pytorch_total_params))\n",
        "\n",
        "        self.n_step_start = self.n_step\n",
        "\n",
        "\n",
        "\n",
        "        self.batch_train = 0\n",
        "        self.batch_test = 0\n",
        "        self.batch_train_counter = 0\n",
        "\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = self.learning_rate\n",
        "\n",
        "        self.do_test = True\n",
        "        self.extract_model = True\n",
        "\n",
        "        self.n_test = self.file_batch/self.n_batch_s*4\n",
        "        self.plot = plot\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        h_0_input_layer_OUTDOORTEMPERATURE = torch.zeros((self.n_lstm_layers[0],self.n_batch_s,self.n_lstm_hidden[0])).to(DEVICE)\n",
        "        c_0_input_layer_OUTDOORTEMPERATURE = torch.zeros((self.n_lstm_layers[0],self.n_batch_s,self.n_lstm_hidden[0])).to(DEVICE)\n",
        "        h_0_output_layer_OUTDOORTEMPERATURE = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        c_0_output_layer_OUTDOORTEMPERATURE = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        hidden_state_input_OUTDOORTEMPERATURE = (h_0_input_layer_OUTDOORTEMPERATURE,c_0_input_layer_OUTDOORTEMPERATURE)\n",
        "        hidden_state_output_OUTDOORTEMPERATURE = (h_0_output_layer_OUTDOORTEMPERATURE,c_0_output_layer_OUTDOORTEMPERATURE)\n",
        "\n",
        "        h_0_input_layer_RADIATION = torch.zeros((self.n_lstm_layers[1],self.n_batch_s,self.n_lstm_hidden[1])).to(DEVICE)\n",
        "        c_0_input_layer_RADIATION = torch.zeros((self.n_lstm_layers[1],self.n_batch_s,self.n_lstm_hidden[1])).to(DEVICE)\n",
        "        h_0_output_layer_RADIATION = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        c_0_output_layer_RADIATION = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        hidden_state_input_RADIATION = (h_0_input_layer_RADIATION,c_0_input_layer_RADIATION)\n",
        "        hidden_state_output_RADIATION = (h_0_output_layer_RADIATION,c_0_output_layer_RADIATION)\n",
        "\n",
        "        h_0_input_layer_SPACEHEATER = torch.zeros((self.n_lstm_layers[2],self.n_batch_s,self.n_lstm_hidden[2])).to(DEVICE)\n",
        "        c_0_input_layer_SPACEHEATER = torch.zeros((self.n_lstm_layers[2],self.n_batch_s,self.n_lstm_hidden[2])).to(DEVICE)\n",
        "        h_0_output_layer_SPACEHEATER = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        c_0_output_layer_SPACEHEATER = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        hidden_state_input_SPACEHEATER = (h_0_input_layer_SPACEHEATER,c_0_input_layer_SPACEHEATER)\n",
        "        hidden_state_output_SPACEHEATER = (h_0_output_layer_SPACEHEATER,c_0_output_layer_SPACEHEATER)\n",
        "\n",
        "        h_0_input_layer_VENTILATION = torch.zeros((self.n_lstm_layers[3],self.n_batch_s,self.n_lstm_hidden[3])).to(DEVICE)\n",
        "        c_0_input_layer_VENTILATION = torch.zeros((self.n_lstm_layers[3],self.n_batch_s,self.n_lstm_hidden[3])).to(DEVICE)\n",
        "        h_0_output_layer_VENTILATION = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        c_0_output_layer_VENTILATION = torch.zeros((1,self.n_batch_s,self.n_output)).to(DEVICE)\n",
        "        hidden_state_input_VENTILATION = (h_0_input_layer_VENTILATION,c_0_input_layer_VENTILATION)\n",
        "        hidden_state_output_VENTILATION = (h_0_output_layer_VENTILATION,c_0_output_layer_VENTILATION)\n",
        "\n",
        "\n",
        "\n",
        "        self.hidden_state = (hidden_state_input_OUTDOORTEMPERATURE,\n",
        "                            hidden_state_output_OUTDOORTEMPERATURE,\n",
        "                            hidden_state_input_RADIATION,\n",
        "                            hidden_state_output_RADIATION,\n",
        "                            hidden_state_input_SPACEHEATER,\n",
        "                            hidden_state_output_SPACEHEATER,\n",
        "                            hidden_state_input_VENTILATION,\n",
        "                            hidden_state_output_VENTILATION)\n",
        "\n",
        "            \n",
        "    def get_input_size(self):\n",
        "        os.chdir(self.vm_drive_training_data_path)\n",
        "        filename = self.space_name + \"_training_batch_%d.npz\" % (self.file_batch)\n",
        "        loaded = np.load(filename)\n",
        "        flat_input = torch.Tensor(loaded[loaded.files[0]])\n",
        "        os.chdir(self.saved_networks_path)\n",
        "        n_input = flat_input.shape[2]\n",
        "        print(\"INPUT\")\n",
        "        print(n_input)\n",
        "        return n_input\n",
        "\n",
        "    def load_batch_into_DEVICE(self, DEVICE, data_type, i):\n",
        "        os.chdir(self.vm_drive_training_data_path)\n",
        "        # os.chdir(self.drive_unzipped_training_data_path)\n",
        "        \n",
        "        name_idx_rand = self.file_batch*i + self.file_batch\n",
        "        filename = self.space_name + \"_\" + data_type + \"_batch_%d.npz\" % (name_idx_rand)\n",
        "\n",
        "        print(f\"LOADED: {filename}\")\n",
        "\n",
        "        loaded = np.load(filename)\n",
        "        flat_input = torch.Tensor(loaded[loaded.files[0]])\n",
        "        output = torch.Tensor(loaded[loaded.files[1]])  \n",
        "\n",
        "        self.flat_input_original = flat_input.to(DEVICE)\n",
        "        self.flat_input = flat_input.to(DEVICE)\n",
        "        self.output = output.to(DEVICE)\n",
        "\n",
        "        self.flat_input = self.flat_input[:,:-1]\n",
        "        self.output_dT = self.output[:,1:]-self.output[:,:-1]\n",
        "\n",
        "\n",
        "    def load_min_max_scale_values(self):\n",
        "        os.chdir(self.vm_drive_training_data_path)\n",
        "        filename = self.space_name + \"_scaling_value_dict\" + \".pickle\"\n",
        "        filehandler = open(filename, 'rb')\n",
        "        self.scaling_value_dict = pickle.load(filehandler)\n",
        "\n",
        "    def scan_directory(self):\n",
        "        os.chdir(self.vm_drive_training_data_path)\n",
        "        directory = os.fsencode(self.vm_drive_training_data_path)\n",
        "        file_counter_training = 0\n",
        "        file_counter_validation = 0\n",
        "        for file in os.listdir(directory):\n",
        "            filename = os.fsdecode(file)\n",
        "            if filename.find(self.space_name + \"_training\") != -1:\n",
        "                file_counter_training += 1\n",
        "            elif filename.find(self.space_name + \"_validation\") != -1:\n",
        "                file_counter_validation += 1\n",
        "        self.max_it_train = file_counter_training\n",
        "        self.max_it_test = file_counter_validation\n",
        "\n",
        "        self.it_list_train = np.arange(0,self.max_it_train)\n",
        "        np.random.shuffle(self.it_list_train)\n",
        "        # self.it_list_test = np.arange(0,self.max_it_test)\n",
        "\n",
        "    def get_input(self, flat_input):\n",
        "\n",
        "        x_OUTDOORTEMPERATURE = torch.zeros((flat_input.shape[0], flat_input.shape[1], 2)).to(DEVICE)\n",
        "        x_RADIATION = torch.zeros((flat_input.shape[0], flat_input.shape[1], 1)).to(DEVICE)\n",
        "        x_SPACEHEATER = torch.zeros((flat_input.shape[0], flat_input.shape[1], 2)).to(DEVICE)\n",
        "        x_VENTILATION = torch.zeros((flat_input.shape[0], flat_input.shape[1], 2)).to(DEVICE)\n",
        "        \n",
        "        x_OUTDOORTEMPERATURE[:,:,0] = flat_input[:,:,0] #indoor\n",
        "        x_OUTDOORTEMPERATURE[:,:,1] = flat_input[:,:,5] #outdoor\n",
        "        # x_OUTDOORTEMPERATURE[:,:,2] = flat_input[:,:,6] #outdoor\n",
        "        # x_OUTDOORTEMPERATURE[:,:,3] = flat_input[:,:,7] #outdoor\n",
        "        # x_OUTDOORTEMPERATURE[:,:,4] = flat_input[:,:,8] #outdoor\n",
        "        x_RADIATION[:,:,0] = flat_input[:,:,4] #radiation\n",
        "        x_SPACEHEATER[:,:,0] = flat_input[:,:,0] #indoor\n",
        "        x_SPACEHEATER[:,:,1] = flat_input[:,:,1] #energy\n",
        "        # x_SPACEHEATER[:,:,2] = flat_input[:,:,2] #supply water temperature\n",
        "        # x_SPACEHEATER[:,:,3] = flat_input[:,:,2]*flat_input[:,:,3] #energy\n",
        "        x_VENTILATION[:,:,0] = flat_input[:,:,2] #energy\n",
        "        x_VENTILATION[:,:,1] = flat_input[:,:,3] #energy\n",
        "        # x_VENTILATION[:,:,2] = flat_input[:,:,4] #supply air temperature\n",
        "        # x_VENTILATION[:,:,3] = flat_input[:,:,4]*flat_input[:,:,5] #energy in \n",
        "        # x_VENTILATION[:,:,4] = flat_input[:,:,4]*flat_input[:,:,0] #energy out\n",
        "\n",
        "        x_OUTDOORTEMPERATURE.requires_grad = True\n",
        "        x_RADIATION.requires_grad = True\n",
        "        x_SPACEHEATER.requires_grad = True\n",
        "        x_VENTILATION.requires_grad = True\n",
        "\n",
        "\n",
        "        input = (x_OUTDOORTEMPERATURE,\n",
        "                x_RADIATION,\n",
        "                x_SPACEHEATER,\n",
        "                x_VENTILATION)\n",
        "\n",
        "        return input\n",
        "\n",
        "    def train_batch(self, i):\n",
        "        self.load_batch_into_DEVICE(DEVICE, data_type=\"training\", i=i)\n",
        "        self.model.train()\n",
        "        #Shuffle data\n",
        "        idx = np.arange(self.flat_input.shape[0])\n",
        "        np.random.shuffle(idx)\n",
        "\n",
        "        self.flat_input = self.flat_input[idx]\n",
        "        self.output_dT = self.output_dT[idx]\n",
        "\n",
        "\n",
        "        abs_err_train = 0\n",
        "        n_it_sub_batch = int(np.ceil(self.file_batch/self.n_batch_s))\n",
        "        t_start = time.time()\n",
        "        loss_vec = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        loss_vec_T = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        loss_vec_dT = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        update = False\n",
        "        # print(\"----\")\n",
        "        for idx in range(n_it_sub_batch):\n",
        "            flat_input_batch = self.flat_input[idx*self.n_batch_s:(idx+1)*self.n_batch_s]\n",
        "            output_dT_batch = self.output_dT[idx*self.n_batch_s:(idx+1)*self.n_batch_s]\n",
        "\n",
        "            input = self.get_input(flat_input_batch)\n",
        "\n",
        "            # time_start = time.time()\n",
        "            with torch.backends.cudnn.flags(enabled=False):\n",
        "                output_batch_pred,hidden_state,x = self.model(input, self.hidden_state)\n",
        "\n",
        "\n",
        "            loss = self.loss_train(output_batch_pred,output_dT_batch,x,input)\n",
        "            loss_vec[idx] = loss.detach()\n",
        "            # loss_list.append(loss.item())\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.n_step += 1\n",
        "            if self.n_step == self.n_step_update and self.n_step <= self.n_step_max:\n",
        "                update = True\n",
        "           \n",
        "        if update == True:\n",
        "            self.learning_rate = self.learning_rate*self.update_factor\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group['lr'] = self.learning_rate\n",
        "            # self.n_batch_s = int(self.n_batch_s*self.update_factor)\n",
        "            # self.n_step_diff = int(self.n_step_diff/self.update_factor)\n",
        "            self.n_step_update = self.n_step_update + self.n_step_diff\n",
        "   \n",
        "        avg_loss = torch.mean(loss_vec).cpu()\n",
        "        self.step_train.append(self.n_step)\n",
        "        self.prec_train.append(avg_loss)\n",
        "\n",
        "        if self.verbose:\n",
        "            # print('Running average: %s' % \"{:.10f}\".format(running_test_avg))\n",
        "            print(\"---Training batch results---\")\n",
        "            print('Avg loss: %s' % \"{:.10f}\".format(avg_loss))\n",
        "            # print('Avg MSE: %s' % \"{:.10f}\".format(avg_MSE))\n",
        "            # print('Avg MAE: %s' % \"{:.10f}\".format(avg_MAE))\n",
        "      \n",
        "        # if self.verbose:\n",
        "        #     print(\"---Training batch results---\")\n",
        "        #     print('Batch number: %d' % (self.batch_train))\n",
        "        #     print('Gradient steps: %d' % (self.n_step))\n",
        "        #     print('Learning rate: %s' % \"{:.10f}\".format(self.learning_rate))\n",
        "\n",
        "\n",
        "        #     print('Update factor: %d' % (self.update_factor))\n",
        "        #     print('Next update: %d' % (self.n_step_update))\n",
        "        #     print('Update difference: %d' % (self.n_step_diff))\n",
        "        #     print('Max update: %d' % (self.n_step_max))\n",
        "        #     print('Batch size: %d' % (self.n_batch_s))\n",
        "\n",
        "        #     print('Avg loss: %s' % \"{:.10f}\".format(avg_loss))\n",
        "\n",
        "    def test_batch(self, i):\n",
        "        self.load_batch_into_DEVICE(DEVICE, data_type=\"validation\", i=i)\n",
        "        \n",
        "\n",
        "        os.chdir(self.saved_networks_path)\n",
        "\n",
        "        rescaled_y_list = []\n",
        "        rescaled_y_pred_list = []\n",
        "        r_valve_list = []\n",
        "        abs_err_test = 0\n",
        "\n",
        "        size = self.n_batch_s\n",
        "        # n_it_sub_batch = int(np.ceil(size/self.n_batch_s))\n",
        "        n_it_sub_batch = int(np.ceil(self.file_batch/size))\n",
        "        print(size)\n",
        "        \n",
        "        # loss_list = []\n",
        "        loss_vec = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        MSE_vec = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        MAE_vec = torch.zeros((n_it_sub_batch)).to(DEVICE)\n",
        "        for idx in range(n_it_sub_batch):\n",
        "            flat_input_batch = self.flat_input[idx*size:(idx+1)*size]\n",
        "            output_dT_batch = self.output_dT[idx*size:(idx+1)*size]\n",
        "            input = self.get_input(flat_input_batch)\n",
        "            output_batch_pred,hidden_state,x = self.model(input, self.hidden_state)\n",
        "\n",
        "            dT_cumsum = torch.cumsum(output_batch_pred,dim=1)\n",
        "            # print(output_batch_pred[0,:,:])\n",
        "\n",
        "\n",
        "            T_0 = flat_input_batch[:,0,0]\n",
        "            T_0 = rescale(T_0,self.model.kwargs[\"scaling_value_dict\"][\"indoorTemperature\"][\"min\"],self.model.kwargs[\"scaling_value_dict\"][\"indoorTemperature\"][\"max\"],0,1)\n",
        "            T_0 = T_0.unsqueeze(1)\n",
        "            T_0 = T_0.repeat(1, dT_cumsum.shape[1]).unsqueeze(2)\n",
        "\n",
        "            T = T_0 + dT_cumsum\n",
        "            T_target = self.flat_input_original[idx*size:(idx+1)*size, 1:, 0]\n",
        "            T_target = rescale(T_target,self.model.kwargs[\"scaling_value_dict\"][\"indoorTemperature\"][\"min\"],self.model.kwargs[\"scaling_value_dict\"][\"indoorTemperature\"][\"max\"],0,1)\n",
        "            T_target = T_target.unsqueeze(2)\n",
        "\n",
        "            # plt.figure()\n",
        "            # idx = 0\n",
        "            # plt.plot(T_target[idx,:,0].detach(), color=\"red\")\n",
        "            # plt.plot(T[idx,:,0].detach(), color=\"blue\")\n",
        "            # # plt.plot(flat_input_batch[idx,:,1], color=\"black\")\n",
        "            # display.display(plt.gcf())\n",
        "            # # display.clear_output(wait=True)\n",
        "            # time.sleep(0.1)\n",
        "\n",
        "            MSE = torch.mean((T-T_target)**2)\n",
        "            MAE = torch.mean(torch.abs(T-T_target))\n",
        "            MSE_vec[idx] = MSE.detach()\n",
        "            MAE_vec[idx] = MAE.detach()\n",
        "            ################################################\n",
        "\n",
        "            loss = self.loss_test(output_batch_pred,output_dT_batch)#,x,input)\n",
        "            loss_vec[idx] = loss.detach()\n",
        "\n",
        "            rescaled_y = rescale(output_dT_batch.cpu(),self.dT_min,self.dT_max,-1,1)\n",
        "            rescaled_y_pred = rescale(output_batch_pred.cpu(),self.dT_min,self.dT_max,-1,1)\n",
        "\n",
        "            rescaled_y_list.extend(np.array(rescaled_y))\n",
        "            rescaled_y_pred_list.extend(np.array(rescaled_y_pred.detach()))\n",
        "            r_valve_list.extend(np.array(flat_input_batch[:,:,1].detach().cpu()))\n",
        "\n",
        "        # avg_loss = np.mean(np.array(loss_list))\n",
        "        avg_loss = torch.mean(loss_vec).cpu()\n",
        "        avg_MSE = torch.mean(MSE_vec).cpu()\n",
        "        avg_MAE = torch.mean(MAE_vec).cpu()\n",
        "\n",
        "        # print(f\"Batch testing loss: {avg_loss}\")\n",
        "\n",
        "        if self.verbose:\n",
        "            # print('Running average: %s' % \"{:.10f}\".format(running_test_avg))\n",
        "            print(\"---Testing batch results---\")\n",
        "            print('Avg loss: %s' % \"{:.10f}\".format(avg_loss))\n",
        "            print('Avg MSE: %s' % \"{:.10f}\".format(avg_MSE))\n",
        "            print('Avg MAE: %s' % \"{:.10f}\".format(avg_MAE))\n",
        "        \n",
        "\n",
        "        self.rescaled_y_list = np.array(rescaled_y_list)\n",
        "        self.rescaled_y_pred_list = np.array(rescaled_y_pred_list)\n",
        "        self.r_valve_list = np.array(r_valve_list)\n",
        "\n",
        "        self.step_test.append(self.n_step)\n",
        "        self.prec_test.append(avg_loss) ##################################\n",
        "\n",
        "        # print(\"test_batch\")\n",
        "        # print(MAE_vec)\n",
        "        # print(self.prec_test)\n",
        "\n",
        "\n",
        "    def test_all(self):\n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            for i in range(self.max_it_test):\n",
        "                self.test_batch(i)\n",
        "        \n",
        "        #Saving\n",
        "        np.save(self.step_train_filename_save + \".npy\",np.array(self.step_train))\n",
        "        np.save(self.prec_train_filename_save + \".npy\",np.array(self.prec_train))\n",
        "\n",
        "        np.save(self.step_test_filename_save + \".npy\",np.array(self.step_test))\n",
        "        np.save(self.prec_test_filename_save + \".npy\",np.array(self.prec_test))\n",
        "\n",
        "        torch.save(self.model.state_dict(),self.network_filename_save)\n",
        "        torch.save(self.optimizer.state_dict(),self.optimizer_filename_save)\n",
        "\n",
        "        if self.plot:\n",
        "            running_test_avg = torch.mean(torch.Tensor(self.prec_test[-self.max_it_test:]))\n",
        "            np_step_test = np.array(self.step_test, dtype=np.int)\n",
        "            np_prec_test = np.array(self.prec_test)\n",
        "            unique_step_test = np.unique(self.step_test)\n",
        "            unique_prec_test = [np.mean(np_prec_test[idx==np_step_test]) for idx in unique_step_test]\n",
        "            try:\n",
        "                self.const_line.remove()\n",
        "            except:\n",
        "                pass\n",
        "            if self.plot:\n",
        "                # Plotting\n",
        "                self.ax_loss.plot(self.step_train,self.prec_train, color=\"blue\")\n",
        "                self.ax_loss.plot(unique_step_test,unique_prec_test, color=\"black\")\n",
        "                self.const_line = self.ax_loss.axhline(y=running_test_avg, color='r', linestyle='-')\n",
        "                self.ax_loss.set_yscale('log')\n",
        "                self.ax[0].clear()\n",
        "                var_vec = np.var(self.rescaled_y_list[:,:,0], axis=1)\n",
        "                max_var_idx = np.random.randint(self.rescaled_y_list[:,:,0].shape[0])#np.argmax(var_vec)\n",
        "                self.ax[0].plot(self.rescaled_y_list[max_var_idx,:,0], color=\"blue\",label=\"Truth\")\n",
        "                self.ax[0].plot(self.rescaled_y_pred_list[max_var_idx,:,0], color=\"green\",label=\"Prediction\")\n",
        "                self.ax[0].plot(self.r_valve_list[max_var_idx,:], color=\"red\",label=\"valve\")\n",
        "                # ax_i.set_ylim([15, 28])\n",
        "                self.ax[0].legend()\n",
        "                self.ax[1].clear()\n",
        "                self.ax[1].plot(self.output.cpu().detach().numpy()[max_var_idx,:-1,0]) #\n",
        "                # self.ax[1].set_ylim([15, 28])\n",
        "                display.display(plt.gcf())\n",
        "                # display.clear_output(wait=True)\n",
        "                time.sleep(0.1)\n",
        "\n",
        "    def serialize_model(self):\n",
        "        do_break = False\n",
        "        # os.chdir(S_path)\n",
        "        self.model.cpu()\n",
        "        os.chdir(self.saved_serialized_networks_path)\n",
        "        filename = self.network_filename_save + \"_step\" + str(self.n_step) + \".pt\"\n",
        "        torch.save((self.model.kwargs, self.model.state_dict()), filename)\n",
        "        # print(\"----\")\n",
        "        # print(self.prec_test[-self.max_it_test:])\n",
        "        # print(np.array(self.prec_test[-self.max_it_test:]))\n",
        "        # print(np.mean(np.array(self.prec_test[-self.max_it_test:])))\n",
        "        # print(\"----\")\n",
        "        self.running_validation_loss.append(np.mean(np.array(self.prec_test[-self.max_it_test:])))\n",
        "        np.save(self.running_validation_loss_filename_save + \".npy\",np.array(self.running_validation_loss))\n",
        "        self.running_validation_loss_model_name.append(self.network_filename_save + \"_step\" + str(self.n_step) + \".pt\")\n",
        "        np.save(self.running_validation_loss_model_name_filename_save + \".npy\",np.array(self.running_validation_loss_model_name))\n",
        "        if self.verbose:\n",
        "            print(\"Saved serialized module\")\n",
        "        \n",
        "        idx = np.nanargmin(np.array(self.running_validation_loss))\n",
        "        best_n_step = int(self.running_validation_loss_model_name[idx].split(\"_step\")[1][:-3])\n",
        "        step_diff = self.n_step-best_n_step\n",
        "\n",
        "\n",
        "        if step_diff>=self.best_loss_diff_max:\n",
        "            print(\"No improvement for the last \" + str(self.best_loss_diff_max) + \" iterations: Stopping...\")\n",
        "            do_break = True\n",
        "\n",
        "        self.model.train()\n",
        "        self.model.to(DEVICE)\n",
        "        self.sort_directory()\n",
        "        return do_break\n",
        "\n",
        "    def train(self, verbose=False):\n",
        "        self.verbose = verbose\n",
        "        if self.plot:\n",
        "            rows = 3\n",
        "            fig = plt.figure(figsize=(40,10))\n",
        "            grid = plt.GridSpec(rows, 1, hspace=0.2, wspace=0.2)\n",
        "            self.ax_loss = fig.add_subplot(grid[0, 0:1]) #0:2\n",
        "            self.ax = []\n",
        "            for i in range(1,rows,1):\n",
        "                for j in range(1):\n",
        "                    self.ax.append(fig.add_subplot(grid[i, j]))#, xticklabels=[])#, sharey=main_ax)\n",
        "            for ax_i in self.ax:\n",
        "                ax_i.set_ylim([20, 23])\n",
        "        \n",
        "        while True:   \n",
        "            if self.verbose:\n",
        "                print('--------------------------')\n",
        "            if self.do_test == True:\n",
        "                self.test_all()\n",
        "                # self.batch_idx_test += 1\n",
        "                self.do_test = False\n",
        "                do_break = self.serialize_model()\n",
        "                if do_break:\n",
        "                    break\n",
        "            self.train_batch(self.it_list_train[self.batch_train])\n",
        "            self.batch_train += 1\n",
        "            if self.batch_train == self.max_it_train:\n",
        "                np.random.shuffle(self.it_list_train)\n",
        "                self.batch_train = 0\n",
        "            if self.n_step % self.n_test == 0:\n",
        "                self.do_test = True\n",
        "\n",
        "            idx = np.nanargmin(np.array(self.running_validation_loss))\n",
        "            best_n_step = int(self.running_validation_loss_model_name[idx].split(\"_step\")[1][:-3])\n",
        "            step_diff = self.n_step-best_n_step\n",
        "            running_test_avg = torch.mean(torch.Tensor(self.prec_test[-self.max_it_test:]))\n",
        "            add_args = [self.n_step, running_test_avg.item(), step_diff, np.nanmin(np.array(self.running_validation_loss))]\n",
        "            progressbar(self.n_step,self.n_step_start,self.max_it_stop, add_args = add_args)\n",
        "\n",
        "            if self.n_step >= self.max_it_stop:\n",
        "                break\n",
        "            if time.time()-start_time>time_limit:\n",
        "                break\n",
        "\n",
        "    def display(self,str_input):\n",
        "\n",
        "        fill_str = \"#\"\n",
        "        n = 100\n",
        "        n_str_input = len(str_input)\n",
        "        n_fill_left = math.ceil((n-n_str_input)/2) - 1\n",
        "        n_fill_right = n-n_fill_left-n_str_input - 2\n",
        "        n_rows = 3\n",
        "        i_row = 1 #Index of row placement of input string\n",
        "\n",
        "        str_output = \"\"\n",
        "        for row in range(n_rows):\n",
        "            if row == i_row:\n",
        "                for j in range(n_fill_left):\n",
        "                    str_output += fill_str\n",
        "                str_output += \" \"\n",
        "                str_output += str_input\n",
        "                str_output += \" \"\n",
        "                for j in range(n_fill_right):\n",
        "                    str_output += fill_str\n",
        "                str_output += \"\\n\"\n",
        "            else:\n",
        "                for j in range(n):\n",
        "                    str_output += fill_str\n",
        "                str_output += \"\\n\"\n",
        "\n",
        "        print(str_output)\n",
        "\n",
        "\n",
        "\n",
        "    def sort_directory(self):\n",
        "        os.chdir(self.saved_serialized_networks_path)\n",
        "\n",
        "        running_validation_loss = np.array(self.running_validation_loss)\n",
        "        idx = np.argmin(running_validation_loss)\n",
        "        running_validation_loss_model_name_sorted = self.running_validation_loss_model_name[:]\n",
        "        running_validation_loss_model_name_sorted.pop(idx)\n",
        "\n",
        "        for filename in running_validation_loss_model_name_sorted:\n",
        "            try:\n",
        "                os.remove(filename)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        self.running_validation_loss = [self.running_validation_loss[idx]]\n",
        "        self.running_validation_loss_model_name = [self.running_validation_loss_model_name[idx]]\n",
        "        \n",
        "        np.save(self.running_validation_loss_filename_save + \".npy\",np.array(self.running_validation_loss))\n",
        "        np.save(self.running_validation_loss_model_name_filename_save + \".npy\",np.array(self.running_validation_loss_model_name))\n",
        "\n",
        "    def one_time_delete(self):\n",
        "        os.chdir(self.saved_serialized_networks_path)\n",
        "\n",
        "        running_validation_loss = np.array(self.running_validation_loss)\n",
        "        idx = np.argmin(running_validation_loss)\n",
        "\n",
        "        print(\"----\")\n",
        "        print(self.running_validation_loss_model_name)\n",
        "        print(self.running_validation_loss)\n",
        "\n",
        "        if running_validation_loss.size!=1:\n",
        "            \n",
        "\n",
        "            self.running_validation_loss = [self.running_validation_loss[idx]]\n",
        "            self.running_validation_loss_model_name = [self.running_validation_loss_model_name[idx]]\n",
        "\n",
        "            np.save(self.running_validation_loss_filename_save + \".npy\",np.array(self.running_validation_loss))\n",
        "            np.save(self.running_validation_loss_model_name_filename_save + \".npy\",np.array(self.running_validation_loss_model_name))\n",
        "\n",
        "        print(\"----\")\n",
        "        print(self.running_validation_loss_model_name)\n",
        "        print(self.running_validation_loss)\n",
        "\n",
        "def load_dataset_into_disk(data_paths):\n",
        "    file_batch = 2**9\n",
        "    (training_data_folder_name,\n",
        "    drive_zipped_training_data_path,\n",
        "    drive_unzipped_training_data_path,\n",
        "    vm_drive_unzip_data_path,\n",
        "    vm_drive_training_data_path) = data_paths\n",
        "    print(drive_zipped_training_data_path)\n",
        "    print(vm_drive_unzip_data_path)\n",
        "    if os.path.isdir(training_data_folder_name):\n",
        "        print(\"VM training directory already exists: Proceeding...\")\n",
        "    else:\n",
        "        print(\"Unzipping training directory...\")\n",
        "        command_str = \"unzip \\\"%s\\\" -d \\\"%s\\\" \" % (drive_zipped_training_data_path, vm_drive_unzip_data_path)\n",
        "        os.system(command_str)\n",
        "    \n",
        "    # os.chdir(vm_drive_training_data_path)\n",
        "    # filename =  \"saved_space_list\" + \".npz\"\n",
        "    # loaded = np.load(filename)\n",
        "    # saved_space_list = loaded[loaded.files[0]]\n",
        "    \n",
        "    print(\"Loaded...\")\n",
        "    # new_saved_space_list = []\n",
        "\n",
        "    # print(\"Validating dataset...\")\n",
        "\n",
        "    # os.chdir(vm_drive_training_data_path)\n",
        "    # for i,space_name in enumerate(saved_space_list):\n",
        "        \n",
        "    #     filename1 = space_name + \"_validation_batch_%d.npz\" % file_batch\n",
        "    #     filename2 = space_name + \"_test_batch_%d.npz\" % file_batch\n",
        "    #     if os.path.isfile(filename1) and os.path.isfile(filename2):\n",
        "    #         load = True\n",
        "    #     else:\n",
        "    #         print(\"Can't load \\\"\" + space_name + \"\\\"\")\n",
        "    #         load = False\n",
        "\n",
        "    #     if load == False:\n",
        "    #         i = 0\n",
        "    #         while True:\n",
        "    #             name_idx = file_batch*i + file_batch\n",
        "    #             filename = space_name + \"_\" + \"training\" + \"_batch_%d.npz\" % (name_idx)\n",
        "    #             try:\n",
        "    #                 os.remove(filename)\n",
        "    #             except Exception as inst:\n",
        "    #                 break\n",
        "    #             i += 1\n",
        "\n",
        "    #     else:\n",
        "    #         new_saved_space_list.append(space_name)\n",
        "\n",
        "    # os.chdir(vm_drive_unzip_data_path)\n",
        "    # filename =  \"saved_space_list\" + \".npz\"\n",
        "    # np.savez_compressed(filename, np.array(new_saved_space_list))\n",
        "\n",
        "    # return new_saved_space_list\n",
        "\n",
        "\n",
        "def progressbar(current,start,stop, add_args=None):\n",
        "    total_time = stop-start\n",
        "    relative_time = current-start\n",
        "    n_ticks_total = 40\n",
        "    n_ticks_current = math.ceil(relative_time/total_time*n_ticks_total)\n",
        "    percent_done = math.ceil(relative_time/total_time*100)\n",
        "\n",
        "    progress_str = '|'\n",
        "    for i in range(n_ticks_total):\n",
        "        if n_ticks_current > i:\n",
        "            progress_str += '#'\n",
        "        else:\n",
        "            progress_str += '-'\n",
        "    if add_args:\n",
        "        progress_str += '| ' + str(percent_done) + '% '\n",
        "        for arg in add_args:\n",
        "            progress_str += \"-- \" + str(arg) + \" \"\n",
        "    else:\n",
        "        progress_str += '| ' + str(percent_done) + '% '\n",
        "    sys.stdout.write('\\r\\x1b[K' + progress_str)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "# !nvidia-smi\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "start_time = time.time()\n",
        "time_limit = 1e+10\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "training_data_folder_name = \"space_model_batches\"\n",
        "drive_zipped_training_data_path = \"/content/drive/My Drive/Google collab/OU44_zipped\" + \"/\" + training_data_folder_name + \".zip\"\n",
        "drive_unzipped_training_data_path = \"/content/drive/My Drive/Google collab/OU44_LSTM_data_2048batch_-11norm_10min_144seq_filtered_test_relu/\"\n",
        "vm_drive_unzip_data_path = \"/content\"\n",
        "vm_drive_training_data_path = vm_drive_unzip_data_path + \"/\" + training_data_folder_name\n",
        "\n",
        "data_paths = (training_data_folder_name,\n",
        "            drive_zipped_training_data_path,\n",
        "            drive_unzipped_training_data_path,\n",
        "            vm_drive_unzip_data_path,\n",
        "            vm_drive_training_data_path)\n",
        "\n",
        "saved_space_list = load_dataset_into_disk(data_paths)\n",
        "\n",
        "# trainer.load_dataset_into_disk()\n",
        "# trainer.load_batch_into_DEVICE()\n",
        "# trainer.visualize_outputs()\n",
        "\n",
        "\n",
        "# trainer.load_batch_into_DEVICE()\n",
        "# trainer.get_input_gradients()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################################################\n",
        "# for i,space_name in enumerate(saved_space_list):\n",
        "#     # clear_output(wait=True)\n",
        "#     train = False\n",
        "#     try:\n",
        "#         trainer = Trainer(space_name, data_paths, load=True)\n",
        "#         running_validation_loss = np.array(trainer.running_validation_loss)\n",
        "\n",
        "#         if running_validation_loss.size==1:\n",
        "#             print(\"Space \\\"\" + space_name + \"\\\" exists and has size 1\")\n",
        "#             # print(trainer.running_validation_loss_model_name)\n",
        "\n",
        "#             best_idx = int(trainer.running_validation_loss_model_name[0].split(\"_step\")[1].split(\".pt\")[0])\n",
        "\n",
        "            \n",
        "#             best_loss_diff = trainer.n_step-best_idx\n",
        "#             if best_loss_diff>=trainer.best_loss_diff_max:\n",
        "#                 print(\"No improvement for the last \" + str(trainer.best_loss_diff_max) + \" iterations: Skipping...\")\n",
        "#             else:\n",
        "#                 train = True\n",
        "\n",
        "#         else:\n",
        "#             print(\"Space \\\"\" + space_name + \"\\\" exists but has size \" + str(running_validation_loss.size))\n",
        "#             trainer = Trainer(space_name, data_paths, load=True)\n",
        "#             train = True\n",
        "\n",
        "#     except Exception as inst:\n",
        "#         # print(inst)\n",
        "#         print(\"Can't load \\\"\" + space_name + \"\\\"\")\n",
        "#         trainer = Trainer(space_name, data_paths, load=False)\n",
        "#         train = True\n",
        "\n",
        "#     if train == True:\n",
        "#         print(\"Space number \" + str(i))\n",
        "#         trainer.load_min_max_scale_values()\n",
        "#         trainer.scan_directory()\n",
        "#         trainer.train(verbose=False)\n",
        "#         trainer.sort_directory()\n",
        "##################################################################\n",
        "# 20-601b-2\n",
        "# 22-511-2\n",
        "space_name = \"OE20-601b-2\"\n",
        "# space_name = \"OE22-511-2\"\n",
        "batch_list = [2**5, 2**7]\n",
        "lr_list = [3e-2, 1e-2, 5e-3]\n",
        "n_hidden_list = [3, 5, 10]\n",
        "n_layers_list = [2, 1, 3]\n",
        "import json\n",
        "result_dict = {str(lr):{\n",
        "                str(batch): {\n",
        "                    str(n_hidden): {\n",
        "                        str(n_layers): {\n",
        "                            \"name\": None, \n",
        "                            \"loss\": None\n",
        "                                        } \n",
        "                                    for n_layers in n_layers_list\n",
        "                                    } \n",
        "                             for n_hidden in n_hidden_list\n",
        "                            } \n",
        "                        for batch in batch_list} \n",
        "                    for lr in lr_list\n",
        "                }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for batch in batch_list:\n",
        "    for lr in lr_list:\n",
        "        for n_hidden in n_hidden_list:\n",
        "            for n_layer in n_layers_list:\n",
        "                hyperparameters = {\"batch\": batch,\n",
        "                                    \"lr\": lr,\n",
        "                                   \"n_hidden\": n_hidden,\n",
        "                                   \"n_layer\": n_layer}\n",
        "                trainer = Trainer(space_name, data_paths, load=False, plot=False, hyperparameters=hyperparameters)\n",
        "                \n",
        "                trainer.scan_directory()\n",
        "                trainer.train(verbose=True)\n",
        "                trainer.sort_directory()\n",
        "                result_dict[str(lr)][str(batch)][str(n_hidden)][str(n_layer)][\"name\"] = trainer.running_validation_loss_model_name[0]\n",
        "                result_dict[str(lr)][str(batch)][str(n_hidden)][str(n_layer)][\"loss\"] = float(trainer.running_validation_loss[0])\n",
        "                print(json.dumps(result_dict, indent=4))\n",
        "                with open(trainer.saved_serialized_networks_path + \"results.json\", 'w') as f:\n",
        "                    json.dump(result_dict, f)\n",
        "\n",
        "\n",
        "# %mprun -f trainer.load_dataset_into_RAM trainer.load_dataset_into_RAM()\n",
        "# %lprun -f trainer.train_batch -f trainer.test_batch -f trainer.train -f trainer.load_batch_into_DEVICE trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yJ5dekd7bbI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X2FGJ3pKphH",
        "outputId": "77b939ba-c168-4253-d96a-fd050a9e015c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K|########################################| 100% "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import math\n",
        "\n",
        "def progressbar(current,start,stop, add_args=None):\n",
        "\n",
        "    \n",
        "\n",
        "    total_time = stop-start\n",
        "    relative_time = current-start\n",
        "\n",
        "    n_ticks_total = 40\n",
        "    n_ticks_current = math.ceil(relative_time/total_time*n_ticks_total)\n",
        "    percent_done = math.ceil(relative_time/total_time*100)\n",
        "\n",
        "    progress_str = '|'\n",
        "    for i in range(n_ticks_total):\n",
        "        if n_ticks_current > i:\n",
        "            progress_str += '#'\n",
        "        else:\n",
        "            progress_str += '-'\n",
        "    \n",
        "    if add_args:\n",
        "        progress_str += '| ' + str(percent_done) + '% '\n",
        "        for arg in add_args:\n",
        "            progress_str += \"-- \" + str(arg)\n",
        "    else:\n",
        "        progress_str += '| ' + str(percent_done) + '% '\n",
        "\n",
        "\n",
        "    sys.stdout.write('\\r\\x1b[K' + progress_str)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "for i in range(10000):\n",
        "    progressbar(i,0,10000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEJ-qclujS6y",
        "outputId": "24da54ac-ea8a-4f38-bac6-006c0895e6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31285 sha256=8beee7403bc291796459a59f64a8832243f92548bd659677491ff3f7f4322478\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.60.0\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/memory_profiler.py\", line 845, in enable\n",
            "    sys.settrace(self.trace_memory_usage)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOTAL NUMBER OF PARAMETERS IN MODEL: 2643209\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "0\n",
            "----\n",
            "4\n",
            "905969664\n",
            "3623878656\n",
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/memory_profiler.py\", line 848, in disable\n",
            "    sys.settrace(self._original_trace_function)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----\n",
            "4\n",
            "905969664\n",
            "3623878656\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from main import Trainer\n",
        "import psutil\n",
        "\n",
        "!pip install memory_profiler\n",
        "# !pip install psutil\n",
        "%load_ext memory_profiler\n",
        "\n",
        "trainer = Trainer()\n",
        "%mprun -f trainer.load_dataset_into_RAM trainer.load_dataset_into_RAM()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsKy5oYHU47i",
        "outputId": "61f29e4a-e3db-4431-da06-7fd45d7f6f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}